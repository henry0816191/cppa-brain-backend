# Simple RAG Evaluation - Per Item Report

**LlamaIndexRAGPipeline**

Total Questions: 20  
Average Similarity: [0.58140516 0.61153334 0.6413766  0.5476894  0.5747075  0.6526638 0.61925775 0.5653993  0.5746726  0.5360156  0.58311397 0.56926024 0.5230895  0.51309454 0.58949745]  
Average Time: 0.435s  

## 1. Question

- **question**: What is the purpose of Boost C++ Libraries?
- **ground_truth**: Boost provides a collection of high-quality, peer-reviewed, portable C++ libraries that extend the functionality of C++. It offers libraries for multi-threading, networking, file handling, algorithms, data structures, and more.
- **rag_answer**: answer 1: > > > > What does this mean for C++ and Boost? I believe there is a > > significant opportunity for Boost to step in and become the rational > > collection of actually useful libraries that the C++ standard library > > is not. We already have networking, some protocols, and JSON. We (the > > existing Boost authors and contributors) might consider looking to the > > list above of industries that use C++, and focus our efforts more > > towards providing libraries that enhance those industries. Perhaps by > > reaching out to leaders in those fields we might establish working > > relationships and build, say, the next Boost.Tensorflow or something > > like that. I don't know. > > > > Oh, and add "cryptocurrency" to the list above. C++ is the language of > > blockchain, because performance matters. > > > > What do you think?...
answer 2: Library A depend on Library B. Some applications depend on library B. Library B is a very simple facility with a clearly defined purpose. That purpose is to permit programs and other libraries to write code which will work accross a variety of platforms. Now Library B is changed to add a bunch of new features and/or facilities. Library B now has a whole new purpose - to provide new features and facilities. How does this in any way benefit the users of the original version of library B? The are still using the library for the original purpose. This may or may not conflict with the new version of library B. Its claimed that the new version offers the original purpose. But this isn't obvious from looking at the code and/or documentation. The fact that the original version was maybe 30 lines and the new one is now 400 lines (at a minimum) and seems to depend on some new compile time switches, certainly suggests that that its not equivalent to the original version. When users complain that they to have time to re-visit all their old applications /libraries to verify that the new version is equivalent, users are library B are encouraged to study the documentation of the new version lf library B to discover what it does and how it will benefit them. It's unbelievable to me that this situation a) this even occured in the first place b) that this has persisted to this point. I don't know anything about the new exceptions library. How good is is or isn't, what it does, etc are not relevant. If you want to create a new throw exception with great new features that's just fine....
answer 3: > > > > What does this mean for C++ and Boost? I believe there is a > > significant opportunity for Boost to step in and become the rational > > collection of actually useful libraries that the C++ standard library > > is not. We already have networking, some protocols, and JSON. We (the > > existing Boost authors and contributors) might consider looking to the > > list above of industries that use C++, and focus our efforts more > > towards providing libraries that enhance those industries. Perhaps by > > reaching out to leaders in those fields we might establish working > > relationships and build, say, the next Boost.Tensorflow or something > > like that. I don't know. > > > > Oh, and add "cryptocurrency" to the list above. C++ is the language of > > blockchain, because performance matters. > > > > What do you think? > > > > Thanks > > > > Vinnie > > > > [1] <https://www.reddit.com/r/cpp/comments/u5vjni/comment/i54qbzq> > > > > [2] <https://docs.python-requests.org/en/latest/> > > > > [3] <https://www.reddit.com/r/cpp/comments/u6z8gr/comment/i5caxr6> > > > > [4] < > http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1860r0.html> > > > > _______________________________________________ > > Unsubscribe & other changes: > http://lists.boost.org/mailman/listinfo.cgi/boost > > _______________________________________________ > Unsubscribe & other changes: > http://lists.boost.org/mailman/listinfo.cgi/boost >...
answer 4: So you might think of my library as a way to detect violations in your rules. I don't see anything in the library which would have to be changed in order to serve your stated purpose. > And it would work for some time, until I start playing with bigger numbers: > > int main(){ > int8_t x = 100; > int y = x * x; > std::cout << y << std::endl; > > int z1 = 1000000000; > int z2 = 1000000000; > auto y2 = z1 * z2; // overflow > std::cout << y2 << std::endl; > > return 0; > } > > And at this point I need safe<int> well, feel free to use it! (or a BigInt). Which to me is an entirely different thing for a different purpose. The main purpose of the safe numeric library is to reconcile the conflict between what people expect when they see an arithmetic expression and what current computer languages actually do. BigInt - or John Maddox's multi-precision numerics address an entirely different concern. C++ doesn't support arbitrarily large numbers and those libraries do. You could say that all libraries also address the confict - but they do so in a very different way. So one or the other is a better choice depending on the purpose to which they are to be used. These libraries complement each other. Robert Ramey...
answer 5: Applying this metric, I would think that if both MQTT libraries > are useful then they should both be reviewed with the potential for > acceptance. Since C++11 C++ standard committee accepted a large number of Boost libraries - thus fulfilling the original purpose of boost. The question then arose - what should Boost do now? Most successful organizations confront this problem. No one who has invested significant effort in the original organization wants to just wind it down. So the search for a new purpose is undertaken. In many cases, no such new purpose is found and the organization just withers into irrelevancy (even though as an organization it could linger on forever - at least until the money runs out). If it's a for profit organization, it's just killed off by lack of investors and customers. This is one of the signature benefits of Capitalism. Boost has been flailing around since that time looking for a new mission. I'd suggest a mission statement like: "The purpose of Boost is to encourage the development of useful quality C++ software not expected to be part of the C++ standard." I think much of the current infrastructure we have - review process etc. is well suited to the above stated purpose. I have a number of reservations about our development support aspects - website, build, documentation, etc. etc. which I've stated previously. > > It really would be nice if there was some kind of documented rationale for > what libraries belong in Boost as this would eliminate the speculation and > guesswork. > > Thanks You're welcome....
answer 6: Manfred Doudar wrote: > The C++ BOOST Libraries are a series of free, peer-reviewed, STL compliant, > portable and thread-safe C++ libraries; That sounds a little too buzzwordy to my ear. What does 'STL compliant' actually mean ? Also, I don't think boost libraries are generally thread-safe, at least not in a general sense. I believe it would be best not to mention thread-safety in a short abstract, or else you'd have to detail the statement quite a bit to make it true. Regards, Stefan...
answer 7: question:What is Boost? a) A collection of libraries to make as many C++ programmers as possible more productive? b) A staging area for libraries which are aimed at being included in the standard library? c) An area for expermenting with and testing new ways of using C++ to exploit novel ideas in software developement like functional programming, DSELs, etc. (I know these aren't new ideas but implementing them within the compile time type system of a widely used language seems pretty novel to me) d) A collection of "facades" to permit one to write one program/algorithm which will efficiently run accross different combinations of OS's and compilers e) A vehicle for promoting C++ to a wider audience and promote quality software practices in general. f) Provide the "definitive" implementation of commonly required components. example shared_ptr. f) ... you're own view here. answer: yes! Do these goals conflict? Personally I don't think so - but a case could be made that they do at least in some cases. example: perhaps supporting portability encourages compiler vendors to postpon investment in compiler development. and of course f) would preclude the inclusion of multiple libraries which do the same thing. So I'm more of the view that we let stuff into boost as long at it meets quality standards. Then let users decide. I very much appreciate the documentation page which shows libraries grouped by functionality. This page isn't on the website (it should be!). I would like to see this page enhanced to include some more categories....
answer 8: That's blah-blah. Every library is supposed to provide something that is useful but missing and to take work out of programming. > "Essentially, Boost needs to sell itself as something that no C++ > programmer would want to be without. [stronger wording self-censored] This is nonsense. Boost does not need to sell itself or to be sold by anyone. People are free to use Boost libraries or not, at their own (or their boss') will. Think how the adman would write it: > "C++ getting you down? Spending hours tracking down that memory leak? > Then try Boost! It will change your life!" Well, maybe not, but > something along these lines would certainly go a long way to showing why > anyone should be using Boost. Frankly, you seem to be an evangelist (in the worst sense of that word) on a mission here. I strongly object to this attitude. Anything like that on any Boost web page would strongly discourage contributing to Boost, at least in my case. At the moment, the front page tells me is > that the libraries are free, portable, peer-reviewed and work well with > the C++ standard library, but that doesn't tell me why it is to anyone's > advantage to use them." This is very essential and useful information, though. It names a lot of advantages Boost has over many other libraries. Just consider the many expensive and/or restrictively licensed, non-portable libraries of questionable quality you have seen....
answer 9: On 5/20/24 8:28 AM, Vinnie Falco via Boost wrote: > On Sat, May 18, 2024 at 11:27 AM Robert Ramey via Boost < > boost@lists.boost.org> wrote: > > > I have similar thoughts as you and until this year I had my own ideas about > "what belongs in Boost." As there is no formal document or informal > exposition offered by the Boost Libraries project website I evolved my own > thinking as I am sure that others have done. > > However, upon discussions with high reputable sources (basically Peter > Dimov), the criteria for "what belongs in Boost" is that "a library is > useful." Applying this metric, I would think that if both MQTT libraries > are useful then they should both be reviewed with the potential for > acceptance. Since C++11 C++ standard committee accepted a large number of Boost libraries - thus fulfilling the original purpose of boost. The question then arose - what should Boost do now? Most successful organizations confront this problem. No one who has invested significant effort in the original organization wants to just wind it down. So the search for a new purpose is undertaken. In many cases, no such new purpose is found and the organization just withers into irrelevancy (even though as an organization it could linger on forever - at least until the money runs out). If it's a for profit organization, it's just killed off by lack of investors and customers. This is one of the signature benefits of Capitalism....
answer 10: The name "Boost" carries with it a certain standard of excellence, quality of implementation, and ubiquity. As a result, it is often much more feasible to use a library in a project/team/company if it's part of Boost than if it isn't. Case in point: at my company, we use Boost extensively, but management is very hesitant to introduce a dependency on other libraries, especially if the library "merely" makes coding in general more convenient, rather than providing some domain-specific features or API. I think the situation is similar in many other companies and projects. For this reason, I think libraries whose purpose is to make general-purpose coding more convenient, rather than some domain-specific use, are especially appropriate for inclusion in Boost. > > - Recall that Boost has several (recent) libraries that could easily be > > labelled as "transitional" libraries: Move, Atomic (at least proposed, not > > sure if accepted), Container. Further, several older libraries are now > > part of the C++11 standard (e.g., Thread (right?)). > > > > I would think though that these transitional libraries would be > deprecated as soon as the standard counterparts become ubiquitous....
answer 11: Yeah, I suppose macros are a matter of taste. I've had similar problems with similar uses of macros as what you mention. An alternative is something like #define THIS add #define THAT + #include <template_file_that_uses_this_and_that> , which preserves line numbers of readable code and is a little more debugging friendly. In your case, I think it even might be possible to use the preprocessor library to define sequence of function names and operators, and iterate over the same file that just pops a pair of function name and operator from the sequence into their implementation. But I've never tried anything like that so I'm not sure. > I think that I have a better understanding of what you are looking for but > let me get the following out of the way: > > I'm not sure that a general purpose container is the best use for this > class. cvalarray is meant to mimic the semantics and purpose of > std::valarray. Which is specifically designed for numeric values. I think > that if the purpose is general, then so should the interface, ie not mimic > std::valarray. One could claim that the incorrect use of boost::array and > by implication a general-purpose cvalarray is not our problem but IMHO, > libraries should be easy to use correctly and hard to use incorrectly. After looking into what you're doing, and what could be done in the general case, I agree with you 100%. I didn't realize that you were limited by adopting the requirements for valarray. Out of curiosity, why "incorrect use of boost::array"?...
answer 12: Boost provides a collection of C++ libraries that improve the utility and portability of C++. Boost uses a highly collaborative, peer-reviewed development process. Boost libraries are completely free for any use, and are thoroughly tested on several platforms. "We emphasize libraries that work..." (possibly make further edits to existing passage) > * When you download Boost, you get the whole collection > > * There are some dependencies among libraries, but they are not > tightly coupled > > * There is a tool (bcp) for extracting the parts you want and their > dependencies. > > * Many boost libraries can be used just by putting the library > collection's top directory in your #include path. Complete > instructions for getting started are at: ___ > > * The important features of the Boost directory structure are: > - boost > - libs > - more > - tools > (with rough descriptions of each) Perhaps this could be added under the "Getting started:" subheading? That is, unless it would make that section too long. The current page is nicely formatted into digestible chucks -- I would be wary of breaking up the visual flow. -Andy...
answer 13: Can someone > please clarify how BOOST_NO_EXCEPTIONS has changed, Just look higher in the the thread for Emil's definition of BOOST_NO_EXCEPTIONS. This is different than the one in the documentation which has never changed and in fact is part of another library. This situation has lead to much confusion as to what this macro means as noted higher in the thread. >what specific > change Robert (and possibly others) find troubling, and what > practical consequences this has had or presently has? Well, it's left me confused about what it's supposed to be. > Ditto for boost::throw_exception. Ahhh - a somewhat different case. boost throw exception as implemented in a very simple way for a very simple purpose. That purpose was to provide and escape to a global function which one could implement for those platoforms which failed to implement exceptions. This is not so uncommon for embedded systems and some shops which prohibit usage of exceptions. The function of this was changed with the inclusion of boost.exception which altered the purpose and implementation of boost::exception in include the functionality of boost.exeption. You should be able to guess what happened. All the librarires which has presumed the original operation started to have changed behavior. Longer build time, dependence on a new library, new requirement that the library be only used with rtti turned on. For some unfathonable reason, the change in boost::throw_exception was allowed to stand. So these libraries including serialization, boost.filesystem, and some others had to creat their own macros to implement the behavior of the original boost::throw_exception....
answer 14: cvalarray is meant to mimic the semantics and purpose of > std::valarray. Which is specifically designed for numeric values. I think > that if the purpose is general, then so should the interface, ie not mimic > std::valarray. One could claim that the incorrect use of boost::array and > by implication a general-purpose cvalarray is not our problem but IMHO, > libraries should be easy to use correctly and hard to use incorrectly. After looking into what you're doing, and what could be done in the general case, I agree with you 100%. I didn't realize that you were limited by adopting the requirements for valarray. Out of curiosity, why "incorrect use of boost::array"? > Additionally, the next step for cvalarray here is for it to automatically > use SIMD instructions to further speed up the numeric operations. Again > making its use general purpose will unnecessarily complicate things. Actually, I stuck the std::string bit into the code I sent you just to see if it would work :-). I'm not really vested into elementwise concatenation of strings personally. > On a side and somewhat historical note, if cvalarray morphs into anything > else, one of the issues here for the adoption is the adding dependancies. > Currently, the libraries is one file, self-contained, and does not rely > on anything outside of the language. That is very important in many > peoples view....
answer 15: > If you tell me that's up to the network library > asynchronous I/O provided by the network library will be used > differently than what eg. > an asynchronicity library might provide. The challenge of an asynchronous I/O library is to provide a general enough interface to allow other more specific libraries to use it for their own specific asynchronous I/O purposes, else there is little purpose in creating it. > And I am only talking about > the interface not about the implementation. The nice thing in .NET is > that asynchronous operations look everywhere the same no matter if > you are in the network library or somewhere else. I agree, looking very much the same but allowing both the end-programmer, and the particularly implementation of asynchronous callback functionality, to pass different data to an asynchronous callback, and also using the results of data picked up by the callback in different ways depending on the implementation. I think we are mostly agreeing. My original appeal is that building a general purpose asynchronous I/O library around Boost threads and Boost function seems feasible, since the equivalent concepts have already been shown to work in another environment, and might save a great deal of trouble from trying to re-invent the code from scratch all over again. On top of that general purpose asynchronous I/O library other implementors which need asynchronous I/O in their particular libraries can build whatever elaborate schemes they want....
- **avg_similarity**: 0.5314
- **max_similarity**: 0.6835
- **num_results**: 15
- **time_seconds**: 0.6279

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.6312701106071472 |
| 2 | None | None | 0.27831727266311646 |
| 3 | None | None | 0.6023432612419128 |
| 4 | None | None | 0.40312084555625916 |
| 5 | None | None | 0.4564158022403717 |
| 6 | None | None | 0.6388310790061951 |
| 7 | None | None | 0.6369738578796387 |
| 8 | None | None | 0.6834821105003357 |
| 9 | None | None | 0.5684854388237 |
| 10 | None | None | 0.588875949382782 |
| 11 | None | None | 0.42356058955192566 |
| 12 | None | None | 0.659902036190033 |
| 13 | None | None | 0.4156387448310852 |
| 14 | None | None | 0.5551742315292358 |
| 15 | None | None | 0.42912834882736206 |

## 2. Question

- **question**: How do I install Boost on Linux?
- **ground_truth**: On Linux, Boost can be installed via a package manager like `apt` (on Ubuntu) by running `sudo apt-get install libboost-all-dev`. Alternatively, you can download and compile it from source by following the instructions on the Boost website.
- **rag_answer**: answer 1: Hi Friends, I am trying to use Bayer++ classes for Kalman filter But before that I have to install boost c++ library. My fisrt effort was not successful. Can anyone tell me how to install it in Redhat Linux-8? I need step by step with best bug free versions Thanks a lot Sena Seneviratene Computer Engineering Lab Sydney University Australia...
answer 2: > > GROUP ( /usr/lib/x86_64-linux-gnu/libc++.so.1 > /usr/lib/x86_64-linux-gnu/libstdc++.so.6 ) > > First entry is as the symbolic link was, the second one is added afterwards > to add the ABI from libstdc++. > > Thanks to David Chisnall for his post here > http://clang-developers.42468.n3.nabble.com/Making-libc-on-Linux-user-friendly-td4038688.html Here is the output as you requested (thanks for showing me how): fe@BLD01:~/frontend/build$ clang++ -v Ubuntu clang version 3.4-1ubuntu3~precise2 (tags/RELEASE_34/final) (based on LLVM 3.4) Target: x86_64-pc-linux-gnu Thread model: posix Found candidate GCC installation: /usr/bin/../lib/gcc/i686-linux-gnu/4.6 Found candidate GCC installation: /usr/bin/../lib/gcc/i686-linux-gnu/4.6.3 Found candidate GCC installation: /usr/bin/../lib/gcc/x86_64-linux-gnu/4.6 Found candidate GCC installation: /usr/bin/../lib/gcc/x86_64-linux-gnu/4.6.3 Found candidate GCC installation: /usr/lib/gcc/i686-linux-gnu/4.6 Found candidate GCC installation: /usr/lib/gcc/i686-linux-gnu/4.6.3 Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.6 Found candidate GCC installation: /usr/lib/gcc/x86_64-linux-gnu/4.6.3 Selected GCC installation: /usr/bin/../lib/gcc/x86_64-linux-gnu/4.6...
answer 3: Hello I am new to boost. In my RHEL linux (no root permission), my program does not find boost installation and says: *** Please install package libboost-filesystem to /home/myself/folder *** Please install package libboost-system to /home/myself/folder I installed latest boost using these instructions<http://www.boost.org/doc/libs/1_42_0/more/getting_started/unix-variants.html#id27> . ./bootstrap.sh ----with-libraries=filesystem,system --prefix=/home/myself/folder ./bjam install Can you tell, what is wrong I am doing and anything to add in include path etc. My paths: echo $LD_LIBRARY_PATH /home/myself/folder/lib:/home/myself/ddrive/test/boost_1_49_0/stage/lib echo $CPLUS_INCLUDE_PATH /home/myself/folder/include/ My program has makefile: LD_LIBS += -lboost_filesystem -lboost_system (and others) Thanks and Regards Sparsh Mittal...
answer 4: Hi Matthieu, Thanks for ur help.. just one last question I have extracted only the thread part in a folder and I am going to use only thread in my application.. Is it possible just to copy the thread folder and then install only the thread part through bjam.. or is it that I have to install the entire boost library in linux box and then use the threading part.... please do let me know if there any possible solutions.... Regards AYAN. On 3/15/09, Matthieu Brucher <matthieu.brucher@gmail.com> wrote: > > - Get bjam > - Compile bjam and install it > - in Boost folder, do: > bjam --prefix=/where/you/want/ install > or if you install it in the standard folders: > bjam install > > Done. > > Matthieu > > 2009/3/15 ayan sinha <ayansinhas@gmail.com>: > > Hi, > > I am new to linux and also to boost library.. I am planning to > install > > boost library in linux box (which is a production machine with no net > > connectivity). i have already got the linux version of boost in that > machine > > and now I am planning to install it. Can please somebody tell me what are > > the steps needs to be done to install linux.. with commands (I cant use > any > > tool that boost provide to install because ther is no net connectivity in > > that box)....
answer 5: Hi, I am new to linux and also to boost library.. I am planning to install boost library in linux box (which is a production machine with no net connectivity). i have already got the linux version of boost in that machine and now I am planning to install it. Can please somebody tell me what are the steps needs to be done to install linux.. with commands (I cant use any tool that boost provide to install because ther is no net connectivity in that box). I have gone through the boost website .. but it looks very complicated :) also I have gone through couple of websites but it was not much usefull. I will be really greatfull if somebody can tell me what are the steps (with commands) to install in linux box. Thanks in Advance, Ayan....
answer 6: Hello, I downloaded boost today so regard me as a newbie. Boost seems great, but the documentation doesn't mention how I should install boost on my system (redhat 9), and how to link against the built libraries. Sure I can include it in every project (though it's huge!), and make the makefiles link into strange locations such as libs/test/build/bin/libboost_unit_test_framework.a/gcc/debug/runtime-link-static/threading-single/libboost_unit_test_framework.a Is there an easier way? Why aren't packages like boost-[devel-]VERSION.PLATFORM.rpm made? Why aren't all built libraries put in the same directory, with a simple path name? Why isn't the thread library built statically? Is putting a "lib" section with BOOST_THREAD_BUILD_STATIC=1 in the Jamfile a legal fix? (seems to work) Also... I think boost should have a network library. Can anyone recommend a platform-independent network library? I'm thankful for any answer... -- Cheers, Tom Weber http://www.dd.chalmers.se/~np98towe/...
answer 7: hi all, i am trying to install boost library on dev cpp but not able to do it as i am new to boost so please give me step by step procedure to install it on dev cpp i am trying from last 5 days thanx...
answer 8: $cd /Boost1.36.0 4. $ ./bjam --build-dir=/build-boost --toolset=gcc --build-type=complete stage So, the Boost Library is installed, I think.... But, I do not know how can I use this. When I install with simple way, there are only 2 directory - include and lib, but using ./bjam there are lots of directories /boost/bin.v2/libs/..... Do I have to assign each path separately? Thanks, On Sat, Jan 23, 2010 at 2:53 PM, Ravi <lists_ravi@lavabit.com> wrote: > On Thursday 21 January 2010 15:46:13 JongKwan Kim wrote: > > I would like to know if the boost 1.36.0 is working well with Linux 64 > > bits. > > Yes, but using 1.42 (to be released in a few days) will likely save you > headaches in the future since there have a been a large number of bug-fixes > since 1.36. > > > If I want to compile with boost 1.36.0 and Linux 64 bits, how should > > I install the boost 1.36.0?...
answer 9: If nothing else, having it serve as a model to Linux distributors would be great, too. I have attached an updated version of that spec file that I feel is an improvement to the earlier version. The philosophy behind this new spec file is to be as true as possible to what I understand to be a "normal" Boost installation. I realize that users are afforded many ways to customize their Boost installation through different build-time options. Without doing any build customization, however, a Boost installation has single- and multi-threaded variants of libraries, both static and dynamic, that are named based on the toolset used for building and the Boost version number. Furthermore, the headers are installed in a versioned subdirectory. All of this allows parallel installations of different Boost build variants, and I see that as an extremely powerful capability. The attached RPM spec file leverages that in a way that I see as being very valuable. Relative to the Boost RPM distributed for use on Red Hat distributions of Linux (I do not have experience with pre-packaged versions of Boost from other Linux distribution vendors, so I cannot comment on how they do things), this RPM spec file has the following benefits: * Allows parallel installations of multiple Boost releases (both the run-time RPM and the developer RPM) * Installs single- and multi-threaded builds of libraries The spec file that Red Hat uses for building Boost RPMs removes the toolset name and the version information from the base name of the library, and it only installs the single-threaded build of each library....
answer 10: On Wednesday 21 July 2004 3:36 am, sena wrote: > Hi Friends, > > I am trying to use Bayer++ classes for Kalman filter > > > But before that I have to install boost c++ library. > > My fisrt effort was not successful. > > > Can anyone tell me how to install it in Redhat Linux-8? Which Boost libraries do you need? For most libraries, installation is as simple as "tar zxvf boost-tarball-name.tgz". Doug...
answer 11: Robert Ramey wrote: > Why would anyone want to use this? and for what? It's a Linux thing. On Linux, you do apt-get install boost and you get a pre-built Boost release (1.55.0, for example, for the current Debian/Ubuntu distributions) automatically downloaded and installed into the system header and library locations. So if you then want to upgrade just Boost.Python, you could in theory download a standalone Boost.Python release and build it with the system-installed Boost.Build, against the system-installed dependencies such as Boost.SmartPtr. On Windows (and, I suppose, OS X), there's no such system-supplied Boost, so the above doesn't apply and Windows people don't see a point, in a similar manner to how Linux people can't see the point of bpm....
answer 12: Somehow I failed > installing it (WinXP, VC6). Is there a step by step > instruction to get boost running under this configuration? > The steps I took so far: > 1) Set the MSDevDir and MSVCDir EnvVars by hand. > 2) Compiled BJam and copied it to the boost root. > 3) Execute bjam "-sTOOLS msvc" install > 4) Set the path for include files and libraries in > Tools->Options->Directories to the folder I unzipped Boost to. > > Got the following error messages while trying to compile a > simple regex example :( > > Thanks in advance, > Thomas > > --------------------Configuration: trwetst - Win32 > Release-------------------- > Compiling... > trwetst.cpp > C:\BOOST\boost/regex/v4/perl_matcher_common.hpp(129) : error C2664: > '__thiscall boost::re_detail::concrete_protected_call<class > boost::re_detail::perl_matcher<char const *,class > std::allocator<struct boost::sub_match<char const *> >,struct > boost::re gex_traits<char,class boost::w32_regex_traits<char> > > > >::boost::re_detail::concrete_protected_call<class > boost::re_detail::perl_matcher<char const *,class > std::allocator<struct boost::sub_match<char const *> >,struct > boost::regex_traits<char,class > boost::w32_regex_traits<char> > > >(class > boost::re_detail::perl_matcher<char const *,class > std::allocator<struct boost::sub_match<char const *> >,struct > boost::regex_traits<char,class boost::w32_regex_traits<char> > > > *,...
answer 13: Abdelmorhit El Rhazi wrote: > Thanks guys. > Please find my answers to your questions : > > 1- Possibly he's using a 1.33.1 release on Windows and a CVS version on Linux > -->I connect to a remote machine in which I do not have admin right. So, I used > the default boost library. I did not download and install the newest version of > boost. May be this is the cause. If you think so, how can I verify the version > that are this machine. Any idea. > 2- What is gcc -v saying? > ----> Here is the display of that command: > Reading specs from /usr/lib/gcc-lib/i386-redhat-linux/3.3.2/specs > Configured with: ../configure --prefix=/usr --mandir=/usr/share/man > --infodir=/usr/share/info --enable-shared --enable-threads=posix > --disable-checking --with-system-zlib --enable-__cxa_atexit > --host=i386-redhat-linux > Thread model: posix > gcc version 3.3.2 20031022 (Red Hat Linux 3.3.2-1) > > 3- That this error didn't become apparent und VC++ might have been caused > by some compiler settings (precompiled headers, maybe?). > > ---> What do you mean ? > > Abdel. GCC 3.3.2 is ancient. You do not have to be an admin to install gcc to your home. Install a newer version....
answer 14: Why don't you use boost installer? It will download and install all required libs, headers and sources: http://www.boost-consulting.com/download.html You will only need to set correct path to boost libs in VC8. With Kind Regards, Ovanes Markarian On Thu, June 8, 2006 19:41, Hemal patel wrote: > Hi! Jan, > > I tried the one you have suggested, and I get message like , > vc80-tools.jam: NO such file or directory. > > Yes, I did visit http://boost.org/tools/build/v1/vc-8_0-tools.html and > followed all the insturctions for vcvars32.bat and > other tips, but it did not work. > > > I also tried.. > bjam -sTOOLS=msvc --v2 > > but it does not generate libs in C:\BOOST\. > > > I wonder, if I'm not executing bjam from right location, I use BOOST ROOT > DIRECTORY to execute bjam for complete installation. > > > For individual library like regex, I 'm able to compile from its source > using its make file. > but I can not compile library like program_options from its source file as > there is no make file available. > since regex is dependent of program_options, I'm stuck > > pl comment . > > Thanks for your time....
answer 15: Why not just install the ubuntu boost library packages? They seem to be available for ubunut... Jeffrey Holle wrote: > To get boost you can use either, not both. > Your Linux doesn't use rpms if its debian based, so use the tar ball > (boost_1_33_1.tar.gz) and unpack it with "tar -xzf boost_1_33_1.tar.gz". > > Umut Tabak wrote: > >>Hi everbody, >> >>I am trying to install boost and posted a message and got the reply >> >>Download >>"boost-jam-3.1.11-1.i386.rpm" >>and >>"boost_1_33_1.tar.gz" >>from >> http://sourceforge.net/project/showfiles.php?group_id=7586 >> >>#rpm -ivh /path/boost-jam-3.1.11-1.i386.rpm >>#mv /path/boost_1_33_1.tar.gz /usr/local/src/ >>#cd /usr/local/src >>#tar -zxvf boost_1_33_1.tar.gz >>#cd /usr/local/src/boost_1_33_1/tools/build/jam_src/ >>#./build.sh >>#cp bin.linuxx86/bjam ../../../ >>#cd ../../../ >>#./bjam "-sTOOLS=gcc" install >> >>but the very first command rpm gives a conflict message with Debian >>files since I am using Ubuntu which is based on Debian or am I wrong? >> >>Any comments will be appreciated....
- **avg_similarity**: 0.5622
- **max_similarity**: 0.6985
- **num_results**: 15
- **time_seconds**: 0.4339

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.5742856860160828 |
| 2 | None | None | 0.30755794048309326 |
| 3 | None | None | 0.5642342567443848 |
| 4 | None | None | 0.5141855478286743 |
| 5 | None | None | 0.6755306124687195 |
| 6 | None | None | 0.6733612418174744 |
| 7 | None | None | 0.6984855532646179 |
| 8 | None | None | 0.587691605091095 |
| 9 | None | None | 0.4859912097454071 |
| 10 | None | None | 0.6132276058197021 |
| 11 | None | None | 0.6345941424369812 |
| 12 | None | None | 0.4861060678958893 |
| 13 | None | None | 0.45109888911247253 |
| 14 | None | None | 0.5190415382385254 |
| 15 | None | None | 0.6471965909004211 |

## 3. Question

- **question**: What is Boost.Asio used for in C++?
- **ground_truth**: Boost.Asio is a library for asynchronous I/O operations. It is commonly used for network programming, including creating servers, clients, and handling I/O operations without blocking the main execution flow.
- **rag_answer**: answer 1: > > - What does asio use on windows? Is that also scalable > > to 20,000 socket descriptors, like epoll and kqueue are? > > It uses IO completion ports. I'm afraid I don't recall any numbers, but > certainly they scale to the thousands. I believe Microsoft pushes them > as the most scalable way to write servers on Windows. Can someone explain to me how it is possible that libACE doesn't use IO completion ports by default?! (Or at all) :) Anyway - I am glad to hear that. Next question that comes to mind: is asio creating any threads itself in order to achieve its normal functionality (on windows)? I am still reading your documentation, but I already have the following questions / remarks that I'd like you reaction on: - The timer resolution of 1 second is too low (see below). Would you be willing to revise/change that part of the interface? [ A resolution of 1 second means that you can request 1 second and get 0 seconds (ie, you call now() 1 microsecond before it would return the next integer, add 1 and request the time out with that). A better timer interface, one that I use myself in my networking library, is to always work with "times" as offsets relative to a function returning 'now()'. The value returned by 'now()' should not change in between calls to the system function that actually waits for events (it is only updated once per mainloop loop thus)....
answer 2: - What is your evaluation of the design? The design looks quite good. There are some points I don't realy like, e.g. that there are no high level classes. The use for _simple_ network workings is too complex. It seems as if the instance user needs too much knowledge to start with asio. - What is your evaluation of the documentation? For a first release in boost it's good. But for the future there should be some more informations for network beginners like me. The first five tutorials shows how complex the library is because the examples have nothing to do with networking. It's realy strange and discourage for a beginner to use asio if he want to start with it. Although the tutorials are understandable. - What is your evaluation of the potential usefulness of the library? The asio library is very usefull and mainly _necessary_ for the C++ community. boost is the right organisation to push a network lib and to improve asio. For the future it's important to make asio more interesting for network beginners and simple network working. I think asio is a realy good base. - Did you try to use the library? With what compiler? Did you have any problems? I tried asio with the tutorial examples. I used it with VC++7.1 and everyting worked well. It looks like there is a mistake in the asio introduction, that said that you need only the headers of boost. But with the asio tutorials with the timers you need to build the boost.date_time library....
answer 3: <p>Source URL: https://www.boost.org/doc/libs/latest/doc/html/boost_asio.html</p> <p>Boost.Asio</p> <h2>Boost.Asio</h2> <h3>Christopher Kohlhoff</h3> <p>Copyright Â© 2003-2025 Christopher M. Kohlhoff</p> <p>Distributed under the Boost Software License, Version 1.0. (See accompanying file LICENSE_1_0.txt or copy at http://www.boost.org/LICENSE_1_0.txt)</p> <p>Boost.Asio is a cross-platform C++ library for network and low-level I/O programming that provides developers with a consistent asynchronous model using a modern C++ approach.</p> <p>Overview : An overview of the features included in Boost.Asio, plus rationale and design information.</p> <p>Using, Building, and Configuring Boost.Asio : How to use Boost.Asio in your applications. Includes information on library dependencies and supported platforms.</p> <p>Tutorial : A tutorial that introduces the fundamental concepts required to use Boost.Asio, and shows how to use Boost.Asio to develop simple client and server programs.</p> <p>Examples : Examples that illustrate the use of Boost.Asio in more complex applications.</p> <p>Reference : Detailed class and function reference.</p> <p>Networking TS Compatibility : Description of changes to provide compatibility with the "C++ Extensions for Networking" Technical Specification.</p> <p>Proposed Standard Executors : Description of Boost.Asio's support for the proposed standard executors library.</p> <p>Revision History : Log of Boost.Asio changes made in each Boost release.</p> <p>Index : Book-style text index of Boost.Asio documentation.</p> <p>---Boost.Asio</p>...
answer 4: James McCartney <asynth@io.com> wrote: >> The ASIO SDK is a C++ library. You can download it from here: >> http://www.steinberg.de/329_0.html > > ...after you click through the page where it says: "ASIO is a > trademark and software of Steinberg Media Technologies GmbH" ^^^^^^^^^ that's a genuine problem, but it's arguable if "boost.asio" qualifies as trademark violation. B....
answer 5: Boost.Asio is a headers-only library which makes use of Boost's 'system' library. Since the 'system' library has been ported to Windows Runtime (aka WinRT) by Steven Gates of Microsoft, I assumed that Boost.Asio should therefore work as-is for WinRT. When I wrote to Steven asking him to verify that Boost.Asio will work today for WinRT he answered: <quote> "I don't know if Boost.Asio works with the Windows Runtime. I would guess it doesn't entirely, but since it is a header file only library it might work depending on the features used. My recommendation would be to run the Windows App Cert Kit and if you didn't pull in any banned APIs then you might be good. When I look in the history of the Boost.Asio Github repository I can see the maintainer at least started some work for the Windows Runtime. I recommend you reach out to him or post of the Boost mailing forums to see." </quote> Can the Boost.Asio maintainer, or anyone else, verify if Boost.Asio can be built as-is for WinRT, or does it need to be ported? Thanks in advance, Moshe Rubin...
answer 6: Hi list, I am wondering about boost.asio. Boost.asio must have a proactor implementation on Linux, I guess. How does the proactor of boost.asio work? Does it use epoll? Is it edge-triggered? What about real-time signal? Doesn't boost.asio use real-time signal on Linux? What is the recommended implementation of boost.asio for asynchronous and non-blocking overlapped IO on Linux? Thank you in advance! ---------------------------------------- Journeyer J. Joh o o s a p r o g r a m m e r a t g m a i l d o t c o m ----------------------------------------...
answer 7: <p>Source URL: https://www.boost.org/doc/libs/latest/doc/html/boost_asio/overview/basics.html</p> <p>Basic Boost.Asio Anatomy</p> <h3>Basic Boost.Asio Anatomy</h3> <p>Boost.Asio may be used to perform both synchronous and asynchronous operations on I/O objects such as sockets. Before using Boost.Asio it may be useful to get a conceptual picture of the various parts of Boost.Asio, your program, and how they work together.</p> <p>As an introductory example, let's consider what happens when you perform a connect operation on a socket. We shall start by examining synchronous operations.</p> <p><strong>Your program</strong> will have at least one <strong>I/O execution context</strong>, such as an <code>boost::asio::io_context</code> object, <code>boost::asio::thread_pool</code> object, or <code>boost::asio::system_context</code>....
answer 8: >> Standalone ASIO is much more popular than Boost.ASIO > > What do you base this statement on? Back when I did the research for my C++ Now talk on the future of Boost, I did a search of open source projects #including "asio/asio" as against "boost/asio". The "asio/asio" ones outnumbered "boost/asio" by approx 50% if I remember rightly. I am subscribed to asio questions on stackoverflow, and there is a noticeable pattern that people with beginner level questions use boost.asio, whereas the tricky questions they are using standalone asio. That suggests the serious users of ASIO use the standalone edition. Finally, a quick google search of "boost.asio vs standalone asio" reveals most of the top results recommend using standalone asio if you have C++ 11 or better. The most common reason given is "because it is truly header only and it doesn't drag in Boost". Niall -- ned Productions Limited Consulting http://www.nedproductions.biz/ http://ie.linkedin.com/in/nialldouglas/...
answer 9: So, yes, the handle can be copied in the same way you can copy a *pointer* to a asio::stream_socket. The fact that boost::stream_socket is itself implemented using a non aliased handle to a socket is an implementation and transport specific detail. Conceptually a stream_socket behaves as a reference to the underlying stream. This means that if you want to share a asio::stream_socket you usually have do dynamically allocate it. And btw system sockets cannot be copied. For example, you can open a file two times or you can dup() a socket, but the new handle refers always to the underlying resource. > > My point is that it shouldnt be needed to use dynamic allocation to > use a socket. Even if you need to share it. > > [snip] > > >>Yes what? Always what? Are you talking about always needing dynamic >>allocation? Definitely not. I've written code that uses asio >>stream_sockets without using dynamic allocation nor moving nor sharing >>ownership. > > > If you could show me maybe it could explain a lot of what you mean. > Can you show me any code and what is its use case? > Well, my code is not actually the expected way to use asio. I'm using a coroutine library tightly coupled with asio. asio_sockets are allocated on the stack and are and callbacks simply resume the coroutine that queued a call to an asio asynch function. You can find some experimental code in the boost vault under concurrency....
answer 10: On Fri, 11 Feb 2011 08:07:34 +0100, Artyom <artyomtnk@yahoo.com> wrote: > [...]asio is very well designed asynchrous event loop that IMHO > should be used for any asynchronous operations as it allows > to do in "async" way almost any task. This was exactly what I always thought, too. Now I believe that I made the classic mistake of seeing everywhere nails because of the Boost.Asio hammer. As much as I like Boost.Asio I don't think anymore that we should try to integrate everything in Boost.Asio just because we managed to add the word "asynchronous" to the description of a feature. There are certain requirements, and if they are not met I think Boost.Asio is the wrong answer. Boost.Asio is based on I/O service objects which provide services to I/O objects. If we create a singleton outside of I/O service objects what's their purpose? We don't need them anymore. We could use the singleton directly. That's what Dmitry Goncharov had proposed with his signal_handler. Or let's imagine Boost.Asio wouldn't exist and we would think about a signal handler. Everyone would probably agree that we need a singleton. But would anyone argue that we also need an I/O service object and an I/O object? Given the easy to use Boost.Asio API some developers would still prefer to use it. And it could all still be built on top of such a singleton....
answer 11: Change the definition of `const_buffer` to include conversion constructors that can accept a more general concept, such as any class which implements data() and size(). If I was to re-implement Beast's buffer adapters, dynamic buffers, parser, and serializer to use these ideas then they would no longer be compatible with Asio. Using them would be more cumbersome and less composable with other standard components which use Asio buffer concepts. Feedback from users is that they overwhelmingly prefer solutions that work out of the box over adherance to some model of buffer abstraction. I have no control over what happens in Boost.Asio and I do not control the evolution of the Networking TS although I have filed some additional issues against it. For better or worse, Boost.Asio is the model that we have and what people are coding against. Therefore, as with Beast my design choice here is pragmatic - use what exists, and what works. The approach offered in Boost.Buffers allows libraries to be written which do not depend on all of Boost.Asio, but yet offer compatibility with Asio's buffer concepts....
answer 12: Hi James --- James McCartney <asynth@io.com> wrote: > > The ASIO SDK is a C++ library. You can download it from here: > > http://www.steinberg.de/329_0.html That page refers to it as the "ASIO specification". That this "protocol" or "specification" has an SDK does not make ASIO itself a library. > ...after you click through the page where it says: "ASIO is a > trademark and software of Steinberg Media Technologies GmbH" I searched the US, UK, EU, Australian and International (Madrid) trademark databases. The only hit was for "ASiO" in the international database, and it relates to "Cleaning units for communal and industrial waste water...". In any case, Boost.Asio as a name should be unambiguously different on all counts. Cheers, Chris...
answer 13: What I changed was: - Created a class static member to be returned by the null() function. Returning a new object each time was a bit of a pessimisation, I admit :) - Explicitly initialised the services socket_acceptor_service and stream_socket_service. Normally these are initialised on the first use of a socket_acceptor or stream_socket respectively. I made this change to the example to make it clearer what the per-object cost is. - Only initialise the reactor implementation on the first use of asynchronous connect emulation (it's not used in this program). ------------------------------ int main() { try { //--> 4 calls to new. asio::demuxer demuxer; //--> 4 calls to new. demuxer.get_service(asio::service_factory< asio::socket_acceptor_service<> >()); //--> 2 calls to new. demuxer.get_service(asio::service_factory< asio::stream_socket_service<> >()); //--> 2 calls to new associated with socket in shared_ptr. asio::socket_acceptor acceptor(demuxer, asio::ipv4::tcp::endpoint(13)); //--> 1 call to new (the explicit new shown here). asio::stream_socket* socket = new asio::stream_socket(demuxer); //--> 1 call to new for OVERLAPPED-derived object. acceptor.async_accept(*socket, boost::bind(handle_accept, &acceptor, socket, asio::placeholders::error)); //--> 2 calls to new when accepting new connection and // underlying socket in shared_ptr is created....
answer 14: I'm trying to write a simple ASIO send/receiver that uses message queueing. The goal is to have a number of virtual streams over a single TCP connection. This is pretty simple using callbacks, but I can't figure out the coroutines alternative. Here is my simplified sample code. Note that I'm using asio::experimental::promise the same way I would use std::promise which obviously doesn't work, but it illustrates what I'm trying to do. What is the simplest solution to my problem? #pragma once #include "asio.hpp" #include "asio/co_spawn.hpp" #include "asio/detached.hpp" #include "asio/experimental/co_composed.hpp" #include "asio/experimental/promise.hpp" #include "asio/use_awaitable.hpp" #include <coroutine> #include <cstdint> #include <map> #include <memory> #include <queue> struct Message { uint64_t id; uint64_t streamId; uint64_t priority; }; class NetworkConnection { public: NetworkConnection(asio::io_context &ioContext) : ioContext_(ioContext), sendTimer_(ioContext_), receiveTimer_(ioContext_){}; asio::awaitable<std::unique_ptr<Message>> receive(uint64_t streamId) { auto promise = std::make_shared< asio::experimental::promise<std::unique_ptr<Message>>>(); auto future = promise->get_future(); receives_[streamId] = promise;...
answer 15: I've been reading over the documentation for Boost.Asio and as far as I can tell the documentation makes no mention whatsoever about using Asio for anything other than sockets programming. Suppose I wanted to implemented a simple file transfer client (I say client because the server will not be in C++) that reads files off of the disk and sends them to the server. I'd like to do it asynchronously. What would be the basic steps needed to do this with Boost.Asio, if it is indeed even possible? I'd specifically like it to use I/O Completion Ports on Windows if possible, and whatever on Linux. I'd like to be able to configure the number of worker threads on the backend, so that for example I can read from N files at once, or from N different locations in the same file. I'd also like to have a single "controller" thread that receives all the events regarding when reads or writes complete, so that I don't have to use any kind of locking to synchronize things. As a final "nice-to-have", I'd like to be able to plug my own types of "actions" into the model, things that aren't really I/O but that I still want to execute asynchronously that would sit in between a completed disk read and the initiation of writing that same data to the socket. Think, for example, of encrypting the file before sending. I don't want to block on the encryption, so it would be nice if I could do that asynchronously and still be notified of its completion through the same interface....
- **avg_similarity**: 0.6529
- **max_similarity**: 0.8791
- **num_results**: 15
- **time_seconds**: 0.4509

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.6431430578231812 |
| 2 | None | None | 0.6254580616950989 |
| 3 | None | None | 0.8791257739067078 |
| 4 | None | None | 0.6865593194961548 |
| 5 | None | None | 0.5491169691085815 |
| 6 | None | None | 0.746239185333252 |
| 7 | None | None | 0.7825963497161865 |
| 8 | None | None | 0.7490221858024597 |
| 9 | None | None | 0.5519395470619202 |
| 10 | None | None | 0.7629703879356384 |
| 11 | None | None | 0.5961405634880066 |
| 12 | None | None | 0.6052587032318115 |
| 13 | None | None | 0.42238590121269226 |
| 14 | None | None | 0.44632840156555176 |
| 15 | None | None | 0.7470259070396423 |

## 4. Question

- **question**: How can I list all files in a directory using Boost.Filesystem?
- **ground_truth**: You can use `boost::filesystem::directory_iterator` to iterate through files in a directory. Example:
```cpp
boost::filesystem::path p("mydir");
for (boost::filesystem::directory_iterator itr(p); itr != boost::filesystem::directory_iterator(); ++itr)
    std::cout << itr->path() << std::endl;
```
- **rag_answer**: answer 1: Martin wrote: > I have used the filesystem library for some time now and noticed that > there is no portable way of iterating over files in a directory that > matches a pattern. > > In my applications I often need to find all files in a directory that > matches "*.txt" or "input.*". > > I think it would be a good idea to add another constructor to the > directory_iterator that support some primitive wilcards. The support could > be limited to "*" at the end or followed by a "." > (e.g. "*", "a*.*", "*.txt", "a.*") Well, supposing that one has a 'shell wildcard matcher' it should be possible to do: typedef filter_iterator<wildcard_matcher, directory_iterator> it; for(it i = it(wildcard_matcher("*.txt), directory_iterator("dir")), e; i != e; ++i) { } which is not altogether nice, but workable. So, we only need somebody write the wildcard_matcher, or better yet, function to convert from wildcard syntax into regex syntax. Actually, I'd love to have some better syntax. E.g....
answer 2: But the startup time for my program grew much > faster. On windows the scan_for_files function in the collector has a loop > that is O(mn), where m is the number of files in the directory, and n is > the number that matched in previous calls to the scan_for_files function > > This means the scan_for_files for the first rotating file log in the > directory has no issue (n is 0), but the second can be problematic. It > iterates over the files in the directory and for each file in the > directory, it calls filesystem::equivalent on all of the matches from > previous scan_for_files calls. On windows, filesystem::equivalent is > particularly heavy, opening handles to both files. > > Thoughts? Is the two file logs getting the same collector the real issue? > Or is it my pointing two file logs to the same directory? I see some ways > to mitigate the slowdown in scan_for_files - e.g., filesystem::equivalent > could be called after all of the method/match_pattern check, but the two > file logs sharing the same collector feels like the real issue. The Windows filesystem is much slower than the filesystems on POSIX, about 70x slower for non-i/o operations. On top of that, the Win32 API adds considerable overhead above the kernel, and on top of that again, filesystem abstractions such as C++ Filesystem add a lot more again....
answer 3: Martin wrote: > I have used the filesystem library for some time now and noticed > that there is no portable way of iterating over files in a directory > that matches a pattern. > > In my applications I often need to find all files in a directory > that matches "*.txt" or "input.*". There was a proposal (and some code) for a globbing iterator some time ago. http://aspn.activestate.com/ASPN/Mail/Message/1977422 The OP uploaded his proposal to Yahoo files. It's named "globiter.zip". HTH, Angus...
answer 4: Lawrence Spector wrote: > std::string folderName = "C:\\*.sys"; > boost::filesystem::path fsDirectoryPath = > boost::filesystem::system_complete( > boost::filesystem::path(folderName, > boost::filesystem::native)); > boost::filesystem::directory_iterator end_iter; > > for (boost::filesystem::directory_iterator > dir_itr(fsDirectoryPath); > dir_itr != end_iter; ++dir_itr) // throws exception > { > std::cout << "Contains the following file: " << > dir_itr->string() << std::endl; > } // end for > > When I do this, I get the following exception: > > boost::filesystem::basic_directory_iterator constructor Are you using Boost 1.34? If not, it might be worth trying. If I'm right about the exception you're getting, I believe it's been eliminated in 1.34. If you're locked into a previous version of Boost, try passing boost::filesystem::no_check instead of boost::filesystem::native....
answer 5: The first thing I should say is I > love boost and I think it is a great library and I'm really > thankful to all its contributors. Now, that being said, I'm > sending this email to ask about a feature in the > boost::filesystem library that I believe would be valuable to > have. > > Currently the only library that supports file and directory > operations in boost is boost::filesystem. Thanks tot hat library > I don't have to use platform specific file manipulation rutines > for things like copying a file, deleting all files in a > directory, iterating through a directory, etc. Now, all the > operations in boost::filesystem take a boost::filesystem::path as > an object encapsulating a platform independent "path" to a file > or a directory. My problem is this path can only be built using a > single char (ANSI) character string. This doesn't allow me to use > boost::filesystem in windows with Unicode support since I cannot > convert a wide string (UTF16) path to a boost::filesystem::path > object. I believe it must not be too difficult to add Unicode > path support to boost::filesystem since only the "path" class > would need to be modified I think. > > Another small feature I think could be interesting is a > convenience function to set the current path (cd operation). > There is a function already to get the current path but not to > set it. > > I do not know if this is the right group to ask for these > features. If not please point me in the right direction....
answer 6: > >> Hello all > >> i like to get all folder and files names under giving > folder , what > >> will be the optimized way ( if any ) that boost can offer can you > >> point me to example code thanks > > > > I do not know if it is optimized but it is portable. You > can use the > > BOOST::Filesystem library/interface. > > > > http://www.boost.org/doc/libs/1_35_0/libs/filesystem/doc/index.htm > > > > iknow , i just need code sample to do it in the best way > recursive_directory_iterator Heres a snippet: for( fs::recursive_directory_iterator it(folder) ; it != fs::recursive_directory_iterator() ; ++it) { if (boost::iequals(fs::extension(it->path()), ".png")){ files.push_back(it->path()); } } -- John...
answer 7: How often do you have to do this? Does it truly have to be random? Does the list of files change? Could you build a list once and index into it? Can you build a list of partial names, index into that randomly, retrieve all of the names that match it, and then pick a random member of that set? Could you generate a random three-character mask, use that as a wild card, and pick one of the matching files at random, repeating if none match? Are they all in one folder? Charles -----Original Message----- From: boost-users-bounces@lists.boost.org [mailto:boost-users-bounces@lists.boost.org] On Behalf Of Lars Viklund Sent: Saturday, June 23, 2012 2:35 PM To: boost-users@lists.boost.org Subject: Re: [Boost-users] Filesystem: Choose random file from directory On Sat, Jun 23, 2012 at 12:27:39PM -0700, Charles Mills wrote: > Generate a random number 'n' between 1 and 500K and then take the nth > file from the directory. I would say that the core question is probably, how do I get a cheap indexed lookup in a directory. You've got to consider that directories, much like SQL tables, have no real innate sort order in most filesystems. All you have is the order given by the OS when doing an opendir/FindFirstFile, unless you use some ordered access method....
answer 8: On 16/01/2019 09:02, Lars wrote: > What is the most "atomic" way to move two files from a local disk to a > server location? The meaning of atomic in this context means that either > both files are moved or both files stay in original location. No > intermediate files should be present once operation is finished. When you detect that the source and target are on different filesystems, you should first perform a regular copy of the file to the target filesystem (using a different filename). Then perform the rename from this temporary file to the actual target filename. Usually you can put the temporary file in the same target directory but with a different file pattern that you know will not be observed by consuming directory watchers. If watchers might be looking for all files, then you may need to put temporary files in a different directory, as long as it's on the same filesystem. Using the same target directory also reduces the risk of permissions problems, although whatever installation process you use can require that the target directory and the temp directory have the same permissions, along with ensuring that they're suitably configured so your app can find them in the first place....
answer 9: Hello everybody, I'm new to this mailing list. The first thing I should say is I love boost and I think it is a great library and I'm really thankful to all its contributors. Now, that being said, I'm sending this email to ask about a feature in the boost::filesystem library that I believe would be valuable to have. Currently the only library that supports file and directory operations in boost is boost::filesystem. Thanks tot hat library I don't have to use platform specific file manipulation rutines for things like copying a file, deleting all files in a directory, iterating through a directory, etc. Now, all the operations in boost::filesystem take a boost::filesystem::path as an object encapsulating a platform independent "path" to a file or a directory. My problem is this path can only be built using a single char (ANSI) character string. This doesn't allow me to use boost::filesystem in windows with Unicode support since I cannot convert a wide string (UTF16) path to a boost::filesystem::path object. I believe it must not be too difficult to add Unicode path support to boost::filesystem since only the "path" class would need to be modified I think. Another small feature I think could be interesting is a convenience function to set the current path (cd operation). There is a function already to get the current path but not to set it. I do not know if this is the right group to ask for these features. If not please point me in the right direction. Thanks a lot Delfin Rojas Delfin@moodlogic.com...
answer 10: On windows the scan_for_files function in the collector has a > loop > > that is O(mn), where m is the number of files in the directory, and n is > > the number that matched in previous calls to the scan_for_files function > > > > This means the scan_for_files for the first rotating file log in the > > directory has no issue (n is 0), but the second can be problematic. It > > iterates over the files in the directory and for each file in the > > directory, it calls filesystem::equivalent on all of the matches from > > previous scan_for_files calls. On windows, filesystem::equivalent is > > particularly heavy, opening handles to both files. > > > > Thoughts? Is the two file logs getting the same collector the real issue? > > Or is it my pointing two file logs to the same directory? I see some ways > > to mitigate the slowdown in scan_for_files - e.g., filesystem::equivalent > > could be called after all of the method/match_pattern check, but the two > > file logs sharing the same collector feels like the real issue. > > One file collector per target directory is the intended behavior - that > is what allows to maintain limits on the log files to keep....
answer 11: Sean Farrow wrote: > Hi: > > I have the following code to iterate through sub directories: > > for (boost::filesystem::directory_iterator end, > dir(DirectoryToIterate); dir != end; ++dir ) { > > if (boost::filesystem::is_directory(dir->status())) > > > TempVec.push_back(boost::filesystem::path(dir->path()).generic_wstring()); > > } > > Iâm getting the following output which I expect: > > C:/Documents and Settings/All Users/Application Data/Freedom > Scientific/JAWS/12.0/Settings/enu > > I have two questions: > > Firstly how do I just obtain the last directory in this case enu (with > out any slashes)? see: http://www.boost.org/doc/libs/1_45_0/libs/filesystem/v3/doc/reference.html#path-decomposition and http://www.boost.org/doc/libs/1_45_0/libs/filesystem/v3/doc/reference.html#Path-decomposition-table > And secondly, is there a method of the path object that gives me the > path in windows form (i.e with the \ character replacing the / character.) See: http://www.boost.org/doc/libs/1_45_0/libs/filesystem/v3/doc/reference.html#path-native-format-observers Jeff...
answer 12: But in dev, I don't, so the number of files in the > directory slowly grew. But the startup time for my program grew much > faster. On windows the scan_for_files function in the collector has a loop > that is O(mn), where m is the number of files in the directory, and n is > the number that matched in previous calls to the scan_for_files function > > This means the scan_for_files for the first rotating file log in the > directory has no issue (n is 0), but the second can be problematic. It > iterates over the files in the directory and for each file in the > directory, it calls filesystem::equivalent on all of the matches from > previous scan_for_files calls. On windows, filesystem::equivalent is > particularly heavy, opening handles to both files. > > Thoughts? Is the two file logs getting the same collector the real issue? > Or is it my pointing two file logs to the same directory? I see some ways > to mitigate the slowdown in scan_for_files - e.g., filesystem::equivalent > could be called after all of the method/match_pattern check, but the two > file logs sharing the same collector feels like the real issue. One file collector per target directory is the intended behavior - that is what allows to maintain limits on the log files to keep....
answer 13: iknow , i just need code sample to do it in the best way On Wed, May 14, 2008 at 3:43 PM, dhruva <dhruvakm@gmail.com> wrote: > Hi, > > On Wed, May 14, 2008 at 3:38 PM, Meir Yanovich <meiry242@gmail.com> wrote: >> Hello all >> i like to get all folder and files names under giving folder , what >> will be the optimized way ( if any ) that boost can offer >> can you point me to example code >> thanks > > I do not know if it is optimized but it is portable. You can use the > BOOST::Filesystem library/interface. > > http://www.boost.org/doc/libs/1_35_0/libs/filesystem/doc/index.htm > > -dhruva > > -- > Contents reflect my personal views only! > _______________________________________________ > Boost-users mailing list > Boost-users@lists.boost.org > http://lists.boost.org/mailman/listinfo.cgi/boost-users >...
answer 14: Hello, when running the filesystem tests on Tru64, some files and directories with unicode characters in their name are created in the current directory. When running svn up in such a directory, it fails with the following error message: boost-trunk/libs/filesystem/test> svn up svn: Non-ASCII character (code 226) detected, and unable to convert to/from UTF-8 When running boost regression tests, these files are normally created in the status directory, and currently this prevents incremental testing because svn aborts when it finds these files. Is anybody else seeing this? Could these files perhaps be moved outside of the source tree? Or perhaps not generated at all, because so far I haven't figured out how to get rid of them, short of removing the whole directory containing these files. Markus...
answer 15: Hi boost-users, I am using a recursvive function for iterating over a starting path. When i finally arrive in a directory that contains no subdirectory (what i call a "final" directory), i want to retrieve the first and the last file of this directory. I succeed in retrieving the first file of the final directory (see code snippet below), But i do not know how to retireve the last one using the same directory iterator. Can someone think of an elegant solution ? ------------------ CODE BEGIN ------- namespace fs = boost::filesystem; void my_function (const fs::path &ph) { bool firstFileOfFinalDir = false; if (fs::is_directory(ph)) { fs::directory_iterator end_iter; for (fs::directory_iterator dir_itr(ph); dir_itr != end_iter; ++dir_itr) { if (fs::is_directory(dir_itr->status())) { // Recursive call my_function(fs::path(dir_itr->path())); } else { // We are in a "final" directory if (fs::is_regular_file( dir_itr->status())) { if (firstFileOfFinalDir) { // Do something with the first file of the final directory firstFileOfFinalDir = false; } else { // My problem : how to check if // dir_itr == (end_iter - 1) // i.e. if it is the last valid value ? }...
- **avg_similarity**: 0.5284
- **max_similarity**: 0.7793
- **num_results**: 15
- **time_seconds**: 0.4336

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.5966326594352722 |
| 2 | None | None | 0.345024049282074 |
| 3 | None | None | 0.5323593020439148 |
| 4 | None | None | 0.7612947225570679 |
| 5 | None | None | 0.6280800700187683 |
| 6 | None | None | 0.7793083190917969 |
| 7 | None | None | 0.41369640827178955 |
| 8 | None | None | 0.17691805958747864 |
| 9 | None | None | 0.6436476111412048 |
| 10 | None | None | 0.32954925298690796 |
| 11 | None | None | 0.6609079837799072 |
| 12 | None | None | 0.3731830418109894 |
| 13 | None | None | 0.6541743874549866 |
| 14 | None | None | 0.32507798075675964 |
| 15 | None | None | 0.7056067585945129 |

## 5. Question

- **question**: What is the difference between `boost::shared_ptr` and `std::shared_ptr`?
- **ground_truth**: Both `boost::shared_ptr` and `std::shared_ptr` provide reference-counted shared ownership of dynamically allocated objects. However, `boost::shared_ptr` was available before `std::shared_ptr` in C++11, and `boost::shared_ptr` has some additional features, such as a custom deleter.
- **rag_answer**: answer 1: Edward Diener wrote: > I am not a Boost developer but rather an end user using Boost. There is no sharp distinction between the two in the newfangled open source world. Imagine that you want to use shared_ptr on FooC++ 4.1a running on FooOS 3.11. Who, in your opinion, has a) the incentive b) the physical ability to run shared_ptr_test on this platform? > The most obvious solution is that each compiler/version supported for > a particular release of Boost needs a regression test run for each > library of that release, and that final test result needs to be kept > permanently somewhere for each Boost release. Saying "needs" by itself does not spawn the volunteers who will actually run the tests. In addition, Boost may decide to not support VC 6.0 for a particular release, but shared_ptr may still be perfectly functional. Who, in your opinion, needs to run the regression tests for shared_ptr on VC 6.0? > If this is not possible it seems that each library developer should > know which of the compilers/versions which are supported for a given > release of Boost works for his library and keep that information > permanently > somewhere in his library documentation. How could I know? I simply don't have access to all platforms that shared_ptr supports, and neither do I have the time to run the tests on each. What's wrong with just running the tests yourself if you want to see whether shared_ptr supports your particular configuration?...
answer 2: Hi, with recently acquired (semi) C++11 compiler (YEY!) I started to think which of BOOST functionality could be replaced by standard counterparts. First obvious candidates are smart pointers. Thing is, there is lots of functions that take boost::shared_ptr<> as arguments (or return them) and it is just not easy to do do. My questions: - does it even make sense to switch to std::shared_ptr<> (should new functions use std instead of boost) - is there a way to easily convert one to another - what are (if any) differences between std and boost versions Regards, Szymon Gatner...
answer 3: Le 21/05/2014 22:26, Peter Dimov a Ã©crit : > Loic Joly wrote: > >> Internally, some boost classes depend on boost::shared_ptr, not on >> std::shared_ptr. I remember making a suggestion that on platform >> supporting std::shared_ptr, boost::shared_ptr should be a simple >> typedef to std::shared_ptr. It was rejected. As a consequence, it's >> very hard not to indirectly include <boost/shared_ptr> when you >> include any part of boost. Which create issues for people who only >> want to use std::shared_ptr in their code. > > I understand why such a setup would be better for some (most) users. > It would however preclude any further improvements to boost::shared_ptr. > > boost::shared_ptr now supports arrays, for example, and no current > std::shared_ptr does that yet. Agreed, but I have never in my life wanted a shared_ptr to an array... Types such as shared_ptr are IMO crucial, because they are basic vocabulary types, that are part of library interfaces, and allow communication between different parts of the code. To me, the fact that std::shared_ptr is in std, and therefore might be used as a common vocabulary type by anyone anywhere has more value than any bells and whistles that might be added to anywhere::shared_ptr. I agree that we are not here yet. Many concurrent implementations of shared pointers (some of them buggy) exist in many libraries....
answer 4: Sumant On 3 June 2011 01:20, Johnny Willemsen <jwillemsen@remedy.nl> wrote: > Hi, > > I can need some help with getting similar behavior as with shared_ptr > for my classes., I have used std::shared_ptr with C++0x which matches > the boost support. > > I have two classes, Base and Derived. Now I want to give our users not > directly access to these implementation classes, but to some reference > to them. I have created two templates, BaseRef_T and Derived_objref (see > below). In Derived_objref I need to add some additional typedefs and > type definitions. I have tried first to add these typedefs to a > specialization of shared_ptr<> but couldn't get a clean solution. > > If I now use shared_ptr I can take a shared_ptr for a Derived and assign > it to a BaseRef_T. That works without problems. But how to accomplish > this with my own wrapper classes....
answer 5: That's my point of view. > > No, that's not how shared_ptr's ownership works. It owns a pointer > and when the last owner releases ownership the pointer is passed to > the deleter (which might just call 'delete'). But there is no > requirement that the pointer is non-null, or points to an instance of > some specific type, and certainly no requirement that if the > shared_ptr owns an X* that it has anything to do with any instance of > a different type Y, even if Y is related to X by inheritance. The > shared_ptr doesn't care about such things, it just owns a pointer and > arranges for it to be passed to the relevant deleter at the > appropriate time. I get your point. I've never expected that shared_ptr would (auto)magically "detect" any relation between X and Y or do anything that is unrelated to its nominal functionality. > > In this example the four shared_ptr objects all share ownership of the > same pointer of type Y*, even though one of them is a shared_ptr<X> > and one is shared_ptr<void> and one stores a completely unrelated > pointer type, but still owns a pointer of type Y*: > > struct X { virtual ~X() {} }; > struct Y : X { }; > > std::shared_ptr<Y> sy(new Y); > std::shared_ptr<X> sx(sy); > std::shared_ptr<void> sv(sx); > std::shared_ptr<int> si(sv, (int*)0); > > The ownership is a property of the static type of the pointer passed > to the first shared_ptr constructor that creates a unique shared_ptr > (i.e....
answer 6: Hi, I can need some help with getting similar behavior as with shared_ptr for my classes., I have used std::shared_ptr with C++0x which matches the boost support. I have two classes, Base and Derived. Now I want to give our users not directly access to these implementation classes, but to some reference to them. I have created two templates, BaseRef_T and Derived_objref (see below). In Derived_objref I need to add some additional typedefs and type definitions. I have tried first to add these typedefs to a specialization of shared_ptr<> but couldn't get a clean solution. If I now use shared_ptr I can take a shared_ptr for a Derived and assign it to a BaseRef_T. That works without problems. But how to accomplish this with my own wrapper classes. This should only be possible when the types are related to inheritance. If I have now a D that is not derived from Base than that shouldn't work. Johnny #include <memory> class Base { public: }; class Derived : public virtual Base { public: }; template <typename T> class BaseRef_T { public: BaseRef_T (std::shared_ptr <T> t) : impl_ (t) {}; BaseRef_T (T* t) : impl_ (t) {}; BaseRef_T (void) : impl_ () {}; typedef T element_type; inline T* operator-> () { return impl_.get ();} inline T* get() const { return impl_.get ();} explicit operator bool() const // never throws { return impl_ == 0 ?...
answer 7: Lastly, I question the usefulness of a shared_ptr without a weak_ptr. Note that weak_ptr is not limited to just circular references resolution, it has other use cases. Although shared_ptr has other useful features, like pointer aliasing and deleter erasure, I find myself using shared_ptr almost exclusively when I also need weak_ptr. When I don't need weak_ptr I would use intrusive_ptr. But then your rcgc_shared_ptr doesn't provide any of the additional features of shared_ptr, so there's even less reason to use it. _______________________________________________ Unsubscribe & other changes: http://lists.boost.org/mailman/listinfo.cgi/boost...
answer 8: On 18/05/10 13:30, Artyom wrote: > boost::shared_ptr, std::tr1::shared_ptr, std::shared_ptr and my > booster::shared_ptr is same pointer as it has same interface and same > semantics - that what is important. It is plain wrong. Interface and specification of std::tr1::shared_ptr is significantly different from std::shared_ptr, so both state very different types in terms of definition and behaviour. Best regards, -- Mateusz Loskot, http://mateusz.loskot.net...
answer 9: I was just watching the video here: http://channel9.msdn.com/shows/Going+Deep/C9-Lectures-Stephan-T-Lavavej-Standard-Template-Library-STL-3-of-n/ And was wondering if anyone had written up a brief guide about the differences between boost::shared_ptr and std::shared_ptr....
answer 10: > with recently acquired (semi) C++11 compiler (YEY!) I started to think which > of BOOST functionality could be replaced by standard counterparts. First > obvious candidates are smart pointers. > > Thing is, there is lots of functions that take boost::shared_ptr<> as > arguments (or return them) and it is just not easy to do do. My questions: > > - does it even make sense to switch to std::shared_ptr<> (should new > functions use std instead of boost) If some (interface) functions use the std version and some other - the boost one, it'd worsen the interoperability. > - is there a way to easily convert one to another See the following: http://stackoverflow.com/questions/6326757/conversion-from-boostshared-ptr-to-stdshared-ptr > - what are (if any) differences between std and boost versions In theory, there shouldn't be any difference. In practice, it depends on the implementation you've got, eg. tr1::shared_ptr in MSCV9 was quite buggy. Some std::make_shared implementations may have better performance, than boost::make_shared: http://stackoverflow.com/questions/12932348/why-stdmake-shared-has-much-better-performance-than-boostmake-shared...
answer 11: >> >> It actually has been evolving past the C++11 std::shared_ptr. >> For example, boost::shared_ptr supported array forms in 1.53 and this >> was eventually added to C++ in C++17. >> >> (Interesting aside: That functionality above was even, and still is >> used, in certain Microsoft projects, where boost::shared_ptr is used >> instead of std::shared_ptr). >> >> The same goes for other Boost libraries like Boost.Thread. They: >> - May have features not in the C++ standard library equivalent >> - May be evolving past the current C++ standard >> - Are in use by actual projects and shouldn't be removed >> >> Glen > > I am not talking about removal, just a note that there is a standard > replacement and a brief cap on their differences. Most people should prefer > using the standard library, reconsidering if they really need the > array-version of shared_ptr. By the way, I am a happy user of boost::thread, > and have not taken the time to move to std::thread yet. There is no "should" here. I let most people decide for themselves what they prefer. e.g. You may intend to move to std::thread, that's fine. Others may choose to continue to use boost::thread and boost::shared_ptr because they may not want to keep switching between std and boost for whatever reason(s). (In some cases, those reasons could be as simple as wanting newer features in Boost libraries that evolve faster....
answer 12: I seriously don't know why one > would use shared_ptr by default - I'm aware that some people might > want the additional features, but that doesn't justify such an advise. One reason for the "try shared_ptr first" recommendation is that while intrusive_ptr's advantages are usually obvious to developers, its disadvantages and shared_ptr's advantages are not. They became evident at a later date. intrusive_ptr is obviously the right choice when (1) shared_ptr's overhead is unacceptable, (2) when the design often needs to convert raw pointers into smart pointers, (3) when the underlying API already uses intrusive counting. And, if you pay attention: >> "As a general rule, if it isn't obvious whether intrusive_ptr better >> fits your needs than shared_ptr, try a shared_ptr-based design >> first." you'll see that the recommendation is for the cases where it isn't obvious whether intrusive_ptr is a better choice. Since most programmers are naturally biased in favor of intrusive_ptr, this just balances the things out. The main disadvantage of intrusive_ptr is that you need to know about the reference count, which usually means no incomplete classes, and virtual inheritance from a non-abstract class containing data members in every interface. This is manageable, but if you can live without it, you'll certainly want to. Also, weak pointers are cool. Really. :-)...
answer 13: I've looked through the shared_ptr documentation and am still puzzled about something. suppose I have class base1 { virtual ~base1; ... }; class derived1 : public base1 { .... }; shared_ptr<derived1> pd1(new derived1) shared_ptr<base1> pb1(pd); ? do pd1 and pb1 refer to the same object? class base2 { virtual ~base2; ... }; class derived3 : public base1, public base2 { ... }; shared_ptr<base2> pb2(pd1); ? do pb1 and pb2 refer to the same object? I'm presuming they do, but it's not really clear to me that this would work. To check this I could downcast everything to derived3. BUT when I have pb1 and pb2, I don't know what to downcast to. since there could be class derived4 : public base1, public base2 { ... }; So how could I verify whether an arbitrary pb1 and pb2 point to the same object or not? Robert Ramey...
answer 14: Hello, I have two questions regarding the proper use of boost::shared_ptr; both actually arose after reading http://www.boost.org/libs/smart_ptr/example/shared_ptr_example.cpp 1. In order for some class to work with std::set, you have to supply an operator with "less than" semantics. Why are you instead declaring a "greater than" operator? 2. In your examples, sometimes you're passing a shared_ptr by value, and sometimes by reference-to-const. Which is the better practice? Usually, common pointers are passed by value, but since in shared_ptr a reference counting mechanism keeps track of the copies, maybe it's better to pass it by reference whenever possible? Thanks in advance, Matthias Kaeppler -- Matthias Kaeppler | Tel: +49 631 3405805 Gerhart-Hauptmann-Str. 16a | Mob: +49 176 20108693 D-67663 Kaiserslautern | E-Mail: matthias at finitestate dot org...
answer 15: Rob Stewart <stewart@sig.com> writes: > From: Tylo <tylo@start.no> >> >> I propose this usage (for shared_ptr): >> >> shared_ptr<Widget> wp1 = NULL; // 1a <snip> >> Current shared_ptr usage: >> >> shared_ptr<Widget> wp1( NULL ); // 2a > > Lines 1a and 2a are just the difference between assignment and > initialization syntax. It's the difference between copy initialization and direct initialization. > The former can be slower than the latter, though the difference may > be optimized away. On many compilers where there is a difference, copy initialization is actually faster than direct initialization. -- Dave Abrahams Boost Consulting http://www.boost-consulting.com...
- **avg_similarity**: 0.6892
- **max_similarity**: 0.8187
- **num_results**: 15
- **time_seconds**: 0.4673

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.6423205733299255 |
| 2 | None | None | 0.6469696760177612 |
| 3 | None | None | 0.8187052607536316 |
| 4 | None | None | 0.6630502343177795 |
| 5 | None | None | 0.7360742688179016 |
| 6 | None | None | 0.6927146315574646 |
| 7 | None | None | 0.6408601403236389 |
| 8 | None | None | 0.7896440625190735 |
| 9 | None | None | 0.7345948219299316 |
| 10 | None | None | 0.6808766722679138 |
| 11 | None | None | 0.731978178024292 |
| 12 | None | None | 0.6369990110397339 |
| 13 | None | None | 0.6181449294090271 |
| 14 | None | None | 0.7739155888557434 |
| 15 | None | None | 0.5315575003623962 |

## 6. Question

- **question**: How do I use Boost.Range to iterate over a container?
- **ground_truth**: Boost.Range provides a set of utilities for working with containers. Example to iterate:
```cpp
#include <boost/range/algorithm.hpp>
std::vector<int> v = {1, 2, 3, 4};
boost::for_each(v, [](int x) { std::cout << x << std::endl; });
```
- **rag_answer**: answer 1: As I work with Boost.Range, I frequently want to call a method returning an iterator_range and, from that range, instantiate a standard container. I have a couple of helpers I'd like to propose for inclusion in the Boost.Range library. /** * From any range compatible with Boost.Range, return an instance of any * class with a constructor accepting a compatible iterator pair. */ template<class TYPE, typename RANGE> TYPE make_from_range(const RANGE& range) { return TYPE(boost::begin(range), boost::end(range)); } It would probably be appropriate to provide a non-const RANGE& overload as well. make_from_range<CONTAINER>(range) is helpful for, e.g., passing an argument to a function accepting const CONTAINER&. But what if you want to declare a local instance of such a container? /** * From any range compatible with Boost.Range, instantiate any class * with a constructor accepting a compatible iterator pair. */ template<class TYPE> struct instance_from_range: public TYPE { template<typename RANGE> instance_from_range(const RANGE& range): TYPE(boost::begin(range), boost::end(range)) {} // Again, a non-const RANGE& overload would probably be useful. }; Usage example: instance_from_range< std::vector<std::string> > my_vector(function_returning_range_of_string()); Perhaps instance_from_range might be more controversial because of the recommendation not to subclass standard containers. My thought is that once the (nearly trivial) constructor has executed, we can completely disregard the subclass....
answer 2: (Is sub_range is typed by iterator > by any chance, or typed by container only ? ) > 2) This is aux question. How to make assign library work for my > inherited container (vector_e here ), like the commented line ? > > > any help is appreciated, and thanks to the community . > > abir > > > Once again. I was looking at the boost::sub_range & iterator_range code (also crange & irange code). It looks, though sub_range and crange are typed over container, they use the iterator (or const_iterator, depending on the container ) as the iterator to iterate over the range. And it seems that is the problem I am facing. Where my range needs a user specified iterator (or iterator adapter ) to iterate over the container. Thus I tried to have my iterator pass as template parameter....
answer 3: Den 26-08-2011 14:30, Martin B. skrev: > Hi! > > Say I have a range R and I want to construct a new container from the > range R. Will I always have to repeat the expression yielding the range, > or is there a shorter way? > > Example: > > std::vector<int> numbers( > boost::irange(7, 42).begin(), > boost::irange(7, 42).end() > ); > > Note that it's just an example. > > Is it possible to create a container C from a range expression R in one > step? Any helper function for this? > std::vector<int> numbers = boost::copy_range<std::vector<int>>( boost::irange(7,42) ); -Thorsten...
answer 4: 2011/8/29 Martin B. <0xCDCDCDCD@gmx.at>: > On 26.08.2011 20:21, Ovanes Markarian wrote: >> >> On Fri, Aug 26, 2011 at 2:30 PM, Martin B. <0xCDCDCDCD@gmx.at >> <mailto:0xCDCDCDCD@gmx.at>> wrote: >> >> Hi! >> >> Say I have a range R and I want to construct a new container from >> the range R. Will I always have to repeat the expression yielding >> the range, or is there a shorter way? >> I do something like this: template <class SinglePassRange> boost::container::vector<typename boost::range_value<SinglePassRange>::type> makeVector(const SinglePassRange& rng) { boost::container::vector<typename boost::range_value<SinglePassRange>::type> v(boost::begin(rng), boost::end(rng)); return move(v); } and using it surprisingly often as move semantics allow for cheap return-by-value I guess you would also add template parameter for container type. -- Szymon Gatner The Lordz Games Studio www.thelordzgamesstudio.com...
answer 5: 2008/9/24 Nat Goodspeed <nat@lindenlab.com> > As I work with Boost.Range, I frequently want to call a method returning an > iterator_range and, from that range, instantiate a standard container. I > have a couple of helpers I'd like to propose for inclusion in the > Boost.Range library. > > /** > * From any range compatible with Boost.Range, return an instance of any > * class with a constructor accepting a compatible iterator pair. > */ > template<class TYPE, typename RANGE> > TYPE make_from_range(const RANGE& range) > { > return TYPE(boost::begin(range), boost::end(range)); > } > > It would probably be appropriate to provide a non-const RANGE& overload as > well. > > make_from_range<CONTAINER>(range) is helpful for, e.g., passing an argument > to a function accepting const CONTAINER&. But what if you want to declare a > local instance of such a container? > > /** > * From any range compatible with Boost.Range, instantiate any class > * with a constructor accepting a compatible iterator pair. > */ > template<class TYPE> > struct instance_from_range: public TYPE > { > template<typename RANGE> > instance_from_range(const RANGE& range): > TYPE(boost::begin(range), boost::end(range)) > {} > // Again, a non-const RANGE& overload would probably be useful....
answer 6: > > Regards, > It is better if I try to post some code to show what I exactly trying to do. ( I am trying to capture digital pen input and create a hierarchical structure from it ) ///This is a range (2 point index, which can create 2 iterators with the ///help of the container, I am using boost::sub_range for that ) typedef std::pair<std::size_t,std::size_t> range_t; ///This is a multi index range allows iterate over a few specific index ///on a container , used with my index_range and container. (for ///simplicity now it uses vector, it can be any container ) typedef std::vector<size_t> index_t; ///The index range. iterates over the specific position on the container ///a simplified version to show the concept. It has const correctness ///and all other functions that sub_range has. It takes container & ///index vector unlike iterators in boost::sub_range....
answer 7: Note, for example, that every range was a whole container. >> >> The three-iterators part was somewhat handwaved-over as well. Take >> this bit of current code, for example: >> >> auto i = find(c.begin(), c.end(), some_pred()); >> rotate(c.begin(), i, c.end()); >> >> How do you do that nicely with ranges, when he has find returning a >> range? (Since right now, it implicitly actually returns 2 ranges.) >> >> And how does insertion work? Do we still need to keep the iterators >> around for insertion position? >> >> I'd love to see the finicky bits worked out, though, since I do like >> the idea. >> >> ~ Scott > > Any place you really want a single iterator, a range of one value would > work. For appending or streaming out, you really want the concept of an > open-ended range. You can shrink ranges from the front or from the back, but you can't grow them. Andrei repeated this several times in his talk so I think it's important. It is part of the improved safety of ranges over iterators. The way I understand this, open-ended ranges don't exist....
answer 8: Nat Goodspeed skrev: > As I work with Boost.Range, I frequently want to call a method returning > an iterator_range and, from that range, instantiate a standard > container. I have a couple of helpers I'd like to propose for inclusion > in the Boost.Range library. > > /** > * From any range compatible with Boost.Range, return an instance of any > * class with a constructor accepting a compatible iterator pair. > */ > template<class TYPE, typename RANGE> > TYPE make_from_range(const RANGE& range) > { > return TYPE(boost::begin(range), boost::end(range)); > } > > It would probably be appropriate to provide a non-const RANGE& overload > as well. http://www.boost.org/doc/libs/1_36_0/libs/range/doc/utility_class.html#copy_range -Thorsten...
answer 9: abir basak wrote: > It is better if I try to post some code to show what I exactly trying to do. > ( I am trying to capture digital pen input and create a hierarchical > structure from it ) > ///This is a range (2 point index, which can create 2 iterators with the > ///help of the container, I am using boost::sub_range for that ) > typedef std::pair<std::size_t,std::size_t> range_t; > > ///This is a multi index range allows iterate over a few specific index > ///on a container , used with my index_range and container. (for > ///simplicity now it uses vector, it can be any container ) > typedef std::vector<size_t> index_t; > > ///The index range. iterates over the specific position on the container > ///a simplified version to show the concept. It has const correctness > ///and all other functions that sub_range has. It takes container & > ///index vector unlike iterators in boost::sub_range....
answer 10: On 2011-08-26 12:30:42 +0000, Martin B. said: > Hi! > > Say I have a range R and I want to construct a new container from the > range R. Will I always have to repeat the expression yielding the range, > or is there a shorter way? This is an interesting topic. There is *almost* a way to do what you want, using boost assign list_of, as per the example below. Note that I am assuming that you want to do this efficiently, hence use the slightly less convenient (because of the size parameter) cref_list_of function. There are two main problems with this approach. 1. The initial element of the range has to be explictly provided to cref_list_of. This is the 0 element in the examples below. 2. The range() function for cref_list_of completely fails when using a boost::irange. With the exception of the initial value, the container is filled with the final value of the irange (5 in this example). This looks like a bug to meâ¦ It would be really good to get boost assign enhanced to remove these limitations. In fact I wonder if it would be particularly hard to implement an assign::range_of function which uses the same underlying mechanism (ie an object which is convertible to the requisite container type)....
answer 11: >> >> Example: >> >> std::vector<int> numbers( >> boost::irange(7, 42).begin(), >> boost::irange(7, 42).end() >> ); >> >> What about that: >> ... >> >> integer_range<int> ir=irange(7,42); >> vector<int> numbers(ir.begin(), ir.end()); >> >> > For this to work I need the exact type of the range, which can be quite > annoying as far as I could tell. (Plus, I *don't want* to care what type of > the range is.) > > Really, if I had C++11/auto, I wouldn't mind so much, i.e. > > auto xr = get_some_range(...); > vector<int> numbers(xr.begin(), xr.end()); > > but I don't have an `auto` capable compiler, so spelling out the range type > for this is really crappy. > If you don't care about the type of range, you could always try: BOOST_AUTO( xr, get_some_range(...) ); vector<int> numbers( xr.begin(), xr.end() ); http://www.boost.org/doc/libs/1_47_0/doc/html/typeof/refe.html#typeof.auto Cheers, Darren...
answer 12: > > Example: > > std::vector<int> numbers( > boost::irange(7, 42).begin(), > boost::irange(7, 42).end() > ); > > Note that it's just an example. > > Is it possible to create a container C from a range expression R in > one step? Any helper function for this? > > > What about that: > ... > integer_range<int> ir=irange(7,42); > vector<int> numbers(ir.begin(), ir.end()); > For this to work I need the exact type of the range, which can be quite annoying as far as I could tell. (Plus, I *don't want* to care what type of the range is.) Really, if I had C++11/auto, I wouldn't mind so much, i.e. auto xr = get_some_range(...); vector<int> numbers(xr.begin(), xr.end()); but I don't have an `auto` capable compiler, so spelling out the range type for this is really crappy. Writing a make_container function seems fiddly wrt. to the C++03 reference type of the passed range, but maybe someone can help: template<typename C, typename R> C make_container(R /*value? ref? const-ref?...
answer 13: > > Like Robert I am uncomfortable with a > range concept that has iteration capabilities. > For one thing, standard containers don't > satisfy that concept, and it seems to me > that a container ought to be a range without > any special adaptation. Furthermore > I have doubts about how well this "range/iterator" > concept maps onto bidirectional > and random access. That said... I think it will be very difficult to have the standard containers satisfy a range concept. Containers hold elements, and provide access to them via iterators. Those two iterators model a range. Algorithms like for_each take that range, and process the items element by element, by using the first element, and shrinking the range by incrementing the first iterator. When you view a container as a range, you can't shrink the range without deleting elements. This would mean that when passing a container to an algorithm that that algorithm either deletes items or has to copy the container. Ranges live at the level of iterators, providing access. They do not live at the level of containers, which store elements. Therefore, I think a container does not need to satisfy the range concept. If I were allowed to make changes to the standard library, I would add a member function range() to containers, returning some range object holding a begin and an end: Containers hold objects, and provide access to them by representing those objects as a range. The range provides access to individual elements using iterators. Of course, changes to the standard library are not considered here....
answer 14: on Fri Jan 25 2013, Beman Dawes <bdawes-AT-acm.org> wrote: > On Thu, Jan 24, 2013 at 8:56 PM, Dave Abrahams <dave@boostpro.com> wrote: >> >> I'm finding that boost::filesystem::path seems to be a strange mix of >> different beasts, unlike any entity we have in the STL. For example, >> when you construct it from a pair of iterators, they're expected to be >> iterators over characters, but when you iterate over the path itself, >> you are iterating over strings of some kind (**). Even though, once >> constructed, this thing acts sort of like a container, it supports none >> of the usual container mutators (e.g. push_back, pop_back, erase) or >> even queries (e.g. size()), making it incompatible with generic >> algorithms and adaptors. > > It isn't really a container, Well, why not? It does most things that containers do, but with different names. And to expose iterators but then not let me use those iterators to modify the path is... well, disappointing. > but it is convenient to supply iterators over the elements of the > contained path. Should more container-like mutators be supplied? It certainly would make it more useful. I could then employ, e.g. back_inserter. But I also have problems with the fact that it's constructed with a range of characters but its iterators traverse a range of paths....
answer 15: > > > What about that: > ... > integer_range<int> ir=irange(7,42); > vector<int> numbers(ir.begin(), ir.end()); > For this to work I need the exact type of the range, which can be quite annoying as far as I could tell. (Plus, I *don't want* to care what type of the range is.) Really, if I had C++11/auto, I wouldn't mind so much, i.e. auto xr = get_some_range(...); vector<int> numbers(xr.begin(), xr.end()); but I don't have an `auto` capable compiler, so spelling out the range type for this is really crappy. Writing a make_container function seems fiddly wrt. to the C++03 reference type of the passed range, but maybe someone can help: template<typename C, typename R> C make_container(R /*value? ref? const-ref?*/ range) { return C(range.begin(), range.end()); } and it would still be very ugly to call: const vector<int> numbers = make_container< vector<int> >(irange(7,42)); (Note: I did not compile/test this code!) any ideas? cheers, Martin...
- **avg_similarity**: 0.6368
- **max_similarity**: 0.7603
- **num_results**: 15
- **time_seconds**: 0.4329

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.6013684868812561 |
| 2 | None | None | 0.6413798332214355 |
| 3 | None | None | 0.7603287696838379 |
| 4 | None | None | 0.6620026230812073 |
| 5 | None | None | 0.6354880928993225 |
| 6 | None | None | 0.7491685152053833 |
| 7 | None | None | 0.5734638571739197 |
| 8 | None | None | 0.6008638739585876 |
| 9 | None | None | 0.7309001088142395 |
| 10 | None | None | 0.6658195853233337 |
| 11 | None | None | 0.6002184748649597 |
| 12 | None | None | 0.7216885089874268 |
| 13 | None | None | 0.5967138409614563 |
| 14 | None | None | 0.4004485011100769 |
| 15 | None | None | 0.6126777529716492 |

## 7. Question

- **question**: What is Boost.Spirit used for?
- **ground_truth**: Boost.Spirit is a library for building parsers directly in C++. It allows you to define grammar rules in a C++-like syntax for parsing text and binary data.
- **rag_answer**: answer 1: Manfred Doudar wrote: > > Hi Boosters: John & others; > > Below are the details of our in-house use of Boost. > > Please not, our software and consequently use of Boost is ^^^ Sorry typo: s/not/note > in-house (not sold to third parties) - consequently, appropriate > classification is needed for this category. > > > > > COMPANY NAME: MetOcean Engineers > > COMPANY ADDRESS: www.metoceanengineers.com > > COMPANY BRIEF: > A leading consultancy providing oceanographic and meteorological > services in support of coastal and ocean engineering and environmental > protection. Core activities encompass: oceanographic measurements; > metocean monitoring systems; coastal and ocean engineering; environmental > consultancy; data management....
answer 2: Hi Roel, > I know that Spirit can be used for scanning and > lexical analysis, at least that where I use it for. > I don't know about the rest, but I guess Spirit will > help you out there too. In my little project I use > it for parsing XML, HTML and other datafiles. > > For more info on spirit : > http://spirit.sourceforge.net/ Thanks a lot! It seems to be a big deal in what I want. > If you need a C/C++ parser, you might consider Wave, > which uses Spirit, and is highly standard compliant. Nope! What I need is a parser generator which is written in C++. I think you've provided me what I wanted. Thanks, --Hossein __________________________________ Do you Yahoo!? Yahoo! Search - Find what youï¿½re looking for faster http://search.yahoo.com...
answer 3: Dear Boosters, The following code is one of my first attempts to use Spirit/Qi. For my education, I have tried 2 techniques to parse the simple "aaa=131;" string. The first one (Block A) compiles and seems to output the expected result. The second (B) does not compile with a huge massively templatized backtrace that I don't understand. What is the difference between using online rules and rule objects ? Is there a syntax error somewhere ? I'm afraid the documentation and example are rather terse about the syntax to be used here when coupling Qi and Phoenix... Many thanks for your help. best regards frc -- <pre> #include <iostream> #include <string> #include <vector> // - Boost/Spirit #include <boost/spirit/include/qi.hpp> #include <boost/spirit/include/phoenix_core.hpp> #include <boost/spirit/include/phoenix_operator.hpp> int main( int argc_, char * argv_[]) { int error_code = EXIT_SUCCESS; using boost::spirit::qi::double_; using boost::spirit::qi::string; using boost::spirit::qi::lit; using boost::spirit::qi::lexeme; using boost::spirit::qi::phrase_parse; using boost::spirit::qi::_1; using boost::spirit::qi::as_string; using boost::spirit::ascii::space; using boost::spirit::ascii::char_; using boost::phoenix::ref;...
answer 4: I am using Cygwin's g++ 3.4.4 and the official Cygwin Boost package version 1.33.1. This minimal programm using namespace boost::spirit; rule< > r; r = real_p; bool b = parse(inp.c_str(),r,space_p).full; produces the following error: g++ -c -o objs/src/Main.o -D__cygwin__ -O -Isrc -Ilibutil/include -Ilibrsrc/include src/Main.cpp /usr/include/boost/spirit/core/scanner/impl/skipper.ipp:173: instantiated from `boost::spirit::parse_info<const CharT*> boost::spirit::parse(const CharT*, const boost::spirit::parser<DerivedT>&, const boost::spirit::parser<SkipT>&) [with CharT = char, ParserT = boost::spirit::rule<boost::spirit::nil_t, boost::spirit::nil_t, boost::spirit::nil_t>, SkipT = boost::spirit::space_parser]' src/Main.cpp:16: instantiated from here /usr/include/boost/spirit/core/non_terminal/impl/rule.ipp:189: error: no matching function for call to `boost::spirit::impl::abstract_parser<boost::spirit::scanner<const char*, boost::spirit::scanner_policies<boost::spirit::iteration_policy, boost::spirit::match_policy, boost::spirit::action_policy> >, boost::spirit::nil_t>::do_parse_virtual(const boost::spirit::scanner<const char*, boost::spirit::scanner_policies_t>&)' Using the parser expression directly works without problems: bool b = parse(inp.c_str(),real_p,space_p).full; What am I doing wrong?...
answer 5: Manfred Doudar wrote: > > Hi Boosters: John & others; > > Below are the details of our in-house use of Boost. > > Please not, our software and consequently use of Boost is ^^^ Sorry typo: s/not/note > in-house (not sold to third parties) - consequently, appropriate > classification is needed for this category. > > > > > COMPANY NAME: MetOcean Engineers > > COMPANY ADDRESS: www.metoceanengineers.com > > COMPANY BRIEF: > A leading consultancy providing oceanographic and meteorological > services in support of coastal and ocean engineering and environmental > protection. Core activities encompass: oceanographic measurements; > metocean monitoring systems; coastal and ocean engineering; environmental > consultancy; data management. > > > PREDOMINANT 3RD PARTY (OPEN-SOURCE) LIBRARIES IN USE: > * Boost > * Blitz++ > > > CONTEXT OF BOOST USAGE: Tools and libraries for analyses and > dissemination of oceanographic & meteorological data: > * Libraries to generically write, read, copy, and hack > oceanographic & meteorological data file formats > * Libraries and tools for numerical modelling, analysis and data > processing > > NOTE: Software is not commercialized to third parties; all software is > delivered in-house > > > WHO's USING BOOST CATEGORY: > Other (in-house/internal usage) > > > BOOST LIBRARIES CURRENTLY IN USE: > boost.any > boost.assign > boost.bind > boost.date_time > boost.iterators > boost.lexical_cast > boost.mpl > boost.phoenix > boost.program_options > boost.ref > boost.smart_ptr > boost.spirit > boost.string_algo > boost.tribool > boost.variant > > > Cheers & Thanks,...
answer 6: On Tue, Jun 9, 2009 at 4:04 PM, Christian Schladetsch <christian.schladetsch@gmail.com> wrote: > > Hi John, > > This is somewhat unexpected. > > The reality for me and my workmates for years has been about boost::spirit: > "boost is fun to look at" or "boost has useful things" or "boost::spirit is > awesome, wait... what?" > > Point being that every real person, self included, that has ever tried to > use boost::spirit has gone through three stages: > > 1. wow, it uses C++ static compile-time rules! > 2. gee, this is slow to compile > 3. ok, i can't use this. its too slow to compile and the error messages are > pointless Hmmm - I can't be a real person, obviously.... I've used Spirit 1 on several projects with great success. I've also use Antlr on several projects with great success! What's the difference? Well, Antlr (for me) implies a reasonable amount of project overhead - building the runtime support, having additional files to configure, having to deal with the conceptual break between Antlr and C++. Spirit doesn't. It does mean a compile-time burden, true, but that burden is the reason I've used Antlr for larger grammars rather than Spirit. > The reality is that Spirit tries to make C++ do something it shouldn't do....
answer 7: "Giovanni Bajo" <giovannibajo@libero.it> writes: > David Abrahams wrote: > >>> Like what, boost::spirit::file_iterator >>> (boost/spirit/iterator/file_iterator.hpp)? >> >> Probably, but a rhetorical question: >> >> "Where is the documentation for this component?" >> >> http://www.boost.org/libs/spirit/doc/file_iterator.html is really >> inadequate. > > I think it serves its purpose for using the iterator within Spirit. I agree it > should be rework, if file_iterator had to be generalized in Boost. Hmmph. I have to say that while I love what Spirit is doing, actually using it with confidence requires way too much use of the source, Luke. Reference docs are annoying to write, but neccessary. >> I can't even tell what iterator category it provides. > > It's a random access iterator. You can experiment with Regex if you want, it > should work as-is. IIRC, it's used in Wave too. That's great! Thank you! -- Dave Abrahams Boost Consulting www.boost-consulting.com...
answer 8: Christopher Jefferson wrote: > Looking at the documentation, Boost::Spirit seems like a very big hammer > to crack this quite small nut, and it is unclear to me how well it would > fit into an existing recursive decent parser. Has anyone ever used it as > such? Is there a simple alternative? Spirit is well tuned for small parsing tasks like this. It is a modular RD parser. What you need is what you pay for. The code is as tight as it can be. Try the int parsing examples and see the generated assembler. One of Spirit's original goal is for such micro-parsing. You don't have to write an RD parser, Spirit is an RD parser. However, if you need to use an existing RD parser, then good! You can use any or all of Spirit facilities as-is by calling Spirit's parse functions (which accept forward iterators) from your RD environment. Or, the other way around, you can write a custom-parser in spirit that calls your RD parser. Regards, -- Joel de Guzman http://www.boostpro.com http://spirit.sf.net...
answer 9: Lastly, my own opinion of "what Boost is" factored in here. I view Boost as *partly* a collection of general purpose libraries that can be used in wide variety of applications (and thus Boost frequently acts as a staging ground for standard adoption). Based on review feedback, I believe Local satisfies this criterion; and based on the mailing list discussion, I believe this view of Boost is not entirely inconsistent with others on the mailing list. Ultimately, it wasn't so much a # of "yes" votes versus # of "no" votes as it was the above general considerations. Regardless, I think independent of how the votes were counted, the "yes" votes outnumbered the "no" votes. This required some discretion on my part as not everyone who expressed an opinion submitted a formal review, and some participants were only arguing in favor of some specific point supporting either acceptance or rejection of Local. "Yes" reviews (7) -------- Krzysztof Czainski Andrzej Krzemienski Pierre Morcello Nat Lindon John Bytheway Edward Diener Gregory Crosswhite "No" reviews (3) -------- Vicente J. Botet Thomas Heller Hartmut Kaiser Paul A. Bristow and Alexander Nasanov (the author of Boost.ScopeExit) both submitted reviews but did not express an opinion (as far as I could tell) on whether Local should be included in Boost, though if I had to peg Paul's, it would be to reject Local....
answer 10: > > Please provide us with a minimal, self-contained piece of code we can > > compile. We have no crystal ball to see what you're doing... > > Sorry, I was sure it's so basic, that there's even no need for real > source-code. Sure it is, but I wanted to see which placeholder do you use, and what includes you have. > Here it is: > > #include <string> > #include <boost/spirit/include/qi.hpp> > #include <boost/spirit/include/phoenix_core.hpp> > #include <boost/spirit/include/phoenix_operator.hpp> > > namespace qi = boost::spirit::qi; > namespace ascii = boost::spirit::ascii; > namespace phoenix = boost::phoenix; > int main() > { > using qi::int_; > using qi::string; > using qi::_1; > using ascii::space; > using phoenix::ref; > > int i1; > std::string s1; > std::string source; > std::string::iterator first = source.begin(), last = > source.end(); > // compiles well: > qi::phrase_parse(first, last, > ( > int_[ref(i1) = _1] > ) > , > space); > > // doesn't compile: > qi::phrase_parse(first, last, > ( > string[ref(s1) = _1] > ) > , > space); > > } qi::string is not a valid parser primitive. What would you expect it to match anyway?...
answer 11: > I have encouraged and supported Bryce's undertaking on the assumption that > the usage of the latest spirit would improve the xml_iarchive in every way > including performance, maintainability and portability. This assumption > was inspired and supported by the warnings that spirit classic was > "deprecated" which seemed to suggest that it would be in our interest to > convert to the latest spirit. The xml grammar used in the serialization > library is very simple - what could go wrong? Well, It is starting to > look like this assumption was wrong and I'm very disappointed. I feel the > developer's of spirit have let Bryce down. Robert, I believe you didn't mean what you wrote, as otherwise your words appear to be a bit too heavy handed. We are in permanent and active contact with Bryce (there is a lengthy mailing list discussion, and I am in contact with him on a daily basis on IRC). Nobody left Bryce down. Additionally, I believe he explicitly stated that in his original mail. BTW, the 'deprecated' warnings never claimed that Spirit.Classic as a whole was deprecated, but only the headers you've been using. We have no intent to remove Spirit.Classic from Boost. A simple change of the include directive to other header files as suggested by those warnings (and defining a pp constant during compilation) would have fixed the warnings altogether. That's something you could have done in 15 minutes if you only had cared to ask. > I'm hoping the spirit developers can step up and follow through to realize > the expections developed for this package. What expectations? What package?...
answer 12: Manfred Doudar wrote: > The C++ BOOST Libraries are a series of free, peer-reviewed, STL compliant, > portable and thread-safe C++ libraries; That sounds a little too buzzwordy to my ear. What does 'STL compliant' actually mean ? Also, I don't think boost libraries are generally thread-safe, at least not in a general sense. I believe it would be best not to mention thread-safety in a short abstract, or else you'd have to detail the statement quite a bit to make it true. Regards, Stefan...
answer 13: Well, in this case I really prefer: using namespace spirit::std_locale; spirit::qi::parse(str, spirit::int_, i); or, if you need another radix: typedef spirit::qi::int_parser<int, 16> hex; spirit::qi::parse(str, hex(), i); or, if you need exactly 4 hex digits: typedef spirit::qi::int_parser<int, 16, 4, 4> hex4; spirit::qi::parse(str, hex4(), i); etc. Which is far less convoluted. Same/similar works for converting the other way around: typedef spirit::karma::int_generator<int, 16> hex; spirit::karma::generate(std::back_inserter(str), hex(), i); <rant> I still don't get it. I agree that it might be favorable to have a simple API for type<-->string conversions. But as you can clearly see the requirements are piling up and it's everything else but simple by now. So I ask again: What's the benefit of coming up with just another full blown parser/generator interface in Boost? What's the benefit of discarding/obsoleting lexical_cast<>() as the _really_ minimal, simple interface? Guy's. You're trying to come up with a DSEL (domain specific embedded language) for parsing and generating. What's it exactly you don't like in Spirits DSEL? Just the fact that it wasn't _you_ to come up with this particular syntax? Have you even looked?...
answer 14: > That's why I thought parsing the grammar from a "plain text file" was what you needed. I confess I didn't understand the UI part of your subject line. Googling I found: http://www.antlr3.org/works/ Is that more like what you want? In particular: http://www.antlr3.org/works/screenshots/editor.jpg > >> Couldn't this grammar be described using spirit, and that spirit >> "source" grammar could be used to *read* your the grammar you actually >> want from a file and create the actual "target" grammar you want? > > The grammar shouldnât read from a file at runtime, it should be build-in > >> After all, I don't see what Antlr would buy you because, IIUC, you'll >> havde to do essentially the same thing, except using Antlr you have to >> learn to systems, Antlr as well as spirit. > > AntLR is a nice tool to create a visual representation of the grammar and > it can be also helpful during the developing of the grammar. In my case > I would like to create a logical language and donât want to create a > âhard encoding spirit codeâ, so I would like to design the grammar in a > UI tool and create from the visual representation the Spirit code and > paste it in my class file which create parser & lexer. > > UI Grammer Modelling -> Spirit Code Generator -> Spirit Code -> Lexer / Parser > > Hope this is a bit clearer....
answer 15: > > Boost libs: > boost.mpl > boost.string_algo > boost.bind > boost.phoenix > boost.spirit > boost.ptr_container > boost.serialization > boost.regex > boost.iterators > boost.lambda > boost.lexical_cast > boost.operators > boost.smart_ptr > boost.tribool > boost.type_traits > > Company Site: www.synergy.com.br > Project Site: www.mintercept.com > > On 6/6/05, John Maddock <john@johnmaddock.co.uk> wrote: > > There are now a set of prototype "Who's Using Boost?" pages available at: > > > > http://freespace.virgin.net/boost.regex/who/html/index.html > > > > Comments and suggests welcome, but in particular we need more case > > studies/products etc that are using Boost to be listed. If you have a > > product or project that could be listed then please see the submission > > guidelines at: > > > > http://freespace.virgin.net/boost.regex/who/html/who_s_using_boost_/submit.html > > > > Regards, > > > > John. > > > > > > _______________________________________________ > > Unsubscribe & other changes: http://lists.boost.org/mailman/listinfo.cgi/boost > > > > > -- > Felipe Magno de Almeida > Developer from synergy and Computer Science student from State > University of Campinas(UNICAMP). > Unicamp: http://www.ic.unicamp.br > Synergy: http://www.synergy.com.br > "There is no dark side of the moon really....
- **avg_similarity**: 0.5309
- **max_similarity**: 0.7477
- **num_results**: 15
- **time_seconds**: 0.4180

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.3908441662788391 |
| 2 | None | None | 0.7476676106452942 |
| 3 | None | None | 0.59577876329422 |
| 4 | None | None | 0.5342180132865906 |
| 5 | None | None | 0.3929814100265503 |
| 6 | None | None | 0.6082683801651001 |
| 7 | None | None | 0.6149090528488159 |
| 8 | None | None | 0.6405476331710815 |
| 9 | None | None | 0.3112129271030426 |
| 10 | None | None | 0.6341091394424438 |
| 11 | None | None | 0.4130619466304779 |
| 12 | None | None | 0.4772335886955261 |
| 13 | None | None | 0.5193842649459839 |
| 14 | None | None | 0.46097609400749207 |
| 15 | None | None | 0.6220268607139587 |

## 8. Question

- **question**: How do I create a thread using Boost.Thread?
- **ground_truth**: You can create a thread using the `boost::thread` class. Example:
```cpp
#include <boost/thread.hpp>
void print_hello() { std::cout << "Hello from thread!" << std::endl; }
int main() {
    boost::thread t(print_hello);
    t.join();
    return 0;
}
```
- **rag_answer**: answer 1: Hi, I have problems creating a thread. This is an example i found: #include <boost/thread/thread.hpp> #include <iostream> void hello() { std::cout << "Hello world, I'm a thread!" << std::endl; } int main(int argc, char* argv[]) { boost::thread thrd(&hello); thrd.join(); return 0; } What if i want to create a thread outside of main (in a class) like this: "myClass.h" class MyClass { public: hello(); myFunction(); }; "myClass.cpp" MyClass::hello() { std::cout << "Hello world, I'm a thread!" << std::endl; } MyClass::myFunction() { boost::thread thrd(&hello); thrd.join(); } This does not work and i get the compile error: '&' : illegal operation on bound member function expression...
answer 2: Hi, I want to make a simple worker thread in my WTL application. However, looking through the boost::thread documentation, I don't see any samples of how to create a thread. Would anyone be so kind as to point me in the right direction? Thank you....
answer 3: Hi, I'm trying to use boost to create a "zip" file containing more than one file. To my understanding I should use boost::iosteams to do this. In the boost documentation I there is only an example on how to unzip a file ..... http://www.boost.org/doc/libs/1_37_0/libs/iostreams/doc/classes/zlib.html#examples ... but I dont understand how I could do the opposite (create a zip-archive) Especially how to do the naming of the files inside the archive. Does anyone have an example on howto do create a zip-archive containing a couple of text files? Thanx /Peter/ -- View this message in context: http://www.nabble.com/Using-iostream-to-create-ZIP-archive-tp21461391p21461391.html Sent from the Boost - Users mailing list archive at Nabble.com....
answer 4: Hi, everyone, A new thread can be created using boost thread either from a function or a functor as the entry point of the new thread, as: void thread_function(); boost::thread thrd(&function); class functor { public: inline void operator()(); }; functor f; boost::thread thrd(f); Is there a performance difference between these two? In an ordinary C++ program, can I claim that calling f() 1000 times gives better performance than calling thread_function() 1000 times, because the functor is hinted "inline" even the hint is igored by my compiler? Is f() the same as a function call in term of performance? Thanks in advance. Robert...
answer 5: Hi; I am in the process of converting an existing thread function originally called using BeginThread to use boost.thread. I have a coupple of questions: 1. How would I go about returning to the existing thread, I use windows event handles and when one is signaled the thread ends, can I still use a while loop to do this, such as: Do { Code While(returnFromThread !=true); 2. Does boost::thread allow me the create mutex's and does it inherit windows mutex handles. 3. Can I tell a thread to run as soon as it starts or do I have to use the call boost.join. Any help apreciated. Cheers San. __________ Information from ESET NOD32 Antivirus, version of virus signature database 4018 (20090418) __________ The message was checked by ESET NOD32 Antivirus. http://www.eset.com...
answer 6: What's the proper way to start a boost thread for each hardware thread available? I can do this... but it is clunky and does not scale (especially when there are lots of cores): const unsigned int hwt() { const unsigned int t = boost::thread::hardware_concurrency(); return t; } if ( t == 2 ) { boost::thread _01( task, thread_data, St ); boost::thread _02( task, thread_data, St ); _01.join(); _02.join(); } if ( t == 4 ) { boost::thread _01( task, thread_data, St ); boost::thread _02( task, thread_data, St ); boost::thread _03( task, thread_data, St ); boost::thread _04( task, thread_data, St ); _01.join(); _02.join(); _03.join(); _04.join(); } It seems that a for loop (or something similar) could be used to start the same number of boost threads as there are HWTs. Could someone point me in the right direction? Thanks, Brad...
answer 7: You need a global wrapper function. Ie, a thread start function that takes the address of the instance of the class as the void* pointer and then runs some method in the class. (Generally a run method or something similar) something like: void* start_thread( void* data ) { TestThread* tt = dynamic_cast<TestThread*>( data ) tt->run() ; } Paul On 9/27/06, Monica Gretzer <mogr_progr@yahoo.se> wrote: > > Hi, > > I want to use boost::thread to create threads that are member functions > within a class. In all the examples I have seen, the thread function is > defined globally. > I explain it with code. The following test code works: > > // code 1: example program that works > ----------------------------------------------- > #include <boost/thread/thread.hpp> > #include <iostream> > using namespace std; > > void testing() > { > cout << "I'm a thread."...
answer 8: Peter Json wrote: > Hi, > > I'm trying to use boost to create a "zip" file containing more than one > file. > > To my understanding I should use boost::iosteams to do this. > > In the boost documentation I there is only an example on how to unzip a file > ..... > http://www.boost.org/doc/libs/1_37_0/libs/iostreams/doc/classes/zlib.html#examples > > ... but I dont understand how I could do the opposite (create a zip-archive) > Especially how to do the naming of the files inside the archive. > > Does anyone have an example on howto do create a zip-archive containing a > couple of text files? > There is a distinction between zlib and zip files. this was asked and answered before. For details see: http://www.nabble.com/iostreams-%2B-unzip-td12725850.html#a12725850...
answer 9: Greetings, I'm wondering why there is no option to pass a parameter to a thread function with boost's threads. With pthreads and Windows CreateThread I'm used to casting an object to a void*, and retrieving the object within the thread function. The only thing similar with boost::thread seems to be to create a struct with an operator()() and a constructor that takes a void*. operator()() then calls an external function with the passed void*. Just curious about this design decision. --M Peltzer...
answer 10: We have a runnable class which is inherited by the applications wanting to create threads and they override the run method. This is how our application currently creates threads. Thanks Peter for your earlier mail explaining on how to use boost::shared_ptr and boost::bind Your code for a Runnable interface > struct Runnable > { > virtual ~Runnable() {} > virtual void run() = 0; > }; We have a class Runnable with nearly the same code as above. To make a dummy implementation, I made the run methd a normal function. Nothing derives from it.. run is what I want to execute in a thread. > > void execute_in_thread( boost::shared_ptr<Runnable> pr ) > { > boost::thread th( boost::bind( &Runnable::run, pr ) ); > } I am creating a thread in MyThread class using the following code. --- MyThread.h ---- typedef boost::shared_ptr<Runnable> myPtr; class MyThread { public: MyThread( ); ~MyThread( ); private: myPtr p1; } --- MyThread.cpp ---- MyThread::MyThread( ) : p1( new Runnable() ) { cout << "MyThread::MyThread( ) constructor " << endl; boost::thread th( boost::bind( &Runnable::run, p1) ); } ---- Runnable.cpp --- // this is the only function in Runnable.h void Runnable::run() { cout << "Runnable::run() YUPPIE! "<< endl; } ------ end ----------- The code compiles, but nothing happens.. I am missing something here ??...
answer 11: >> >> 5.can i resume a thread after pausing it ? ( how can i pause a thread? ) >> >> Boost.Thread doesn't provide fibers or resumable threads. There is >> Boost.Fiber for that purpose (not yet in Boost). >> >> 6. how can i share a variable between two or more threads , suppose i >> have a loop , i want two threads to simultaneously iterate through it , if >> thread1 counted to 3, thread2 continues it from 4 and so on . ? >> i already tried >> >> You need to protect the access to the loop index variable 'i' with a >> mutex as you did with sum. >> >> HTH, >> Vicente >> >> ------ >> >>> what is wrong with my sample app ? >>> #include <iostream> >>> #include <boost/thread.hpp> >>> using namespace std; >>> using namespace boost; >>> >>> mutex bmutex; >>> int i=0; >>> int sum=0; >>> void IteratorFunc(int threadid) >>> { >>> for ( ; i<25 ; i++) >>> { >>> lock_guard<mutex> locker(bmutex); >>> >>> cout<<"\t"<<threadid<<"\t"<<this_thread::get_id()<<"\t"<<i<<"\n"; >>> sum+=i; >>> } >>> } >>> >>> int main() >>> { >>> //boost::posix_time::ptime start = >>> boost::posix_time::microsec_clock::local_time(); >>> >>> thread thrd(IteratorFunc,1); >>> thread thrd2(IteratorFunc,2); >>> >>> cout<<sum; >>> thrd.join(); >>> thrd2.join(); >>> } >> >>...
answer 12: Hi everyone, I've been playing around with the Parallel Boost Graph Library in hopes of using it for a distributed mesh with redistribution capabilities. Unfortunately, I've been having a lot of issues and I was hoping to get some clarification from the community on some points. I am trying to construct a distributed graph that represents a mesh. The idealized plan is to use this library to create a mesh class that allows for the easy introduction of new vertices and edges as well as repartitioning/data migration capabilities. For this effort, I created a simple struct called Cell that is attached as an interior vertex property and identified the cell id value as the key for indexing. I've attached a short program to really quickly demonstrate what I've been trying to prototype. At this point, I have some questions regarding some things about the library that I can't seem to figure out. 1. How do you control the initial distribution of the names? That is, how do you control which processes own what vertex names when you dynamically add named vertices? 2. How do you create a VertexProcessorMap to use with the redistribution function? The test adjlist_redist_test.cpp looks like it creates a property_map of the vertex_rank but I'm not sure how to do something similar when I have named graph. 3. Is there any way and any point to accomplish what I'm trying to do without using named graphs? I started down this route because the referenced test did not use named graphs....
answer 13: Boris wrote: > If I instantiate a shared_memory_object with open_or_create how do I know > if it was opened or created? I ask as if it was created I need to create a > structure in the mapped region. If it was opened though I must not create > a structure (as another program created the structure before and I might > overwrite data). > > I ran into this problem after creating a reader and writer. They exchange > data using a shared_memory_object. It would be great if I could start the > two programs in any order. But currently the programs don't know which one > created and which one opened the shared memory. Do I miss anything or was > open_or_create added for another use case? > > Boris Since you must create an object to share between both, use find_or_construct<> on both processes (supposing both have enough information to create the shared structure) before doing anything. If the object is already created, the function will return a pointer to the already created structure. Regards, Ion...
answer 14: Boost Community, I'm trying to create a custom velocity unit. I would like to create a unit that is in nautical miles per hour to represent my speed value. If I use pound_force.hpp as an example of units with more than one dimension I can create the following. BOOST_UNITS_DEFINE_BASE_UNIT_WITH_CONVERSIONS(metric, nautical_mile_per_hour, "nautical mile per hour", "nmi h^-1", factor, si::velocity, ???); If this is the right track, what id would I use and how do I know that it is unique? This seems forced. I would rather define this unit in terms of meters per second. Nautical miles is already in terms of meters and hours is also defined as a scale of seconds. Can I somehow use these two already defined units to create the new unit? How would I do this? Ryan...
answer 15: Hi all, I'm a new user of BOOST library. I'm creating a class that requires to do some multi threading stuff. The class I'm creating has a method... void Calculator::Calc(int value) { ... } In order to run multiple Calc() in different threads, I created another method FindResult() the implementation was... void Calculator::FindResult(int numbers) { thread_group group; boost::function<void (Calculator *, int value)> boostFunction; boostFunction = &Calculator::Calc; for(int i=0; i<3; i++) { boost::thread * th = group.create_thread(&boostFunction); } } However, it seems it doesn't work at all... Is there any idea?? Cheers, -- Alexander Dong Back Kim Australia +61 433 469 100 / Korea +82 10 6357 8840...
- **avg_similarity**: 0.5101
- **max_similarity**: 0.7330
- **num_results**: 15
- **time_seconds**: 0.4167

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.732974648475647 |
| 2 | None | None | 0.6513186693191528 |
| 3 | None | None | 0.2699792981147766 |
| 4 | None | None | 0.5617326498031616 |
| 5 | None | None | 0.6023598909378052 |
| 6 | None | None | 0.6629781723022461 |
| 7 | None | None | 0.6734445691108704 |
| 8 | None | None | 0.23477984964847565 |
| 9 | None | None | 0.6048948168754578 |
| 10 | None | None | 0.5922538042068481 |
| 11 | None | None | 0.6439462304115295 |
| 12 | None | None | 0.2494298368692398 |
| 13 | None | None | 0.3110995888710022 |
| 14 | None | None | 0.2492387443780899 |
| 15 | None | None | 0.6112899780273438 |

## 9. Question

- **question**: How do I store different types of data in a `boost::any` object?
- **ground_truth**: `boost::any` can hold any type of data. You can assign values of any type to it and later retrieve them by casting. Example:
```cpp
boost::any a = 42; // storing an integer
int x = boost::any_cast<int>(a);
```
- **rag_answer**: answer 1: Fellow boost enthusiasts, I want to be able to store a set of information that contains types. For example: > template<typename T> > void register_field( const FieldID id ) > { > // need to keep a record of (T,id) > } Later on, I need to recover the type and id (T,id) for use. Any thoughts on a way to accomplish this? Thanks for any advice, James...
answer 2: On 3 November 2010 11:21, Hossein Haeri <powerprogman@yahoo.com> wrote: > Dear Nevin, > >> > In case you're wondering why I'd interested in such >> operators, the answer is that I'm thinking of storing >> objects of type boost::any in an unordered_map. >> >> Wouldn't this just be the address of the object (which >> isn't >> particularly useable as a key in a map)? > > So, what specifically is undesirable in Boost.Any for storing their addresses in containers? Storing its address, sure. Using that address as a key (which is the address of its location in the map)? How do you envision using that? Why would you need Boost.Any as the key type in that case? If this is really the functionality you need, maybe consider using a shared_ptr<void> instead. It certainly isn't something I'd like to see in Boost.Any, as that isn't usually what people mean by equality comparable. Take the following example given the semantics you propose: boost::any x(0); boost::any y(x); assert(x == y); // fails One that forwards the work to (lhs == rhs) for the underlying objects is much more interesting, but would require extending Boost.Any to implement it. It also means defining semantics for: 1. What to do if they hold the same type 2. What to do if they hold different types 3. What to do if one side is not a Boost.Any object 4....
answer 3: Iulian M wrote: > Hello, > > I'm trying to use boost::any to store a group of types. For value types > everything works as expected. The problem is that i need to store some > polymorphic types also. The following code explains what i'm trying to > accomplish. > > #include <boost/any.hpp> > > class A {}; //base calss > class B: public A {}; // derived class > > int main() > { > B *b = new B(); //create derived class > boost::any n(b); // place inside boost::any > > /* > other part of code where i only know n contains a pointer to a class > derived from A > this will throw bad_any_cast: typeid(A*) != typeid (B*) > */ > A* a = boost::any_cast<A*>(n); > } > > Is there any way of making boost::any_cast work work ok with "convertible" > types? Or is there a way of storing different types of objects and having the > possibility of retrieving them as compatible objects ? > > I've looked into any.hpp and found that it uses a typeid() equality test to > see if the cast can be made. Can't there be a is_convertible test insted , at > least for the case when is holding pointer to objects? There's no easy way for the boost.any code to work with polymorphic types as you expect since there's no current way to know what types are convertible at runtime....
answer 4: I have implemented the serialization routine for a rather complex structure with many nested classes. The serialization seems to work for small examples, however, for bigger data sets, I get a stack overflow error. If I increase the stack size from 8MB to 20MB, the examples seems to work. However, I'd like to optimize the code the way that I do not need to increase the stack size (especially, since not all users can do that themselves) So here are my questions: 1. Why is the required stack size different for different data sets different. The structure of the datasets is identical, only the number of data sets differs - so why is the recursive level different? The only thing I can imagine is, that I have a class (container) with a vector of objects. Each object stores a pointer to the container class. Is it possible that once serialization in the container class starts, that there is a recursive serialization pattern? This seems to be support by the fact that the objects in the container class are not serialized in the same way as they are stored in the container. class container { std::vector<object*> myObjects; }; class object { const container* myContainer; } 2. How can I try to decrease the required stack size for the serialization routines and is there a way to estimate the required stack size for a specific problem a priori, so that I can throw an exception with an error message manually instead of having a segmentation fault. Thanks for any suggestions JFU...
answer 5: What I did was make a function >> pointer >> to allow the user to define their own access function. They could >> write >> something along the lines of >> >> template<typename T> >> void* get_boost_any(boost::any* data) >> { >> return (void*)boost::any_cast<T>(data); >> } >> >> template<typename U, typename T1, typename T2, ... typename TN> >> void* get_boost_variant(boost::variant<T1,T2,...,TN>* data) >> { >> return (void*)boost::get<U>(data); >> } >> >> The problem with this is there is a separate function for each T >> created so >> a single function pointer doesn't quite work. > Those aren't function pointers. They are function templates. You're on the right track, but you're not using overloading to your advantage. You need a get function template that is overloaded for the various holder types. > > namespace custom > { > template<class T> > T & > get(boost::any & _value) > { > return boost:: any_cast<T>(_value); > } > } > > You then write code like the following for your access: > > custom::get<T>(value); > > Regardless of the value type, be it any, variant, or what have you, with an appropriate overload of get(), you'd be able to extract the value. IOW, your code determines the interface(s) needed for common interactions with the holder types, and then it relies on specializations and/or overloads to adapt to the holder types....
answer 6: On 5/5/2015 6:54 AM, James Armstrong wrote: > So, as it is currently implemented, it doesn't actually make use of > boost::any or boost::variants. I used a deque<void*> to store addresses of > the data, and deque<boost::core::typeinfo> to store the data types. > Therefore, iterating through the container to get the data for datatype T > simply involves iterating through the deque<boost::core::typeinfo> until a > type match is found, then casting the void* to a T* for the corresponding > index. > > There are definitely different ways to take the idea, and maybe there is > use for multiple types of heterogeneous containers. The way this container > is setup has the advantage (depending on your viewpoint) that you do not > have to explicit declare what data types the container will store up > front. This could be useful in some context where, for instance, you are > pulling information from a database where you don't quite know up front > whether certain fields will be numeric or character data until you've > queried the db. This container can allow you to pop in whatever data-type > the result is, without having to explicitly list out every possibility up > front. > Like I already said, all this is also true for std::vector<boost::any>. So I still don't understand how your container is better than std::vector<boost::any>....
answer 7: AMDG James Sutherland wrote: > Fellow boost enthusiasts, > > I want to be able to store a set of information that contains types. > For example: > > template<typename T> > void register_field( const FieldID id ) > { > // need to keep a record of (T,id) > } > > > Later on, I need to recover the type and id (T,id) for use. Any > thoughts on a way to accomplish this? > > Thanks for any advice, > > James How are you using T when you recover it? I assume that std::vector<std::pair<const std::type_info*, FieldID> > doesn't do what you need? If you need to recover T at compile time to do some template instantiations or something, then you can't use an ordinary container because you lose the static type information. If the set of possible types is known up front you can use Boost.Fusion. Otherwise, you can use some kind of type erasure to capture all the information about T that you need. In Christ, Steven Watanabe...
answer 8: > Well, my only suspicion is about the fact that I store "this" pointers in > my shared_ptr's. However, those objects are dynamically allocated by > myself, namely, they are not of automatic storage type anyway. In other > words, my row pointer and "this" -- which themselves are different > objects -- both point to the same memory dynamically allocated by myself. > Furthermore, my following observation goes against this guess: (This is > available above too.) Why do you need to use two semantically different pointers to point to the same piece of dynamic memory? > Actually it does allocate memory for other objects (which are stored in > the same container). But, I have tested that and the result is that > everything -- including this extra allocation -- works perfectly fine JUST > if I drop the insertion of this very specific object in the same > container. > Am I missing anything? I would especially be keen on knowing whether you > see any problems in storing "this" pointers of my own dynamically > allocated objects in shared_ptr's. You may need to show how "specific" the object is -- sometimes a few lines of code are better than paragraphs of words. Why do you need to put a "this" pointer in a shared_ptr? When you can get a hand on "this", you are in the member function of the class. Basically that means your instance has already been created. The client creating the instance should probably manage the life cycle of this instance....
answer 9: Sorry I think the explanation of my problem wasn't clear enough. I want to store some of my objects into a different archive without duplicating them. I have some kind of project file (Workspace) at my application which should be the "main" archiv and several document files (measurment data). The serialization process always start by loading/save this workspace object, because this object stores the location of the current opened measument objects. I noticed that I can create and load this kind of archiv structue as following: template<class Archive> void save(Archive & ar, const unsigned int version) const { ar & BOOST_SERIALIZATION_NVP(m_FileName); // store the file name of the archiv std::ofstream ofs(m_FileName.c_str()); assert(ofs.good()); boost::archive::xml_oarchive oa(ofs); oa << BOOST_SERIALIZATION_NVP(m_SignalList); // store the child objects into the new archiv } But I don't know how I can serialize a reference on a object located at a different archiv. I need such references from workspace object to store a persistent view object. The Object Tracking works only within a archive. Any ideas or suggestions on this problem? Regards, Stefan >Von: boost-users-bounces@lists.boost.org [mailto:boost-users-bounces@lists.boost.org] Im Auftrag von Robert Ramey >Gesendet: Freitag, 23....
answer 10: Hello In a callback function I need to store and save an exception object for until the callback is finished and the control is returned to my application code. The callback is invoked by the C language code in minizip library from zlib-1.2.3 contrib directory, and I need to throw the exception when control returns to my application invoking minizip functions. This is true for any exception that might get thrown and caught in my callback, so I would like to do that for any exception type. However how can I store a thrown object for later re-throw without the actual exception type ? Is there a way to do that ? Thank you, Timothy Madden...
answer 11: The container will take care about how to store data. So one can have * integer_t<std::vector> (for generic implementation), * integer_t<boost::array> (for fixed-length), * integer_t<vector_fixed_capacity>, * integer_t<very_secure_vector> (for very secure arithmetic), * integer_t<copy_on_write_vector> (if one want copy on write optimisation) * etc This solution requires the container interface to be extended through global functions(see below), but I think that finally we get very extensible and easy to use integer_t. For example: xint::push_back is used in operator+ and operator- when we need to add most significant digit. * for std::vector it does simple push_back * for boost::array it may do nothing (silent overflow behavior) or throw an exception (if we don't want overflow to happen) xint::trim is used when we need to trim most significant zeros. * for std::vector it does resize * for boost::array it does nothing Another option could be wrapping containers into some entity with interface suitable for integer_t needs. One more thought about "secure" option. There are no standard containers with this option. I think either both standard containers and integer_t should have such option or both shouldn't have. This is yet another argument for container parametrization. 2. Signed Zero. I'm sure that long integer arithmetic should behave as close to native integer numbers as possible. Native integer types don't have negative zero....
answer 12: using something like boost::get<T>()? > I would actually prefer not to use type erasure: make a strong-typed and efficient heterogenous container. Something like this... ? template <typename... Args> struct tuple_vector : std::tuple< std::vector<Args>... > { typename std::tuple<Args...> type; template <typename T> void push_back(const T& value) { std::get< std::vector<T> >(*this).push_back(value); } template <typename T> void push_back( T&& value) { std::get< std::vector<T> >(*this).push_back(value); } }; struct Point { double x; double y; }; struct Line { double x; double y; double a; double l; }; struct Rectangle { double x; double y; double a; double w; double h; }; struct Circle { double x; double y; double r; }; tuple_vector<Point, Line, Rectangle, Circle> shapes; shapes.push_back(Point{1.0, 1.0} ); shapes.push_back(Point{1.0, 1.0} ); shapes.push_back(Circle{1.0, 1.0, .3} ); shapes.push_back(Rectangle{0.0, 0.0, 0.0, 1.0, 1.0} );...
answer 13: > } > > > > -------------------------------------------------- > From: "Steven Watanabe" <watanabesj@gmail.com> > Sent: Tuesday, August 31, 2010 11:04 AM > To: <boost-users@lists.boost.org> > Subject: Re: [Boost-users] How to store on exception object ? > >> AMDG >> >> Timothy Madden wrote: >>> In a callback function I need to store and save an exception object >>> for until the callback is finished and the control is returned to my >>> application code. The callback is invoked by the C language code in >>> minizip library from zlib-1.2.3 contrib directory, and I need to >>> throw the exception when control returns to my application invoking >>> minizip functions. >>> >>> This is true for any exception that might get thrown and caught in my >>> callback, so I would like to do that for any exception type. >>> >>> However how can I store a thrown object for later re-throw without >>> the actual exception type ? Is there a way to do that ? >> >> I think this is what boost::exception_ptr is for. >> http://www.boost.org/libs/exception/doc/exception_ptr.html >> >> In Christ, >> Steven Watanabe >> >> _______________________________________________ >> Boost-users mailing list >> Boost-users@lists.boost.org >> http://lists.boost.org/mailman/listinfo.cgi/boost-users >>...
answer 14: Hello. Context: ------- I use the boost serialization library to save and load objects of a system. I defined practices around this lib, and so I always serialize from a base class (every class serializable inherits from ISerializable). As a consequence, the true_type (i.e. the most derived type) is different from the this_type (i.e. ISerializable) and the true_type is stored in the archives. My question: ----------- How to retreive this true_type (as the string written in the archive), only from the archive object? I developp just a little bit: ---------------------------- Let's have this class tre: ISerializable <|-- B <|-- D If I do : B* b = new D(); b->SaveToFile(path); // <= this will do the serialization ar & this (this being a ISerializable*) I obtain an archive where it is written the true_type "D" (whatever the type of the archive : txt, bin or xml). With the b object and this code : const boost::serialization::extended_type_info & true_type = * boost::serialization::type_info_implementation<ISerializable>::type ::get_const_instance().get_derived_extended_type_info(*b); I have what I want in true_type.get_key(), i.e : "D". I can verify that "D" is written in every archive storing b. My question again : how, only with an archive object (construct from the archive file without error), car I retrieve this key? Tanks for any help. Nicolas....
answer 15: Any ideas on how to store the type of an object stored in an any instance for later use in comparisons (like <, >, ==, etc)? I don't want to store an instance of the class unless necessary. I thought about storing a pointer to the type, but could that be used with any_cast? like: template<class type> class typestuffPOD { typedef type value_type; type *datatype_; } This requires knowing the type when you want to use the any_cast. Sincerely, Joe McCay...
- **avg_similarity**: 0.5109
- **max_similarity**: 0.7650
- **num_results**: 15
- **time_seconds**: 0.4169

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.6727545261383057 |
| 2 | None | None | 0.7155938148498535 |
| 3 | None | None | 0.7650298476219177 |
| 4 | None | None | 0.23880404233932495 |
| 5 | None | None | 0.6440930962562561 |
| 6 | None | None | 0.6592937707901001 |
| 7 | None | None | 0.6330207586288452 |
| 8 | None | None | 0.33362916111946106 |
| 9 | None | None | 0.43234550952911377 |
| 10 | None | None | 0.1273702085018158 |
| 11 | None | None | 0.596653938293457 |
| 12 | None | None | 0.5343234539031982 |
| 13 | None | None | 0.25346794724464417 |
| 14 | None | None | 0.47663646936416626 |
| 15 | None | None | 0.5799923539161682 |

## 10. Question

- **question**: How do I remove a file using Boost.Filesystem?
- **ground_truth**: You can remove a file by using `boost::filesystem::remove()`:
```cpp
boost::filesystem::remove("myfile.txt");
```
- **rag_answer**: answer 1: : >>>> >>>> fsys::directory_iterator it{path}, itEnd{}; >>>> for ( ; it != itEnd ; ) >>>> { >>>> if (predicate(*it)) >>>> fsys::remove((it++)->path()); >>>> else >>>> ++it; >>>> } >>> >>> >>> >>> From the documentation, it seems the behavior should be similar to >>> readdir, >>> in which case it would seem that both pieces of code above are valid. >> >> >> Indeed, boost::filesystem and std::filesystem (ISO/IEC TS 18822:2015) as >> well >> as POSIX readdir behave in the same way. >> But, for all of them, behaviour is unspecified in case content of >> directory that is >> being traversed changes. > > > It is unspecified whether the removed/added files will be discovered as part > of the traversal. Other than that the behavior is defined. For instance, the > implementation should not crash and the iterator should still reach the end > at some point. Right, the iteration following any changes in the filesystem content remains valid. Thanks for the correction. Best regards, -- Mateusz Loskot, http://mateusz.loskot.net...
answer 2: On 01/20/2012 05:13 AM, toran wrote: > I am having trouble deleting files with boost::filesystem. Following code does > not work for me (and I can't find the doc that explains how to do it). > > boost::filesystem::path pt("somepath"); > pt /= ("*.data"); > boost::filesystem::remove(pt); > > pt variable points to the valid set of files, but removal does not happened. > > I will appreciate an advise and may be pointing me to the right place in the > docs. Thanks. As far as I know there is no such thing as wildcard replacement in filesystem. So unless your file is not actually named "*.data" it won't be found. If you're trying to delete every .data file in a directory, you'd need to use the (recursive_)directory_iterator and the .extension() member function of the path object. And be aware that the iterator is invalidated when you remove a file. See this similar question at Stackoverflow: http://stackoverflow.com/questions/1257721/can-i-use-a-mask-to-iterate-files-in-a-directory-with-boost And be aware that filesystem::remove() returns a bool indicating if the file existed, so it'd be easy to check in your code. See http://www.boost.org/doc/libs/1_48_0/libs/filesystem/v3/doc/reference.html#remove Norbert...
answer 3: I am having trouble deleting files with boost::filesystem. Following code does not work for me (and I can't find the doc that explains how to do it). boost::filesystem::path pt("somepath"); pt /= ("*.data"); boost::filesystem::remove(pt); pt variable points to the valid set of files, but removal does not happened. I will appreciate an advise and may be pointing me to the right place in the docs. Thanks....
answer 4: https://msdn.microsoft.com/en-us/library/windows/desktop/aa363915%28v= vs.85%29.aspx. [square brackets stuff added by me] Longer answer: the Windows NT kernel was originally the next edition of the VAX VMS kernel, and was considered by many to have a set of superior, if more conservative, design choices to the Unixes of the day which ended up becoming POSIX. Many of the NT kernel APIs are very similar to those of VMS as a result. One interesting feature of the VMS filesystem was that when you deleted a file, the system went off and securely scrubbed the contents before doing the deletion, a process which could take considerable time. NTFS and Windows NT inherited that behaviour, and it was furthermore considered valuable for secure by design code to lock out use of a file being deleted because it makes inode swapping tricks and other such security holes on POSIX systems impossible on VMS and NT systems. NT absolutely allows you to explicitly opt into POSIX semantics by renaming a file before deletion as AFIO does, this leads to default more secure semantics than the POSIX default behaviour. Ultimately of course the ship has sailed, and POSIX is now the standard. NT reflects a continuing objection to many design failures in POSIX especially around the filesystem where POSIX has many deeply flawed design decisions. As a result of the above behaviours, unfortunately the lion's share of code out there written for Windows which deals with the filesystem is simply wrong....
answer 5: On 18 March 2012 13:14, Steven Watanabe <watanabesj@gmail.com> wrote: > > cd boost/filesystem > svn cp ^/trunk/boost/filesystem ^/branches/filesystem_v3/boost/filesystem > svn switch ^/trunk/boost/filesystem Should that be: svn switch ^/branches/filesystem_v3/boost/filesystem > svn rm *.hpp > svn mv v3/*.hpp . > svn rm v2 v3 > # modify headers > svn commit -m "Remove Filesystem V2" > svn switch ^/trunk/boost/filesystem > svn merge --reintegrate ^/branches/filesystem_v3/boost/filesystem > svn commit -m "Merge back to trunk" > > FWIW, if you're doing this in one go, there's > no good reason to create a branch. Also, if we eventually switch to git, I don't think git will understand that the file has moved, since there was already a file in the new location. There might be a benefit to having an intermediate version with the file missing (although, there might not, I don't how well the git conversion will handle it)....
answer 6: On 7 September 2016 at 16:45, Andrey Semashev <andrey.semashev@gmail.com> wrote: > On 09/07/16 17:07, Mateusz Loskot wrote: >> On 7 September 2016 at 15:46, Andrey Semashev <andrey.semashev@gmail.com> wrote: >>> On 09/07/16 16:06, Andrzej Krzemienski wrote: >>>> >>>> >>>> Hi, >>>> I wonder what is boost::filesystem recommendation for solving the >>>> following >>>> problem. >>>> >>>> I want to remove all files from a given directory that satisfy a certain >>>> predicate, e.g., only these whose names start with letter "s". >>>> >>>> It is my understanding that the calling filesystem::remove may >>>> invalidate >>>> the iterator, and therefore the following solution is incorrect: >>>> >>>> fsys::directory_iterator it{path}, itEnd{}; >>>> for ( ; it != itEnd ; ++it ) >>>> { >>>> if (predicate(*it)) >>>> fsys::remove(it->path()); >>>> } >>>> >>>> But, is the following guaranteed to work?...
answer 7: On 18 March 2012 15:27, Dave Abrahams <dave@boostpro.com> wrote: > > on Sun Mar 18 2012, Daniel James <dnljms-AT-gmail.com> wrote: > >> On 18 March 2012 13:14, Steven Watanabe <watanabesj@gmail.com> wrote: >>> >>> cd boost/filesystem >>> svn cp ^/trunk/boost/filesystem ^/branches/filesystem_v3/boost/filesystem >>> svn switch ^/trunk/boost/filesystem >> >> Should that be: >> >> svn switch ^/branches/filesystem_v3/boost/filesystem >> >>> svn rm *.hpp >>> svn mv v3/*.hpp . >>> svn rm v2 v3 >>> # modify headers >>> svn commit -m "Remove Filesystem V2" >>> svn switch ^/trunk/boost/filesystem >>> svn merge --reintegrate ^/branches/filesystem_v3/boost/filesystem >>> svn commit -m "Merge back to trunk" >>> >>> FWIW, if you're doing this in one go, there's >>> no good reason to create a branch. >> >> Also, if we eventually switch to git, I don't think git will >> understand that the file has moved, since there was already a file in >> the new location. There might be a benefit to having an intermediate >> version with the file missing (although, there might not, I don't how >> well the git conversion will handle it). > > I don't think so....
answer 8: On 7 September 2016 at 15:46, Andrey Semashev <andrey.semashev@gmail.com> wrote: > On 09/07/16 16:06, Andrzej Krzemienski wrote: >> >> Hi, >> I wonder what is boost::filesystem recommendation for solving the >> following >> problem. >> >> I want to remove all files from a given directory that satisfy a certain >> predicate, e.g., only these whose names start with letter "s". >> >> It is my understanding that the calling filesystem::remove may invalidate >> the iterator, and therefore the following solution is incorrect: >> >> fsys::directory_iterator it{path}, itEnd{}; >> for ( ; it != itEnd ; ++it ) >> { >> if (predicate(*it)) >> fsys::remove(it->path()); >> } >> >> But, is the following guaranteed to work?: >> >> fsys::directory_iterator it{path}, itEnd{}; >> for ( ; it != itEnd ; ) >> { >> if (predicate(*it)) >> fsys::remove((it++)->path()); >> else >> ++it; >> } > > > From the documentation, it seems the behavior should be similar to readdir, > in which case it would seem that both pieces of code above are valid. Indeed, boost::filesystem and std::filesystem (ISO/IEC TS 18822:2015) as well as POSIX readdir behave in the same way....
answer 9: on Sun Mar 18 2012, Daniel James <dnljms-AT-gmail.com> wrote: > On 18 March 2012 13:14, Steven Watanabe <watanabesj@gmail.com> wrote: >> >> cd boost/filesystem >> svn cp ^/trunk/boost/filesystem ^/branches/filesystem_v3/boost/filesystem >> svn switch ^/trunk/boost/filesystem > > Should that be: > > svn switch ^/branches/filesystem_v3/boost/filesystem > >> svn rm *.hpp >> svn mv v3/*.hpp . >> svn rm v2 v3 >> # modify headers >> svn commit -m "Remove Filesystem V2" >> svn switch ^/trunk/boost/filesystem >> svn merge --reintegrate ^/branches/filesystem_v3/boost/filesystem >> svn commit -m "Merge back to trunk" >> >> FWIW, if you're doing this in one go, there's >> no good reason to create a branch. > > Also, if we eventually switch to git, I don't think git will > understand that the file has moved, since there was already a file in > the new location. There might be a benefit to having an intermediate > version with the file missing (although, there might not, I don't how > well the git conversion will handle it). I don't think so. John's SVN->Git conversion knows about svn mv operations, but if you delete and recreate a file somewhere else it isn't going to realize you moved something....
answer 10: >> >> What I'd like to do is: >> >> * create a branch, >> * switch to it, >> * delete the top level forwarding headers, >> * move the v3 headers up to boost/filesystem, >> * delete the v2 and v3 directories, >> * modify the headers as needed, >> * merge back to trunk. >> >> At the completion of the merge, the history for the boost/filesystem >> headers should include the full history of what were the >> boost/filesystem/v3 headers. >> >> What are the svn commands to accomplish that? >> > > cd boost/filesystem > svn cp ^/trunk/boost/filesystem ^/branches/filesystem_v3/boost/filesystem > svn switch ^/trunk/boost/filesystem > svn rm *.hpp > svn mv v3/*.hpp . > svn rm v2 v3 > # modify headers > svn commit -m "Remove Filesystem V2" > svn switch ^/trunk/boost/filesystem > svn merge --reintegrate ^/branches/filesystem_v3/boost/filesystem > svn commit -m "Merge back to trunk" OK, thanks! I'll give it a try. > FWIW, if you're doing this in one go, there's > no good reason to create a branch. The actual steps are somewhat more complex because there are a parallel set of changes to libs/filesystem. I'll do some testing along the way. Using Git on other projects, I've gotten used to creating branches more often and doing commits along the way....
answer 11: -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA1 Hi! I've read the discussion and want to provide some words of caution. Am 18.03.12 14:14, schrieb Steven Watanabe: > cd boost/filesystem svn cp ^/trunk/boost/filesystem > ^/branches/filesystem_v3/boost/filesystem svn switch > ^/trunk/boost/filesystem svn rm *.hpp svn mv v3/*.hpp . svn rm v2 > v3 # modify headers svn commit -m "Remove Filesystem V2" svn switch > ^/trunk/boost/filesystem svn merge --reintegrate > ^/branches/filesystem_v3/boost/filesystem svn commit -m "Merge back > to trunk" The --reintegrate option requires a merge of trunk to the branch beforehand if there have been commits to trunk since creation of the branch. Simply not using this option will merge the changes into the trunk correctly here. Using a separate branch to do the work will encourage a single merge into the trunk at the end. The commit "Merge back to trunk" will delete files and create moved files in their place. This triggers the git move problem Daniel mentioned. You can merge two times, though, by first merging just up to that revision that deleted the files and then merging the rest. Creating the branch from /trunk enables working on /boost/filesystem and /libs/filesystem at the same time at no additional costs with svn....
answer 12: : >> >> fsys::directory_iterator it{path}, itEnd{}; >> for ( ; it != itEnd ; ) >> { >> if (predicate(*it)) >> fsys::remove((it++)->path()); >> else >> ++it; >> } > > > From the documentation, it seems the behavior should be similar to readdir, > in which case it would seem that both pieces of code above are valid. Indeed, boost::filesystem and std::filesystem (ISO/IEC TS 18822:2015) as well as POSIX readdir behave in the same way. But, for all of them, behaviour is unspecified in case content of directory that is being traversed changes. Best regards, -- Mateusz Loskot, http://mateusz.loskot.net...
answer 13: On 09/07/16 16:06, Andrzej Krzemienski wrote: > Hi, > I wonder what is boost::filesystem recommendation for solving the following > problem. > > I want to remove all files from a given directory that satisfy a certain > predicate, e.g., only these whose names start with letter "s". > > It is my understanding that the calling filesystem::remove may invalidate > the iterator, and therefore the following solution is incorrect: > > fsys::directory_iterator it{path}, itEnd{}; > for ( ; it != itEnd ; ++it ) > { > if (predicate(*it)) > fsys::remove(it->path()); > } > > But, is the following guaranteed to work?: > > fsys::directory_iterator it{path}, itEnd{}; > for ( ; it != itEnd ; ) > { > if (predicate(*it)) > fsys::remove((it++)->path()); > else > ++it; > } From the documentation, it seems the behavior should be similar to readdir, in which case it would seem that both pieces of code above are valid. Although I would prefer the second one as it is more in line with common practices in C++. > If not, does there exist a dedicated solution for solving this problem that > would not require of me N traversals through the directory? If you still want a different solution, you could collect the matching file names on the directory traversal and delete the files in the second loop....
answer 14: >>>> >>>> I want to remove all files from a given directory that satisfy a certain >>>> predicate, e.g., only these whose names start with letter "s". >>>> >>>> It is my understanding that the calling filesystem::remove may >>>> invalidate >>>> the iterator, and therefore the following solution is incorrect: >>>> >>>> fsys::directory_iterator it{path}, itEnd{}; >>>> for ( ; it != itEnd ; ++it ) >>>> { >>>> if (predicate(*it)) >>>> fsys::remove(it->path()); >>>> } >>>> >>>> But, is the following guaranteed to work?: >>>> >>>> fsys::directory_iterator it{path}, itEnd{}; >>>> for ( ; it != itEnd ; ) >>>> { >>>> if (predicate(*it)) >>>> fsys::remove((it++)->path()); >>>> else >>>> ++it; >>>> } >>> >>> >>> >>> From the documentation, it seems the behavior should be similar to >>> readdir, >>> in which case it would seem that both pieces of code above are valid. >> >> >> Indeed, boost::filesystem and std::filesystem (ISO/IEC TS 18822:2015) as >> well >> as POSIX readdir behave in the same way. >> But, for all of them, behaviour is unspecified in case content of >> directory that is >> being traversed changes. > > > It is unspecified whether the removed/added files will be discovered as part > of the traversal. Other than that the behavior is defined....
answer 15: On 09/07/16 17:07, Mateusz Loskot wrote: > On 7 September 2016 at 15:46, Andrey Semashev <andrey.semashev@gmail.com> wrote: >> On 09/07/16 16:06, Andrzej Krzemienski wrote: >>> >>> Hi, >>> I wonder what is boost::filesystem recommendation for solving the >>> following >>> problem. >>> >>> I want to remove all files from a given directory that satisfy a certain >>> predicate, e.g., only these whose names start with letter "s". >>> >>> It is my understanding that the calling filesystem::remove may invalidate >>> the iterator, and therefore the following solution is incorrect: >>> >>> fsys::directory_iterator it{path}, itEnd{}; >>> for ( ; it != itEnd ; ++it ) >>> { >>> if (predicate(*it)) >>> fsys::remove(it->path()); >>> } >>> >>> But, is the following guaranteed to work?: >>> >>> fsys::directory_iterator it{path}, itEnd{}; >>> for ( ; it != itEnd ; ) >>> { >>> if (predicate(*it)) >>> fsys::remove((it++)->path()); >>> else >>> ++it; >>> } >> >> >> From the documentation, it seems the behavior should be similar to readdir, >> in which case it would seem that both pieces of code above are valid....
- **avg_similarity**: 0.4672
- **max_similarity**: 0.7596
- **num_results**: 15
- **time_seconds**: 0.4259

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.44476887583732605 |
| 2 | None | None | 0.6961866617202759 |
| 3 | None | None | 0.7595868706703186 |
| 4 | None | None | 0.21280093491077423 |
| 5 | None | None | 0.38978782296180725 |
| 6 | None | None | 0.5462499260902405 |
| 7 | None | None | 0.44437116384506226 |
| 8 | None | None | 0.5279938578605652 |
| 9 | None | None | 0.4289568066596985 |
| 10 | None | None | 0.36825031042099 |
| 11 | None | None | 0.33887261152267456 |
| 12 | None | None | 0.46068477630615234 |
| 13 | None | None | 0.49388566613197327 |
| 14 | None | None | 0.3599710762500763 |
| 15 | None | None | 0.53626549243927 |

## 11. Question

- **question**: How can I sort a container using Boost.Algorithm?
- **ground_truth**: Boost provides algorithms for sorting, such as `boost::algorithm::sort`. Example:
```cpp
#include <boost/algorithm/string.hpp>
std::vector<int> v = {4, 3, 1, 2};
boost::sort(v); // Sorting in ascending order
```
- **rag_answer**: answer 1: I am using below composite container. Finally I am looking to sort...
answer 2: Mathias Gaunard wrote: > Phil Endecott wrote: > >> - It would be good if the docs were explicit about this being a thin >> wrapper around your existing std::sort, and identifying those algorithms >> that are not so thin. > > Actually, I believe sort(c) calls c.sort() if it exists. > So it's not just std::sort. I don't see any evidence of that in boost/range/algorithm/sort.hpp. Where should I be looking? This would of course be a useful feature, and documenting whether it is or is not done would be useful. >> unique(vec); >> My point is that std::unique only has its "move duplicates to the end" >> behaviour because the conventional interface with a pair of iterators >> doesn't let you change the size of the container. Now that we have a >> unique() that takes a container we don't need that restriction. > > Not a container, a range. The fact that the container that I pass is converted to a range can be considered as an implementation detail for many applications of this library. There is a lot of stuff in C++ that is more complicated to use than it could be. We have all got used to how things are and know the reasons why, but it presents an obstacle to new users. This library reduces some of this complexity, which is really great. I suggest that we consider how much further we can go in this direction. Maybe algorithms that really take containers, rather than ranges, are beyond the scope of this library. Or maybe not....
answer 3: Sure. But I have no guarantee that input data is in another vector, the container just receives just a range of iterators I can't modify, just read. So I should: -> allocate a new buffer to store 130 elements -> Copy new elements to the back of the buffer (last 30 positions) -> Sort them using 15 elements of additional storage from that buffer. -> Merge the old buffer and the newly sorted elements in the first positions of the new buffer. -> Destroy last 30 positions of the new buffer. The problem is that we don't want to reallocate in every range input, only when capacity is filled. Extra memory is not small when the input is bigger than the stored element count. E.g.: You have a vector of 30 elements and range to insert has 10000 elements, I'd need to allocate a buffer of 15000 elements, extra 5000 elements only to do the initial sort. Obviously, your N/2 is much better than N. The ideal (not from a performance point of view, but from a "balanced" point of view) would be: Consider: N = size() //current flat_xxx size M = std::distance(first, last) //range to insert T = M+N If capacity() > N + M (vector is NOT reallocated) --------------------------------------------------- -> No new memory is allocated -> new elements are copied at the end of the already inserted elements. -> stable_sort in new elements passing the remaining capacity of the vector as a temporary buffer....
answer 4: Hello, I am developing a library called Stxxl. It is an implementation of STL for external memory (out-of-core) computations, i.e. Stxxl implements containers and algorithms that can process huge volumes of data that only fit on disks. Currently I have implemented vector, stack, and priority_queue. External memory map, list, and queue are coming soon. The containers take only specified (given) fixed amount of main memory, but can contain more elements than can fit into the main memory. The containers are compatible with STL algorithms, an example: #include <stxxl> // ten billion doubles stxxl::vector<double> HugeVector(10ULL * 1000000000ULL); std::fill(HugeVector.begin(), HugeVector.end(), 0.0); STL algorithms that rely on Output, Input, Forward and Bidirectional iterators will work I/O efficiently with Stxxl containers. For the RandomAccessIterator algorithms (sortting) I have implemented specialized I/O efficient implementations: // ten billion doubles stxxl::vector<double> HugeVector(10ULL * 1000000000ULL); std::generate(HugeVector.begin(), HugeVector.end(), MyRandom()); // sort the vector using only 512 MB of main memory stxxl::sort(HugeVector.begin(), HugeVector.end(), 128*1024*1024); or another example (sort a file): stxxl::file myfile("../myfile.dat",stxxl::file::RDWR); stxxl::vector<double> HugeVector(&myfile); // sort the vector using only 512 MB of main memory stxxl::sort(HugeVector.begin(), HugeVector.end(), 128*1024*1024); More details about the Stxxl library: http://i10www.ira.uka.de/dementiev/stxxl.shtml Would such a library be interesting for Boost users?...
answer 5: On 21/09/2015 20:53, Phil Endecott wrote: > Ion Gazta?aga wrote: >> I'm trying to improve insertion times for flat associative containers. >> In range insertions one optimization is to insert the whole range in >> the end of the container and sort the whole vector instead of trying a >> loop. > > Hi Ion, > > We've discussed this before... > > Why do you (still) want to sort the whole container, rather than just > sorting the new items and then using inplace_merge? Well, I actually want to have both merge and sort. And yes, if understand this correctly sort + merge would be faster. In any case the idea is to have both (sort and merge) as adaptable algorithms, so that the extra capacity of the vector can be used to speed up the both sort and merge. For already sorted inputs and multikey containers, when size()+std::distance(begin, end) > capacity(), then a usual O(N) merge can be done in the newly allocated memory. The latest version of flat containers (Boost 1.59) already does this. > The idea of using the allocated-but-unused part of the buffer for > temporary storage is an interesting one, which would benefit > inplace_merge as well as stable_sort. Have you tried to quantify > the benefits? Not yet, but if known algorithms are used, the difference between inplace_sort|merge and sort|merge is theoretically big. Merge becomes O(N) instead of O(NlogN)....
answer 6: I am having below composite container. I am looking to sort the container by member<CA,std::string,&CA::card> at the end. Can some one help me to achieve this? typedef multi_index_container< CA, indexed_by< ordered_unique< composite_key< CA, member<CA,std::string,&CA::name>, member<CA,std::string,&CA::displayName>, member<CA,std::string,&CA::card> > > > > duplicateBook; Regards, UJ...
answer 7: Is it possible to sort the container by value? In below example by "member<Element_Entry,size_t,&Element_Entry::Id>" Or also other keys like: Sort by "member<Element_Entry,size_t,&Element_Entry::Index>" typedef multi_index_container< Element_Entry, indexed_by< ordered_non_unique< composite_key< Element_Entry, member<Element_Entry,size_t,&Element_Entry::MatId>, member<Element_Entry,double,&Element_Entry::Thickness>, member<Element_Entry,double,&Element_Entry::Angle>, member<Element_Entry,size_t,&Element_Entry::Index> > >, ordered_unique< member<Element_Entry,size_t,&Element_Entry::Id> > > > ElementRecord; Regards, UJ...
answer 8: Hi Jon, If the elements in the flat associative container are sorted, you need only to sort the elements to insert and after do a fusion of the two parts. If your container admit repeated elements, you can use the std::sort, if not, you must use an stable sort , and delete the repeated. You have several algorithms for to do a stable sort. In the library we are developing (https://github.com/fjtapia/sort_parallel ) you have a smart_merge_sort, which is a very fast stable sort and use only one half of the memory used by the data, is exception safe and use the move semantics I didn't see any implementation of the stable sort algorithms without additional memory, in any library GCC, TBB, IPP â¦ I suppose because they are slow. If you have 100 elements and want to insert 30 elements, need to resize the vector to 130 elements, the last 30 are empty. If you have other vector with the data to insert, you can use smart_merge_sort, and use as auxiliary memory the last 15 elements of the main vector. After sort, delete the repeated elements. And with the two vectors you must do a half_merge fusion , and all is done. With this method you need only the vector for to sort the elements to insert. If you want I can write a small program doing this, using the code of the library....
answer 9: > > I could try to use std::sort/std::stable_sort but there are some problems: > > -> Non-portable for C++03 compilers and Boost.Move, and Boost.Container > fully supports those platforms. > Do you have example current users of your library who need this portability? It would help me to understand an actual use case. > So I started analyzing several papers and implementations to see if a > custom implementation was possible, but I felt Boost.Sort could be a > good place to have that implementation and the Boost community a good > place to discuss design alternatives. > That's reasonable. > My initial requirements: > > 1) Stable sort. A non-stable sort is faster and useful for unique keys > containers, but stable sort can be used initially in all flat containers > until the non-stable version is implemented. > > 2) Externally supplied auxiliary memory with optionally no auxiliary > memory at all. It seems that there are newer algorithms like Grailsort > (https://github.com/Mrrl/GrailSort) or WikiSort > (https://github.com/BonzaiThePenguin/WikiSort) that claim O(1) memory, > even no auxiliary buffer, and key comparison and data exchanges with > complexity O(n*log(n)). However I don't think those implementation > correctly handle the basic exception guarantee or non-trivially copyable > types. > > Reason: I want to avoid allocating short-lived temporary memory: if it's > available I want to pass the extra capacity that flat containers' > internal vector holds for future insertions....
answer 10: On 22/09/2015 6:58, Francisco JosÃ© Tapia wrote: > Hi Jon, > > If the elements in the flat associative container are sorted, you need only > to sort the elements to insert and after do a fusion of the two parts. Yes, I understand that merge has better complexity guarantees than sort, sincethe already stored elements are sorted, it's better to sort the new elements and merge. > If your container admit repeated elements, you can use the std::sort, if > not, you must use an stable sort , and delete the repeated. I don't think I could use std::sort as is unstable, if there are repeated elements, I should only keep the first occurrence, so I need stability while sorting. In any case, I can't use standard algorithms as as I'd like some traits support to customize basic operations (swap, move, uninitialized_move) in order to use Boost.Move or future destructive move operations. > You have several algorithms for to do a stable sort. In the library we are > developing (https://github.com/fjtapia/sort_parallel ) you have a > smart_merge_sort, which is a very fast stable sort and use only one half of > the memory used by the data, is exception safe and use the move semantics Very nice! Is the N/2 memory requirement achieved with techniques similar to those described here?...
answer 11: A non-stable sort is faster and useful for unique keys > containers, but stable sort can be used initially in all flat containers > until the non-stable version is implemented. > > 2) Externally supplied auxiliary memory with optionally no auxiliary > memory at all. It seems that there are newer algorithms like Grailsort > (https://github.com/Mrrl/GrailSort) or WikiSort > (https://github.com/BonzaiThePenguin/WikiSort) that claim O(1) memory, > even no auxiliary buffer, and key comparison and data exchanges with > complexity O(n*log(n)). However I don't think those implementation > correctly handle the basic exception guarantee or non-trivially copyable > types. > > Reason: I want to avoid allocating short-lived temporary memory: if it's > available I want to pass the extra capacity that flat containers' > internal vector holds for future insertions. > Please figure out your full set of requirements, state them, and then list algorithms that fulfill them (if any). Spreadsort and other radix-based sorts are capable of being stable if you give them enough RAM and structure the computation properly, and are quite fast properly used. Would it be ok to have a full copy of pointers to the elements?...
answer 12: - Do we really want this in the top-level boost:: namespace? There have been discussions about sorting libraries for Boost who might also want boost::sort. Would it not be better to put these algorithms in a boost::range namespace? Then we move on to the algorithms where you can select what is returned using a template parameter. This is an interesting idea, but it's a little verbose and I can't think of any precedent for it in the std library or elsewhere in Boost. Being unfamiliar increases the learning curve for a feature. I was wondering if it would be possible to have something more like: boost::unique(rng).found instead of boost::unique<boost::return_found>(rng) Or maybe not; just a thought. You then have this example for sorting and removing duplicates: boost::erase( vec, boost::unique<boost::return_found_end>( boost::sort(vec) ) ); Err... yuk. Why can't I write: unique(vec); Or maybe unique(sort(vec)); or sort(vec); unique(vec); My point is that std::unique only has its "move duplicates to the end" behaviour because the conventional interface with a pair of iterators doesn't let you change the size of the container. Now that we have a unique() that takes a container we don't need that restriction. I recently tried to write a starts_with algorithm: template <typename CONTAINER> bool starts_with(const CONTAINER& a, const CONTAINER& b) { // does a start with b ?...
answer 13: My initial requirements: 1) Stable sort. A non-stable sort is faster and useful for unique keys containers, but stable sort can be used initially in all flat containers until the non-stable version is implemented. 2) Externally supplied auxiliary memory with optionally no auxiliary memory at all. It seems that there are newer algorithms like Grailsort (https://github.com/Mrrl/GrailSort) or WikiSort (https://github.com/BonzaiThePenguin/WikiSort) that claim O(1) memory, even no auxiliary buffer, and key comparison and data exchanges with complexity O(n*log(n)). However I don't think those implementation correctly handle the basic exception guarantee or non-trivially copyable types. Reason: I want to avoid allocating short-lived temporary memory: if it's available I want to pass the extra capacity that flat containers' internal vector holds for future insertions. 3) Customization points (without ADL, which IMHO is not customizable enough). The sort algorithm should use a SortTraits template parameter for basic operations like "move", "swap", "initialized_move". E.g: template<class T> struct sort_traits { static? void move(T &from, T &to); static? void swap(T &l, T &r); static?...
answer 14: > One of the most important features of the stl is that it separates > algorithms from the container types they operate on. Most of these > algorithms already exist in the stl. What is your justification that > they need to be overridden for your container in the first place? Because I bet that these are optimized for either O(1) random access or O(1) insertion/removal. The new container doesn't fit any of those, and it would perform suboptimal if treated by algorithms based on those assumptions. Is there a sort specialization for sorted trees? I mean, creating a tree from scratch and populating it with an insert_sorted method. Even if it exists, note the optimization I am using: instead of extracting the nodes one by one from the source tree (with the corresponding rebalancing), I detach the list from it, and traverse it. The complexity will remain the same, but this trick will save a lot of time. This can only be done from inside the class or from a friend function. The same is for stable_sort(). The methods reverse, merge and unique are all O(N) (well, merge is O(M+N) ;). I can't imagine how this could be achieved by an existing algorithm, using only the public interface, and maintaining the validity of all iterators. The methods insert_sorted() and binary_search() would take O(sqr(log n)) if implemented from the outside....
answer 15: > Ok. Here are the results, copied directly from the console: > OK, well a factor of 3 in speed could certainly be interesting. I want to try compiling this code on my system to see how it compares, but I can't seem to compile any of the library now. It's possible that I just downloaded the wrong version though, there are Sorting files spread all over the place in the vault, in Algorithms, Algorithms/Sorting, etc. Can you clean them up please so there is just one .zip file containing the most recent version of everything? That would probably make it easier. Your example file SortTimings.cpp contains this line: int _tmain(int argc, _TCHAR* argv[]) I assume that is coming from MSVC? You should only post standard C++ that everyone can compile. I am also getting a lot of errors from radix.hpp, at least some of them are stemming from a typo on line 16. Also, I wanted to try the multi-key quick sort, but there is no documentation and no example so I have no idea how to use it. At a quick glance, the new mkquicksort.hpp looks to be much cleaner now. (There is an older example, but it doesn't include the mkquicksort.hpp file, it has a bunch of classes defined in the .cpp file containing main). -Lewis...
- **avg_similarity**: 0.4986
- **max_similarity**: 0.7002
- **num_results**: 15
- **time_seconds**: 0.4086

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.3908011317253113 |
| 2 | None | None | 0.6666855812072754 |
| 3 | None | None | 0.4281142055988312 |
| 4 | None | None | 0.4100795090198517 |
| 5 | None | None | 0.4352870285511017 |
| 6 | None | None | 0.6011278629302979 |
| 7 | None | None | 0.5163799524307251 |
| 8 | None | None | 0.5023393034934998 |
| 9 | None | None | 0.7002208828926086 |
| 10 | None | None | 0.569618821144104 |
| 11 | None | None | 0.3474007844924927 |
| 12 | None | None | 0.6156818866729736 |
| 13 | None | None | 0.3439132869243622 |
| 14 | None | None | 0.48033803701400757 |
| 15 | None | None | 0.47064316272735596 |

## 12. Question

- **question**: What is Boost.Lambda and how do I use it?
- **ground_truth**: Boost.Lambda provides a way to write lambda expressions before C++11. Example:
```cpp
#include <boost/lambda/lambda.hpp>
#include <iostream>
std::for_each(v.begin(), v.end(), boost::lambda::_1 *= 2);
```
- **rag_answer**: answer 1: Frank Mori Hess wrote: > What about lambda? I don't see it in there anywhere. There seem to be a > couple lambda tickets assigned to the "none" component. <http://article.gmane.org/gmane.comp.lib.boost.devel/165546> -- -- Grafik - Don't Assume Anything -- Redshift Software, Inc. - http://redshift-software.com -- rrivera/acm.org - grafik/redshift-software.com -- 102708583/icq - grafikrobot/aim - grafikrobot/yahoo...
answer 2: I'm having some difficulties figuring out how to use boost::bind and boost::lambda Here's what I've trying to do: use transform to transform the values in one container to another, looking up the new value as a function of the old. What I'm trying to do is conceptually simple: call std::transform with a predicate that takes the original value, does a std::find_if on that value in another "container" using a bound std::greater< int > predicate, converts the returned iterator to an integral distance, and inserts that integral distance in the container that is the destination of the transform. Doing this using a hand-coded functor is easy enough, but I'm not able to figure out how to do it using boost::lambda. If I understand lambda, this should make each element of c equal to four times the corresponding element of o, and indeed this compiles as works as expected....
answer 3: What is the proper syntax for using lamda with with array? i.e. how do I do something like namespace lambda = ::boost::lambda; boost::array< boost::array<int,2>, 4 > foo = {{ {-1,1}, {0,0}, {1,-1}, {2,-2} }}; std::for_each( foo.begin(), foo.end(), std::cout << lambda::constant( "first = " ) << lambda::_1[0] << ' ' << lambda::constant( "second = " ) << lambda::_1[1] << '\n' ); Thanks...
answer 4: - memoize. An use case would be very useful. - mono. I have never needed this, but I understand that it might be useful sometimes. - nestN. This is still very very obscure to me. The more I read the description the more confused I become. I understand that the problems are nested lambda expressions, but I do not understand how your soultion work, what the syntax is and why it must be so complicated (did you see how phoenix handles the problem via local variables to lambda?) - perfect. Recently a forwarding library has been added to boost. Does 'perfect' add anything? - pipable. I have already commented on pipable in the concept section. - regular. I understand the need for this, but wouldn't it better to just fix lambda. Not that it would be easy... (Also I think that boost.bind and maybe even tr1::bind has the same problem, is that right?). - return_. Does this just do the equivalent of implicit cast? - tagged. I have never needed strong typedefs for function objects. What are your use cases? === Function objects - adapted_to. Shouldn't this be adapted_from? - always/identity/apply. Obvious and generally useful. - bll_N. Is this just an alias for lambda placeholders? why i can't just use _N and boost::lambda::placeholderN_type? In the 'valid expressons' it states 'polymorphic boost::lambda::_N'. What does 'polymorphic' refers to here? - X_construct....
answer 5: [9]Download Download and installation information. [10]Compiler Status What library works with which compiler. [11]People boost people. [12]Membership Discuss current boost libraries and review library proposals. [13]Submitting a Library Guidelines and Information about = submitting libraries to boost. [14]FAQ Answers to some common questions = we get asked. [15]News Recent releases and events. [16]Tracker View and submit bug reports, support, feature requests. . References 1. 3D"http://boost.org/3D"index.htm" 2. 3D"http://boost.org/3D"libs/libraries.htm" 3. 3D"http://boost.org/3D"people/people.htm" 4. 3D"http://boost.org/3D"more/faq.htm" 5. 3D"http://boost.org/3D"more/index.htm" 6. 3D"http://anubis.dkuug.dk/jtc1/sc22/wg21/" 7....
answer 6: On 20/03/12 16:14, Robert Dailey wrote: > Ok. Is it available in version 1.48? Why was boost.lambda deprecated in > favor of this new library? Boost.Lambda had a lot of bugs and limitations that were solved with Boost.Phoenix....
answer 7: For some application I need to sum the complex modulus of a collection of elements. In short, I want to be able to replace the lambda expression _1 + bind(&std::norm<double>, _2) by something more natural like _1 + llnorm(_2) For that I use std::accumulate and the lambda library, like in the next working example; #include<boost/lambda/lambda.hpp> #include<boost/lambda/bind.hpp> using namespace boost::lambda; int main(){ using boost::lambda::_1; using boost::lambda::_2; std::vector<std::complex<double> > v(3); v[0]=1.; v[1]=2.; v[2]=3.; double result=std::accumulate(v.begin(), v.end(), double(0.), _1 + bind(&std::norm<double>, _2)); std::cout<<result<<std::endl; return 0; } the question is what do I have to do to be able to use the following syntax instead _1 + llnorm(_2) where llnorm is something I have to define (globally) somewhere else. The question is, how do I have to define llnorm to have the desired effect? The ideal syntax for me would be to be able to say std::norm(_2) or std::norm<double>(_2), but that may not be possible due to name conflict, is it? I am clueless because I don't even know even what is the (C++) type of the argument that would be taken by llnorm. Thanks, Alfredo...
answer 8: In Reference to this... I found out about the Upgrade of Lambda in Boost... I have downloaded and recompiled boost with the new Lambda and will try to sort this out myself first... It will be a bit tho as I now have to recompile the other Libraries dependent on boost First before I can go back to the original problem. On a side not: The boost "HEAD" version compiles much better for VC8 then my last one (1.30) jpmythic _____________________________________________________________________ [Edited Original] Subject: [Boost-users] Converting a Boost implementation of Lambda to VC8 so it compiles The basics: New to boost. Converting a project from VC7 to VC8 that uses Lambda functionality. Other issue, (I didn't write this code... so still learning it). The problem: ----------- The original compiles in earlier compilers, but comes up with "Ambiguous" error in VC8. The original code doesn't deal with Issues with MSVC compiliers, this I found in my searches. The fix from the Searches, points me to using the following workaround: (This was posted on both boost.org and ASPN) http://aspn.activestate.com/ASPN/Mail/Message/1387917 Now I get the basics, but I am still not quite sure about the whole boost structure, so heres the code I am dealing with. 4 files, so not too bad, and only in a small section....
answer 9: Library based lambdas cannot be made perfect, unfortunately. BLL works in most cases the natural way, and then when it doesn't, things can be confusing. One of the biggest issues is that _1.foo() cannot be made to work. It is hard to give precise advice on your email, but judging from the discussion on scopes you may have some confusion on how placeholders work. A placeholder is "in scope" for the entire lambda expression and will get the same value everywhere. That is, all occurrences of _1 are replaced by the same argument (of type foo* in your example). Here's a lambda function and a call to it which could be what you are after (I am not exactly sure what you wanted to do). As you can see, casts are special too, as they cannot be overloaded. Best, Jaakko JÃ¤rvi #include <boost/lambda/lambda.hpp> #include <boost/lambda/bind.hpp> #include <boost/lambda/casts.hpp> #include <boost/lambda/if.hpp> #include <vector> using namespace boost::lambda; struct foo { int a; void* b; }; int main () { std::vector<foo*> v; v.push_back(new foo); if_then_else( bind(&foo::a, _1) == 0, bind(&foo::a, _1) = 1, (*(ll_reinterpret_cast<int*>(bind(&foo::b, *_1)))) = 42 )(v[0]); } On Nov 9, 2006, at 5:51 AM, Martin Young wrote: > Hi, > > I've just started trying to use the Boost lambda library and I'm > finding > that I can't get anything much to work how I'd expect....
answer 10: Defining a namespace 'bind' still >> reserves the same name in boost, namely, 'bind', except that user >> code is now uglier. > > Try to include boost/bind.hpp and boost/lambda/bind.hpp at the same > time (just for matters of uniformity: this is the first time where I don't > agree that one of those includes is in a subdirectory and the other > is not!) I've not found any solution for how to use e.g. _1 from > boost.lambda > in one function and _1 from boost.bind in another _without_ having to > qualify these two everytime, which is totally ugly IMO. You bring up the legitimate problem of bind's _1 clashing with lambda's _1 (when "using namespace boost::lambda" is in effect), but I totally don't see what this has to do with moving boost::bind to boost::bind::bind. To answer your specific question, ::_1 selects the Bind placeholder and boost::lambda::_1 selects Lambda's one; consequently, "using ::_1" is an using declaration for Bind's _1, and "using boost::lambda::_1" is the using declaration for its Lambda counterpart....
answer 11: 2009/11/11 Emanuele Rocci <rocciemanuele@hotmail.com> > Hi All > I started playing with boost::lambda and I need some help or some > clarification about it > or some hint to better understanding how does it work. > > I have this piece of code > > using namespace boost::lambda; > using boost::lambda::var; > > int main(int argc, char** argv) { > std::vector< int > myList; > myList.push_back(100); > myList.push_back(200); > int interval = 20; > > std::for_each( myList.begin(), myList.end(), > ( > std::cout << "value: " << _1 << "\n", > std::cout << "interval: " << var( interval ) << "\n", > var( interval )++ > )); > } > Instead of std::cout << "value: " << _1 << "\n", do this std::cout << constant("value: ") << _1 << "\n", It's described here: http://www.boost.org/doc/libs/1_40_0/doc/html/lambda/using_library.html#lambda.introductory_examples . By the way, if you are just starting with lambda, it's better to use Boost.Phoenix instead. Roman Perepelitsa....
answer 12: Robert Jones wrote: > I believe this is because the lambda version does not publish result_type to its > resultant functors, since the increased generality of lambda makes this difficult > or impossible to do. What version of Boost do you use? Boost.Lambda has supported result_of since Boost 1.44. Your code compiles fine with the trunk version of Boost. Regards, Michel...
answer 13: Hi Joel, On Mar 21, 9:49 pm, Joel de Guzman <j...@boost-consulting.com> wrote: > alfC wrote: > > the question is what do I have to do to be able to use the following > > syntax instead > > _1 + llnorm(_2) > > Lambda does not have such a facility. Ok, I believe you, I will use bind instead for the moment. However I am still puzzled: for example, when boost::lambda defines some operator+ (the one use above) it does indeed what we expect. What is special about operator+ compared to any other user defined (lazy) function defined by the user? (i.e. the lazy function that I want but don't know how to define in the context of Lambda) After all the operator+ above must be a function defined somewhere. > You can use Phoenix instead. > Phoenix (lazy) functions allow you to do that. Phoenix is intended > to supercede Lambda. Phoenix has been reviewed and is conditionally > accepted into Boost after another mini-review. I used Spirit a little bit and I recall that Phoenix was part of Spirit or something like that. While we wait for the Phoenix library, would you recommend to use the Phoenix included in Spirit? Thanks, Alfredo...
answer 14: >> > >> > My question is: what is the right way to use lambda control structure in > this >> > case? >> >> Maybe you want std::find_if instead of std::for_each? >> > > > Well, what I have to do is to iterate through each and every element of the > container and calculate validity of the element. If current element fails the > test I don't have to continue further. I don't think that std::find_if would > work in this case. > > My question is more to how the control structure of "lambda" library works in > respect to "return" or "brake" in the cycle. Well you could return early, but it would not help since the lambda function is called for each element, returning early would just finish execution of the current element work. What you probably want to do is either find_if (which should still work for your situation), or throw an exception (much easier to do with Boost.Phoenix instead of Boost.Lambda, Phoenix can do everything Lambda does and a great deal more)....
answer 15: Manfred Doudar wrote: > The C++ BOOST Libraries are a series of free, peer-reviewed, STL compliant, > portable and thread-safe C++ libraries; That sounds a little too buzzwordy to my ear. What does 'STL compliant' actually mean ? Also, I don't think boost libraries are generally thread-safe, at least not in a general sense. I believe it would be best not to mention thread-safety in a short abstract, or else you'd have to detail the statement quite a bit to make it true. Regards, Stefan...
- **avg_similarity**: 0.5554
- **max_similarity**: 0.6831
- **num_results**: 15
- **time_seconds**: 0.4174

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.3297847807407379 |
| 2 | None | None | 0.5993755459785461 |
| 3 | None | None | 0.683050274848938 |
| 4 | None | None | 0.5519573092460632 |
| 5 | None | None | 0.4578389525413513 |
| 6 | None | None | 0.5465875267982483 |
| 7 | None | None | 0.6250239014625549 |
| 8 | None | None | 0.5032795667648315 |
| 9 | None | None | 0.5917719006538391 |
| 10 | None | None | 0.549079179763794 |
| 11 | None | None | 0.6752002835273743 |
| 12 | None | None | 0.5765652060508728 |
| 13 | None | None | 0.5592724084854126 |
| 14 | None | None | 0.6389004588127136 |
| 15 | None | None | 0.4428330957889557 |

## 13. Question

- **question**: How do I convert a date to a string using Boost.DateTime?
- **ground_truth**: You can convert a date to a string using Boost.DateTimeâs `to_simple_string` function:
```cpp
#include <boost/date_time/gregorian/gregorian.hpp>
boost::gregorian::date d(2025, 10, 2);
std::cout << boost::gregorian::to_simple_string(d) << std::endl; // "2025-Oct-02"
```
- **rag_answer**: answer 1: I use boost 1.46.0 and visual studio 2010. I try to convert a string into a date time object. I found some examples that use stringstreams. Is it possible to convert custom formatted date/time strings into gregorian date objects without using a stringstream? Thank you, Louis...
answer 2: On 2011-07-30 20:42:37 +0200, Igor R said: >> >> I read a string with a date / time format, like: Fri, 29 Jul 2011 >> 13:48:57 +0000 >> Can I use Boost.DateTime to convert the string into a std::time_t value? >> How can I do this? > > See the DateTime docs for details: > http://www.boost.org/doc/libs/1_47_0/doc/html/date_time/posix_time.html#ptime_from_string > Thanks, but can I use a "parsing string"? The examples shows a other format, so I must convert my string or tell the "time_from/iso_string" to use a other format. How can I set the format? Thanks...
answer 3: Hello, I read a string with a date / time format, like: Fri, 29 Jul 2011 13:48:57 +0000 Can I use Boost.DateTime to convert the string into a std::time_t value? How can I do this? Thanks Phil...
answer 4: > I read a string with a date / time format, like: Fri, 29 Jul 2011 13:48:57 +0000 > Can I use Boost.DateTime to convert the string into a std::time_t value? > How can I do this? See the DateTime docs for details: http://www.boost.org/doc/libs/1_47_0/doc/html/date_time/posix_time.html#ptime_from_string...
answer 5: > I read a string with a date / time format, like: Fri, 29 Jul 2011 13:48:57 +0000 > Can I use Boost.DateTime to convert the string into a std::time_t value? > How can I do this? See the DateTime docs for details: http://www.boost.org/doc/libs/1_47_0/doc/html/date_time/posix_time.html#ptime_from_string...
answer 6: Hello, I read a string with a date / time format, like: Fri, 29 Jul 2011 13:48:57 +0000 Can I use Boost.DateTime to convert the string into a std::time_t value? How can I do this? Thanks Phil...
answer 7: Hi there, I would like to create a date object from a string with a specific format ( mm-dd-yyyy ). How to I do that? Thanks ahaed, Christian...
answer 8: Hi: Within a string I have a date in the format: 22 July 2009 How can I input this in to the boost::datetime library as I need to transform it in to another format. As far as I can tell, the constructor of boost::gregorian::date doesn't takethis format as one of it's string parameters. Cheers Sean....
answer 9: Hi, (sorry if this is off topic) I need to get the current date and time and convert it into a string that follows the xsd:datetime time stamp format: [-]CCYY-MM-DDThh:mm:ss[Z|(+|-)hh:mm]. (timezone should be UTC) Any ideas on how to do that? The Boost::Date_Time library documentation is confusing to my feeble mind. Thanks, Joe...
answer 10: No problems spoted. I had also tryed it with various Boost.Locale's manipulators including parameterised and not parameterised. It worked very well allowing to do things like std::string now = boost::convert<std::string>::from(std::time(0)) >> boost::locale::as::datetime; Or std::string now = boost::convert<std::string>::from(std::time(0)) >> boost::locale::as::ftime("%Y-%m-%d %H:%M:%S"); Same for parsing - very-very convenient. > - How much effort did you put into your evaluation? A glance? A > quick reading? In-depth study? I had spend several hours mostly trying different use cases and seen how it works. Did a quick glance to various source files. And fast reading of docs. Most of the time I spend doing things with library like formatting and parsing different values. Formatting with different locales and so on. > - Are you knowledgeable about the problem domain?...
answer 11: Hi there, I would like to create a date object from a string with a specific format ( mm-dd-yyyy ). How to I do that? Thanks ahead, Christian...
answer 12: I would like to be >>> able to convert these timestamps, no matter what timezone they are in >>> (I know the names of the timezones) to UTC timestamps. >>> >>> I looked through datatime library documentation and found >>> date_time_zonespec.csv database which doesn't seem to support the >>> notion of different rules for the same timezone depending on the >>> date. For example, Russia used to have summer time but not any more. >>> Another method seems to be passing a timezone specification string >>> manually, which requires the user to figure what it should be for a >>> particular date. >>> >>> In other words, given a timestamp and its timezone, I would like to >>> be able to convert that timestamp into a UTC timestamp using >>> conversion rules in force at that particular date in the past. >>> Ideally, this would use IANA Time Zone Database or something similar. >>> Is there a facility in boost to do just that? > > Oh, thanks Artyom. > > That is quite a surprising place to find this functionality. Not sure > why it is not in datetime library....
answer 13: Quite clear. However the reference documentation should be better. some parts are missing - I don't know why like convert/doc/html/header/boost/convert/string_to_bool_hpp.html > - What is your evaluation of the potential usefulness of the > library? Very useful. The conversion according to current locale of boost::lexical_cast and throwing behavior caused me to use std::stringstream as much more reliable. I implemented small tools for this in my sql library and may other places. Such library is too convenient and useful not to be in Boost. > - Did you try to use the library? With what compiler? Did you > have any problems? I've tryed it with GCC-4.3.4 on Cygwin 1.7. No problems spoted. I had also tryed it with various Boost.Locale's manipulators including parameterised and not parameterised. It worked very well allowing to do things like std::string now = boost::convert<std::string>::from(std::time(0)) >> boost::locale::as::datetime; Or std::string now = boost::convert<std::string>::from(std::time(0)) >> boost::locale::as::ftime("%Y-%m-%d %H:%M:%S"); Same for parsing - very-very convenient. > - How much effort did you put into your evaluation? A glance? A > quick reading? In-depth study? I had spend several hours mostly trying different use cases and seen how it works. Did a quick glance to various source files. And fast reading of docs....
answer 14: I would like to be able to convert these timestamps, no matter what timezone they are in (I know the names of the timezones) to UTC timestamps. >> >> I looked through datatime library documentation and found date_time_zonespec.csv database which doesn't seem to support the notion of different rules for the same timezone depending on the date. For example, Russia used to have summer time but not any more. Another method seems to be passing a timezone specification string manually, which requires the user to figure what it should be for a particular date. >> >> In other words, given a timestamp and its timezone, I would like to be able to convert that timestamp into a UTC timestamp using conversion rules in force at that particular date in the past. Ideally, this would use IANA Time Zone Database or something similar. Is there a facility in boost to do just that? Oh, thanks Artyom. That is quite a surprising place to find this functionality. Not sure why it is not in datetime library....
answer 15: boost::date_time::date_input_facet* pMyFacet = new boost::date_time::date_input_facet( "%m-%d-%Y" ); std::locale loc( std::locale::classic(), pMyFacet ); std::istringstream ss; ss.str( "22-03-2006" ); Boost::gregorian::date myDate; ss >> myDate; Normally, myDate must be initialized to the 22-03-2006 like indicated. Alexandre -----Message d'origine----- De : boost-users-bounces@lists.boost.org [mailto:boost-users-bounces@lists.boost.org] De la part de Christian Henning EnvoyÃ© : mercredi 22 mars 2006 15:01 Ã : boost-users@lists.boost.org Objet : Re: [Boost-users] [date_time] How to create a date fromstringwithspecific format? Alexandre, this was my initial approach of the problem, but somehow I couldn't figure out how to construct the data or time object? ptime oTime ss >> oTime; //??????? Thanks, Christian _______________________________________________ Boost-users mailing list Boost-users@lists.boost.org http://lists.boost.org/mailman/listinfo.cgi/boost-users...
- **avg_similarity**: 0.6757
- **max_similarity**: 0.8065
- **num_results**: 15
- **time_seconds**: 0.4168

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.7926842570304871 |
| 2 | None | None | 0.7673983573913574 |
| 3 | None | None | 0.7738222479820251 |
| 4 | None | None | 0.775412917137146 |
| 5 | None | None | 0.775412917137146 |
| 6 | None | None | 0.7738222479820251 |
| 7 | None | None | 0.5619762539863586 |
| 8 | None | None | 0.8064588308334351 |
| 9 | None | None | 0.6284874677658081 |
| 10 | None | None | 0.5826654434204102 |
| 11 | None | None | 0.5586690306663513 |
| 12 | None | None | 0.4868467152118683 |
| 13 | None | None | 0.5923131108283997 |
| 14 | None | None | 0.4848552346229553 |
| 15 | None | None | 0.7744467258453369 |

## 14. Question

- **question**: How do I use Boost.CircularBuffer?
- **ground_truth**: Boost.CircularBuffer provides a fixed-size buffer that overwrites the oldest data when full. Example:
```cpp
#include <boost/circular_buffer.hpp>
boost::circular_buffer<int> buffer(3);
buffer.push_back(1);
buffer.push_back(2);
buffer.push_back(3);
buffer.push_back(4); // 1 is overwritten
```
- **rag_answer**: answer 1: "Luca Cappa" wrote: > I would like to use the circularbuffer class provided by boost-sandbox, > and I would like if someone could tell > me which are the rules to include the boost-sandbox files (either the .cpp > and the .h) in my building process, > i.e. should I copy only the relevant files into the actual boost > installation directory, or anything else? > It is header only. It will be added into the main CVS once 1.34 gets out of the door, otherwise it is finished. /Pavel...
answer 2: AMDG SelÃ§uk Giray Ãzdamar wrote: > Hi everyone, > I specialized the boost::circular_buffer template class for concurrent > access. But I have no idea about how the locking strategy must be for > copy ctor, and also assignment operator. I inserted question marks at > the end of the related lines. > > // copy ctor > CircularBuffer(const CircularBuffer& other) > { > //WriteLock w_lock(rw_mutex); ??????????? > m_capacity = other.m_capacity; > m_buffer = other.m_buffer; > } You need a ReadLock on other. There is no need to lock the object being constructed. > // assignment operator Use the swap trick. // assignment operator CircularBuffer& operator= (const CircularBuffer& other) { CircularBuffer temp(other); WriteLock w_lock(rw_mutex); using std::swap; swap(m_capacity, other.m_capacity); swap(m_buffer, other.m_buffer); return *this; } In Christ, Steven Watanabe...
answer 3: Luca Cappa wrote: > Hi all, > > I would like to use the circularbuffer class provided by boost-sandbox, > and I would like if someone could tell > me which are the rules to include the boost-sandbox files (either the .cpp > and the .h) in my building process, > i.e. should I copy only the relevant files into the actual boost > installation directory, or anything else? > > Greetings, > Luca > _______________________________________________ > Boost-users mailing list > Boost-users@lists.boost.org > http://lists.boost.org/mailman/listinfo.cgi/boost-users > > hi luca, there seems to be no need to build a lib for circular_buffer, so you can just add boost-sandbox to your include dirs and it should work. -- HTH dave...
answer 4: I'm afraid the way you want to use a circular buffer, this implementation is not applicable. But have a look at the Bounded Buffer example http://www.boost.org/doc/libs/1_39_0/libs/circular_buffer/doc/circular_buffer.html#examples This is the right way how to use circular_buffer in procuder/consumer scenario. Regards, Jan ----- Original Message ---- From: David Baird <dhbaird@gmail.com> To: Jan Gaspar <jano_gaspar@yahoo.com> Cc: boost-users@lists.boost.org Sent: Saturday, 25 July, 2009 22:25:46 Subject: Re: [Boost.CircularBuffer] begin()/end() arithmetic not working out quite right Hmmm, well, I think I understand what you are saying. But it seems counter-intuitive to me that end() will always remain constant and that begin() will always move back. Even this graphic here seems to indicate that end() moves: http://www.boost.org/doc/libs/1_39_0/libs/circular_buffer/doc/circular_buffer.png (from http://www.boost.org/doc/libs/1_39_0/libs/circular_buffer/doc/circular_buffer.html) Unfortunately, that makes it hard to use circular_buffer in some of our applications. But I might be mistaken... It seems that circular_buffer works great for this scenario: for(i = buf.begin(); i= buf.end(); ++i) { ... } But my application is a little bit different from that....
answer 5: Hi everyone, I specialized the boost::circular_buffer template class for concurrent access. But I have no idea about how the locking strategy must be for copy ctor, and also assignment operator. I inserted question marks at the end of the related lines. Thanks in advance... template <class T> class CircularBuffer { typedef boost::circular_buffer<T> internal_buffer; typedef boost::shared_mutex ReadWriteMutex; typedef boost::shared_lock<boost::shared_mutex> ReadLock; typedef boost::unique_lock<boost::shared_mutex> WriteLock; public: // Constructors explicit CircularBuffer(capacity_type capacity = 10) : m_capacity(capacity) , m_buffer(capacity) { } // copy ctor CircularBuffer(const CircularBuffer& other) { //WriteLock w_lock(rw_mutex); ??????????? m_capacity = other.m_capacity; m_buffer = other.m_buffer; } size_type size() const { ReadLock r_lock(rw_mutex); return m_buffer.size(); } void push_back(param_value_type item = value_type()) { WriteLock w_lock(rw_mutex); m_buffer.push_back(item); } // assignment operator CircularBuffer& operator= (const CircularBuffer& other) { //WriteLock w_lock(rw_mutex); ?????????? if (this != &other) { m_capacity = other.m_capacity; m_buffer = other.m_buffer; } return *this; } private:// member variables capacity_type m_capacity; internal_buffer m_buffer; // rw_mutex for internal buffer mutable ReadWriteMutex rw_mutex; };...
answer 6: Hi all, The Circular Buffer library has been added to boost (HEAD CVS). http://boost.cvs.sourceforge.net/*checkout*/boost/boost/libs/circular_buffer/doc/circular_buffer.html The implementation reflects the suggestions and improvements as a result of the formal review: - defined exception safety for every method - introduced new methods array_one(), array_two() and rerase() - contains several bug fixes and solves some compiler issues - contains better documentation in general The full list can be found here http://boost.cvs.sourceforge.net/*checkout*/boost-sandbox/boost-sandbox/libs/circular_buffer/doc/TODO and the formal review here http://boost.cvs.sourceforge.net/*checkout*/boost-sandbox/boost-sandbox/libs/circular_buffer/doc/formal_review.txt. Jan ___________________________________________________________ Yahoo! Answers - Got a question? Someone out there knows the answer. Try it now. http://uk.answers.yahoo.com/...
answer 7: Michael Marcin wrote: > Jan Gaspar wrote: >> Subject: circular_buffer added to boost >> >> >>> Hi all, >>> >>> The Circular Buffer library has been added to boost (HEAD CVS). >>> >>> http://boost.cvs.sourceforge.net/*checkout*/boost/boost/libs/circular_buffer/doc/circular_buffer.html >>> >>> The implementation reflects the suggestions and improvements as a >>> result of the formal review: >>> - defined exception safety for every method >>> - introduced new methods array_one(), array_two() and rerase() >>> - contains several bug fixes and solves some compiler issues >>> - contains better documentation in general >>> >>> The full list can be found here >>> http://boost.cvs.sourceforge.net/*checkout*/boost-sandbox/boost-sandbox/libs/circular_buffer/doc/TODO >>> and the formal review here >>> http://boost.cvs.sourceforge.net/*checkout*/boost-sandbox/boost-sandbox/libs/circular_buffer/doc/formal_review.txt. >>> > > Congrats! > > I'm glad you found the time to finish it up. Me too...this is good news. Jan, could you please update the $BOOST_ROOT/status/Jamfile.v2 so that the circular_buffer tests get included in the regresssions? Should be pretty obvious what to do there. Thx, Jeff...
answer 8: AMDG Ovanes Markarian wrote: > > > // assignment operator > CircularBuffer& operator= (const CircularBuffer& other) > { > CircularBuffer temp(other); > > why do you need this temp, if it is not used further? > > > WriteLock w_lock(rw_mutex); > > using std::swap; > swap(m_capacity, other.m_capacity); > swap(m_buffer, other.m_buffer); > Whoops. swap(m_capacity, temp.m_capacity); swap(m_buffer, temp.m_buffer); In Christ, Steven Watanabe...
answer 9: Hello there, i am new here and i just want to say "hi". so, i'm using boost almost a year now, usually i just used the array component. latley i wanted to implement the circular_buffer. i've defined it in a class after the private-modifier like this: boost::circular_buffer<std::string> textBuffer(10); (as take from the documentation) but my compiler on minGW will throw an error. so, i guess i got something wrong in declaring a string-textbuffer with the lenght of 10?! in the boost-docs there is following example: boost::circular_buffer<int> cb(3); help is appreciated, best would be a working example and a little hint which information is may have missed. greetings tony...
answer 10: Here I'm returning by value. Below you can see my complete implementation. There may be possible potential risks here. For example, in overloaded index operator (const function) it returns by value, so read lock assures it's safety. But I can't say the same things for non-const function which returns reference. If you write something like this: T& _refT = mCircularBuffer[0]; It returns as reference, and some other time you are free to change the value of _refT (after leaving the index operator scope). So write lock is unlocked, and as a consequence it's not thread safe so. And also iterators are same as the index operator, not thread safe. I'm looking for much safer implementation. Thanks, regards... template <class T> class CircularBuffer { typedef boost::shared_mutex ReadWriteMutex; typedef boost::shared_lock<boost::shared_mutex> ReadLock; typedef boost::unique_lock<boost::shared_mutex> WriteLock; public: // A const (random access) iterator used to iterate through the circular_buffer typedef typename boost::circular_buffer<T>::const_iterator const_iterator; // A (random access) iterator used to iterate through the circular_buffer typedef typename boost::circular_buffer<T>::iterator iterator; explicit CircularBuffer(unsigned capacity = 10) : m_capacity(capacity) , m_buffer(capacity) { } ~CircularBuffer() { } CircularBuffer(const CircularBuffer& other) : m_capacity(other.m_capacity) , m_buffer(other.m_buffer) { } CircularBuffer& operator= (const CircularBuffer& other) { CircularBuffer temp(other); WriteLock w_lock(rw_mutex); using std::swap; swap(m_capacity, temp.m_capacity); swap(m_buffer, temp.m_buffer); return *this; } // Get the iterator pointing to the beginning of the <code>circular_buffer</code>....
answer 11: Jan Gaspar wrote: > Subject: circular_buffer added to boost > > >> Hi all, >> >> The Circular Buffer library has been added to boost (HEAD CVS). >> >> http://boost.cvs.sourceforge.net/*checkout*/boost/boost/libs/circular_buffer/doc/circular_buffer.html >> >> The implementation reflects the suggestions and improvements as a >> result of the formal review: >> - defined exception safety for every method >> - introduced new methods array_one(), array_two() and rerase() >> - contains several bug fixes and solves some compiler issues >> - contains better documentation in general >> >> The full list can be found here >> http://boost.cvs.sourceforge.net/*checkout*/boost-sandbox/boost-sandbox/libs/circular_buffer/doc/TODO >> and the formal review here >> http://boost.cvs.sourceforge.net/*checkout*/boost-sandbox/boost-sandbox/libs/circular_buffer/doc/formal_review.txt. >> Congrats! I'm glad you found the time to finish it up. Thanks, Michael Marcin...
answer 12: Hi, Is there a Circular buffer library in boost? If not, can you please tell me if there is a circular buffer library in c++? Thank you....
answer 13: Steven, please see my question below. On Mon, Jun 9, 2008 at 6:14 PM, Steven Watanabe <watanabesj@gmail.com> wrote: > AMDG > [...] > > // assignment operator > CircularBuffer& operator= (const CircularBuffer& other) > { > CircularBuffer temp(other); why do you need this temp, if it is not used further? > > WriteLock w_lock(rw_mutex); > > using std::swap; > swap(m_capacity, other.m_capacity); > swap(m_buffer, other.m_buffer); > > return *this; > } > > In Christ, > Steven Watanabe > <http://lists.boost.org/mailman/listinfo.cgi/boost-users> With Kind Regards, Ovanes...
answer 14: Here I'm returning by value. Below you can see my complete implementation. There may be possible potential risks here. For example, in overloaded index operator (const function) it returns by value, so read lock assures it's safety. But I can't say the same things for non-const function which returns reference. If you write something like this: T& _refT = mCircularBuffer[0]; It returns as reference, and some other time you are free to change the value of _refT (after leaving the index operator scope). So write lock is unlocked, and as a consequence it's not thread safe so. And also iterators are same as the index operator, not thread safe. I'm looking for much safer implementation. Thanks, regards... template <class T> class CircularBuffer { typedef boost::shared_mutex ReadWriteMutex; typedef boost::shared_lock<boost::shared_mutex> ReadLock; typedef boost::unique_lock<boost::shared_mutex> WriteLock; public: typedef typename boost::circular_buffer<T>::const_iterator const_iterator; typedef typename boost::circular_buffer<T>::iterator iterator; explicit CircularBuffer(unsigned capacity = 10) : m_capacity(capacity) , m_buffer(capacity) { } ~CircularBuffer() { } CircularBuffer(const CircularBuffer& other) : m_capacity(other.m_capacity) , m_buffer(other.m_buffer) { } CircularBuffer& operator= (const CircularBuffer& other) { CircularBuffer temp(other); WriteLock w_lock(rw_mutex); using std::swap; swap(m_capacity, temp.m_capacity); swap(m_buffer, temp.m_buffer); return *this; } iterator begin() { WriteLock w_lock(rw_mutex); return m_buffer.begin(); } iterator end() { WriteLock w_lock(rw_mutex); return m_buffer.end(); } const_iterator begin() const { ReadLock r_lock(rw_mutex); return m_buffer.begin();...
answer 15: There doesn't need to be a single type of a ring buffer. Similarly to vector/static_vector/small_vector, there can be multiple ring buffer types that make different tradeoffs wrt. their storage and other properties. Specifically re. Boost.CircularBuffer, I see no problem that it performs dynamic memory allocations given its support for dynamic sizes and capacities. That is, circular_buffer provides a ring buffer with (reasonably) unlimited capacity, and it is good at that purpose. There may be other use cases, where a different set of tradeoffs are more suitable. For example, I've written a ring buffer adapter that operates on an array of fixed capacity (meaning that all elements of the array are constructed upon the ring buffer construction rather than on insertion), which was better suited for a given use case than Boost.CircularBuffer. Again, there's nothing wrong in having different ring buffer types that make different tradeoffs and fit different use cases. If your colleague's use case is sufficiently different from that of Boost.CircularBuffer, there's nothing wrong with implementing his own version....
- **avg_similarity**: 0.5670
- **max_similarity**: 0.7142
- **num_results**: 15
- **time_seconds**: 0.4232

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.43360820412635803 |
| 2 | None | None | 0.5286619663238525 |
| 3 | None | None | 0.5242912173271179 |
| 4 | None | None | 0.6979379653930664 |
| 5 | None | None | 0.5520305037498474 |
| 6 | None | None | 0.6536198258399963 |
| 7 | None | None | 0.6571828722953796 |
| 8 | None | None | 0.4964312016963959 |
| 9 | None | None | 0.6319478750228882 |
| 10 | None | None | 0.3985050916671753 |
| 11 | None | None | 0.6549109220504761 |
| 12 | None | None | 0.7142297625541687 |
| 13 | None | None | 0.6337653994560242 |
| 14 | None | None | 0.4141368567943573 |
| 15 | None | None | 0.5142375230789185 |

## 15. Question

- **question**: How do I create a graph with Boost.Graph?
- **ground_truth**: Boost.Graph provides a framework for graph algorithms. You can create a graph and add vertices/edges as follows:
```cpp
#include <boost/graph/adjacency_list.hpp>
boost::adjacency_list<> g;
boost::add_vertex(g);
```
- **rag_answer**: answer 1: Carsten Hoyer wrote: > Hi > Just turned to Boost - What a fantastic library :) > > I have a question about the construction of a Graph. I can't figure out how > to use boost to represent a graph where each Vertex has several outs. F.ex > Vertex 1 has out 1, 2 and 3. Vertex A has in a, b and c. I can then make > edges going from 1-a, 1-b, 2-b etc. Like F.ex > http://messe.harmony-central.com/Musikmesse05/Content/Native_Instruments/PR/Reaktor-5-interface-lg.jpg > Reaktor > > Any hints? > Thank you > Carsten > add_edge(node1, node2, g); add_edge(node1, node3, g); add_edge(node1, node4, g);...
answer 2: Hello, i'm working with a (huge) undirected graph, with severeal internal properties in both vertices and edges, including weights. At one point, i compute the minumim spanning tree of the graph. The question is simple: how can i create another graph (a tree, so a directed graph) from the original undirected graph plus the list of edges conforming the mst ? And how can i do it _efficiently_ (considering that the original graph will be huge) ? Consider this seudo-code: #include <boost/graph/adjacency_list.hpp> #include <boost/graph/graph_traits.hpp> #include <boost/property_map.hpp> #include <boost/graph/properties.hpp> #include <boost/graph/kruskal_min_spanning_tree.hpp> typedef adjacency_list < boost::listS, boost::vecS, boost::undirectedS, VertexProperties, EdgeProperties> UGraph; typedef adjacency_list < boost::listS, boost::vecS, boost::directedS, VertexProperties, EdgeProperties> MSTree; void createGraph() { UGraph g; add_vertices(); add_edges(); compute_edges_weights(); vector<graph_traits<UGraph>::edge_descriptor> mst_edges(num_vertices(g)); kruskal_minimum_spanning_tree(g, back_inserter(mst_edges)); // At this point i want to create another graph of type MSTree from // g and mst_edges. How can i do it efficiently ? } thank you in advance aitor...
answer 3: I need >> the resulting graph for further computations. How do you create a >> graph >> from an existing one but only selecting the edges contained in the >> minimum spanning tree vector? I've seen that there are some functions >> to accomplish this but I couldn't find any example of how to do it: >> >> template <class EdgeIterator, class EdgePropertyIterator> >> adjacency_list(EdgeIterator first, EdgeIterator last, >> EdgePropertyIterator ep_iter, >> vertices_size_type n, >> vertices_size_type m = 0, >> const GraphProperty& p = GraphProperty()) >> >> The existing graph has properties in edges and vertices that I also >> need >> to keep. Can anyone help? Thank you all, > > Unfortunately, the above constructor probably won't help. I expect > you'll need to write the copy routine yourself, because I don't know of > a function in the Graph library that does exactly what you want. The > simple way to do this is: > > - Create a new, empty graph > - Create a property map orig2copy that maps from the old graph's > vertex descriptors to the new graph's vertex descriptors > - For each vertex v in the original graph, add_vertex on the new graph > using get(vertex_all, orig, v) for the value of the properties, then > setup the correspondence orig2copy[v] = the new vertex....
answer 4: Hi Just turned to Boost - What a fantastic library :) I have a question about the construction of a Graph. I can't figure out how to use boost to represent a graph where each Vertex has several outs. F.ex Vertex 1 has out 1, 2 and 3. Vertex A has in a, b and c. I can then make edges going from 1-a, 1-b, 2-b etc. Like F.ex http://messe.harmony-central.com/Musikmesse05/Content/Native_Instruments/PR/Reaktor-5-interface-lg.jpg Reaktor Any hints? Thank you Carsten -- View this message in context: http://www.nabble.com/a-little-Graph-guidance-%28looking-for-hints%29-tp19088639p19088639.html Sent from the Boost - Users mailing list archive at Nabble.com....
answer 5: I need >>>the resulting graph for further computations. How do you create a >>>graph >>>from an existing one but only selecting the edges contained in the >>>minimum spanning tree vector? I've seen that there are some functions >>>to accomplish this but I couldn't find any example of how to do it: >>> >>>template <class EdgeIterator, class EdgePropertyIterator> >>>adjacency_list(EdgeIterator first, EdgeIterator last, >>> EdgePropertyIterator ep_iter, >>> vertices_size_type n, >>> vertices_size_type m = 0, >>> const GraphProperty& p = GraphProperty()) >>> >>>The existing graph has properties in edges and vertices that I also >>>need >>>to keep. Can anyone help? Thank you all, >> >>Unfortunately, the above constructor probably won't help. I expect >>you'll need to write the copy routine yourself, because I don't know of >>a function in the Graph library that does exactly what you want. The >>simple way to do this is: >> >> - Create a new, empty graph >> - Create a property map orig2copy that maps from the old graph's >>vertex descriptors to the new graph's vertex descriptors >> - For each vertex v in the original graph, add_vertex on the new graph >>using get(vertex_all, orig, v) for the value of the properties, then >>setup the correspondence orig2copy[v] = the new vertex....
answer 6: I need > the resulting graph for further computations. How do you create a > graph > from an existing one but only selecting the edges contained in the > minimum spanning tree vector? I've seen that there are some functions > to accomplish this but I couldn't find any example of how to do it: > > template <class EdgeIterator, class EdgePropertyIterator> > adjacency_list(EdgeIterator first, EdgeIterator last, > EdgePropertyIterator ep_iter, > vertices_size_type n, > vertices_size_type m = 0, > const GraphProperty& p = GraphProperty()) > > The existing graph has properties in edges and vertices that I also > need > to keep. Can anyone help? Thank you all, Unfortunately, the above constructor probably won't help. I expect you'll need to write the copy routine yourself, because I don't know of a function in the Graph library that does exactly what you want. The simple way to do this is: - Create a new, empty graph - Create a property map orig2copy that maps from the old graph's vertex descriptors to the new graph's vertex descriptors - For each vertex v in the original graph, add_vertex on the new graph using get(vertex_all, orig, v) for the value of the properties, then setup the correspondence orig2copy[v] = the new vertex. - For each edge e, add the edge (orig2copy[source(e, orig)], orig2copy[target(e, orig)]) using get(edge_all, orig, e) for the value of the properties....
answer 7: Dear Aaron, > you could do something like: > > struct VertexProperties { int enum_label; }; > > struct EdgeProperties > { > int Input; > int Output; > }; > > Then, define your graph as: > > typedef boost::adjacency_list<boost::listS, boost::vecS, > boost::bidirectionalS, VertexProperties, EdgeProperties> graph_t; > thanks for your quick answer. I understand what you are suggesting. I thought a bit further on that. Apart from the integers, I have some classes representing the Inputs and Outputs, etc. which allow to make settings on them, which contain a name and additional parameters etc. Also, there are additional layers, which the audio signal runs through. It would be desirable to have something like "Give me the output that is connected to input 1" But also: "give me the audio processing block that is connected to NodeM". As there are existing classes, it would be nice if I could just use these for the graph. I guess, all these, then, must have a common base class, right? And I need RTTI to figure out the class type after I asked the graph for the neighbour of NodeM, e.g., right? I expect some benefit in simplicity and maintainability of the code. Currently I have a "RoutingManager" which I ask for an Output connected to a Node, etc. This manager has a lot of different methods which makes it a bit hard to maintain. Kind regards, Rainer...
answer 8: Something like. >> >> >> function(){ >> typedef adjacency_list<vecS, vecS, bidirectionalS, no_property, >> EdgeProperty> Graph; >> shared_ptr< Graph > gptr( new Graph(n) ); >> return gptr; >> } > > You could also just declare the graph in whichever scope will end up > storing it and then pass it by reference to the construction function: > > void function(Graph& g) { > // build g, or build a temporary and assign it to g > } > > Graph the_graph; > function(the_graph); > > Where are you going to be putting the final graph? Will it be in a > variable in your main(), even if it is not constructed there? > > -- Jeremiah Willcock Jeremiah, I'm sorry if I was not clear in my first post. The majority of the code (along with the main routine) is written in Fortran. I am using the graph to update a number of arrays which are needed for this Fortran code....
answer 9: Hi, I am a newbie in using boost libraries and template programming, and I try to get familiar with the graph library at the moment. My first problem is, that I want to create subgrahps in "sub-functions" and create the whole graph out of these subgraphs in the calling function. I tried to create the subgraph in the calling function and pass it to the sub-function, but then, the new vertices were added to the root-graph and not to the subgraph. I solved this in the calling-function with adding all the new vertices and their edges again to the subgraph. Is there a better way to do that? My second problem is just as mentioned in the subject line. How to use boost::write_graphviz to print out subgraphs? It works for "normal" graphs but not for subgraphs. I hope this is the right place to ask these questions. Thanks for your answers. Lisa __________________________________________________ Do You Yahoo!? Sie sind Spam leid? Yahoo! Mail verfÃ¼gt Ã¼ber einen herausragenden Schutz gegen Massenmails. http://mail.yahoo.com __________________________________________________ Do You Yahoo!? Sie sind Spam leid? Yahoo! Mail verfÃ¼gt Ã¼ber einen herausragenden Schutz gegen Massenmails. http://mail.yahoo.com...
answer 10: I've been > reading the doc site, but I haven't found any information about > how to create my own graph. Could you please tell me where to > look? > > I think your best bet may be to modify the CSR graph types to use something > other than size_t. Copy it, rename the type, and change it to suit your > needs. That's close enough to creating your own graph type :) > > I'm not entirely convinced that the benefits will outweigh the cost here. > Maybe you'll save a couple MB, but you might do so at the expense of > performance. If your graph is purely a grid, you can also just create an implicit graph that takes no space (at least for the graph structure). In this case, your vertex_descriptor would just be the grid coordinates, and the edge_descriptor would be a source vertex and an output index. You could save a large amount of memory for large graphs that way, since the structure of the graph would not be stored at all, and you could trivially convert between vertex_descriptors and positions in the grid. Your properties would still take memory if you have some, of course. There is an example of how to create a graph like you want in chapter 9 of the BGL book (your grid is very similar to the knight's tour problem in that chapter). -- Jeremiah Willcock...
answer 11: You want to induce a subgraph of this > >> >> >> graph. How do you do this? > >> >> >> > >> >> >> I looked at the boost docs and found the Subgraph < Graph > page: > >> >> >> > >> >> >> http://www.boost.org/doc/libs/1_36_0/libs/graph/doc/subgraph.html > >> >> >> > >> >> >> Indeed there exists a subgraph member function: > >> >> >> > >> >> >> subgraph<Graph>& create_subgraph(); > >> >> >> > >> >> >> However this suggests, as does the example, that you want to take > >> >> >> an induced subgraph of a graph whose type is Subgraph < Graph >. > >> >> >> However my graph is just of type Graph....
answer 12: First, you have not succeeded in giving your graph any properties, either vertex or edge. Something like this would do the trick for edge properties: enum edge_Datum_t { edge_Datum }; namespace boost { BOOST_INSTALL_PROPERTY(edge,Datum); } typedef std::pair<int,int> IntPair; typedef property<edge_Datum_t,IntPair> EdgeProperty; typedef adjacency_list<vectS, vecS, undirectedS, property<boost::vertex_index_t, int>, EdgeProperty> Graph; Second, I'm not sure about your algorithm's needs, wheither you need edge or vertex properties. Third, you need to add referenced vertices before edges. Not doing so would result in an exception. Andrew Chapman wrote: > Hi everyone, I've got a fairly simple use for boost::graph, and I've > been trying to get it working, but the documentation, whilst thorough, > isn't being too helpful in getting me started. > > What I'm trying to do, is build a graph of polygon mesh edges, which are > simply pairs of unsigned ints. I need to find contiguous edge lists....
answer 13: I created a graph. And use add_edge to add some edges, I wanna disable some edges, and add some edges. and use boost graph algorithm for enable edges How can I do this? not create new graph....
answer 14: The graph is not called in the main routine, only in >>> subroutines. >>> >>> I need to know the way the graph is stored so I can pass it back to the >>> main function (or perhaps define it as a public variable). >>> >>> In reference to the code snippet above, am I correct in reading it as the >>> creating routine will be defined as: >>> void function(Graph& g) { >>> // build g, or build a temporary and assign it to g >>> } >>> and then the function to modify it would be defined as: >>> void modify_the_graph(Graph& g){ >>> \\ some graph manipulations here >>> } >> >> Where is the variable holding the graph going to be? If it doesn't have a >> Fortran type the variable cannot be in Fortran code. Are you going to have >> a global variable (in C++) that contains the graph? Otherwise, you might >> need to use a raw (not shared) pointer to the graph, managing the memory >> yourself, and pass it between Fortran and C++ as either some kind of >> interoperability C pointer type (in newer Fortran versions), a large enough >> integer, or maybe a Cray pointer. >> >> -- Jeremiah Willcock > > That is the issue....
answer 15: So, the graph has to represent connections between inputs, nodes, and outputs. (Actually, there are more layers, but to keep it simple I show only these 3). The inputs, outputs, etc. in the end are integers, which are sent to the device. I represent them as enums. So I have, e.g. enum Inputs{ Input1 = 0, Input2, InputNone }; enum Nodes{ NodeM=0, NodeN, NodeNone }; enum Outputs{ AnalogOut1 = 0, AnalogOut2 OutputNone }; Now, to use graphs, I have to define vertices. These have to be of "one" type, as far as I understand that. How do I use the enums as shown above? A vertice-value may be in enum Inputs or Nodes or Outputs. Do I have to use a graph with elements of type ints and cast them to my enums? From the introduction to BGL, modified: const int num_vertices = InputNone + NodeNone + OutputNone; // writing out the edges in the graph typedef std::pair<int, int> Edge; Edge edge_array[] = { Edge(Input1,NodeM), Edge(Input2,NodeN), Edge(AnalogOut1,NodeM), Edge(AnalogOut2,NodeN)}; const int num_edges = sizeof(edge_array)/sizeof(edge_array[0]); // declare a graph object Graph g(num_vertices); // add the edges to the graph object for (int i = 0; i < num_edges; ++i) add_edge(edge_array[i].first, edge_array[i].second, g); When I e.g....
- **avg_similarity**: 0.6087
- **max_similarity**: 0.7199
- **num_results**: 15
- **time_seconds**: 0.4095

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.6628967523574829 |
| 2 | None | None | 0.5918028950691223 |
| 3 | None | None | 0.6613910794258118 |
| 4 | None | None | 0.6061065793037415 |
| 5 | None | None | 0.669247031211853 |
| 6 | None | None | 0.6429795026779175 |
| 7 | None | None | 0.5842189192771912 |
| 8 | None | None | 0.5762476325035095 |
| 9 | None | None | 0.5802964568138123 |
| 10 | None | None | 0.5072457790374756 |
| 11 | None | None | 0.6604639291763306 |
| 12 | None | None | 0.7198581695556641 |
| 13 | None | None | 0.6589084267616272 |
| 14 | None | None | 0.4868438243865967 |
| 15 | None | None | 0.5215757489204407 |

## 16. Question

- **question**: How do I parse command-line options using Boost.Program_options?
- **ground_truth**: Boost.Program_options allows you to define and parse command-line arguments. Example:
```cpp
#include <boost/program_options.hpp>
namespace po = boost::program_options;
po::options_description desc("Allowed options");
desc.add_options()
    ("help", "Produce help message")
    ("config", po::value<std::string>(), "Config file");
```
- **rag_answer**: answer 1: Hi, I'm trying to use the Program Options library to parse command line arguments and config files. I can do this with moderate success. I am currently stuck on a solution to the problem of unrecognized options that are present in a config file. It seems that parse_config_file() does not have an obvious way to not abort reading a config file once it finds something that isn't declared in the options description. Any help on how to get around this (or just a kind of "hey you missed this bit of the manual" kind of pointer) would be very welcome. Thanks, Kevin...
answer 2: Hi all, I'm looking to implement an "incremental" command-line parser using Boost.Program_options. The parser should be incremental in the sense that parsing should stop at the first unknown option or positional argument. At this point, my program would pick the next options description and continue parsing with that. This would proceed until the command-line has been parsed completely or the program is no longer interested in the remainder. The idea is to use this for a program that interfaces to a collection of commands that each support a set of actions. The program, commands and actions all have their own list of options, so you get command-lines like so prog [prog-opts] [cmd [cmd-opts] [act [act-opts]]] Eventually, I might want to throw in positional arguments for some or each of these as well. Any suggestions on how to achieve this? My main concerns are with the way Boost.Program_options wants to parse the whole command-line (when using allow_unregistered()) every time and with how to keep track of what still needs to be processed. Thanks in advance, -- Olaf Meeuwissen, LPIC-2 FLOSS Engineer -- AVASYS CORPORATION FSF Associate Member #1962 Help support software freedom http://www.fsf.org/jf?referrer=1962...
answer 3: Can program_options be used to parse command line elements up to the first non-option that is not an option argument?...
answer 4: Regarding boost::program_options: I would like to parse (and then store) some command-line options that potentially contain unregistered flags, and I understand from <<http://www.boost.org/doc/html/program_options/howto.html#id2716386>> that the way to do this is: basic_command_line_parser<char> parser(argc, argv); basic_parsed_options<char> parsed(parser.options(options).allow_unregistered().run()); Indeed this works--for parsing. But how do I store the resulting parsed options (in a way that ignores the unregistered ones)? Simply calling store(parsed, vm); throws a boost::program_options::unknown_option exception. I can take the (brute force) step of erasing from parsed.options all elements for which the unregistered attribute is true, and then calling store(parsed, vm). That seems to work, but it so clumsy that it makes me think I'm using the system in a way that was not intended. Can anyone help? Thank you. MD P.S. There is a bug in the doc: "collect_arguments(...)" on the last line of the above link should be collect_unrecognized(...); similarly, in the source code parsers.hpp (line 158) there is a mention of the nonexistent function "collect_unregistered"). Michael Drumheller Boeing Phantom Works Mathematics and Engineering Analysis 425.865.3520 michael.drumheller@boeing.com This email may contain proprietary information. If you are not the intended recipient please delete it and notify the sender that you received it in error....
answer 5: The first requirement is already met. The second seems not -- the property_tree docs say that operator>> is used by the 'get' methods, while program_options used strong typing. I would say the second requirements is hard one for program_options, so would hope property_tree is adjusted to make this possible. > One has to distinguish between reading command-line options (or other > simple configuration) and reading structured DOM data. For example, take a > program like visual XML editor. It could use both PO and property_tree to > read its startup config (keyboard shortcuts, font etc.). But only > property_tree would be suitable to handle XML files to be parsed, > displayed, edited and saved by the editor. It would be rather ridiculous > to use program_options to do that, although not impossible, if one tried > really hard. The question is where to draw the line. Reading XML with program_options is not what I'd like to do. Ideally, if somebody wants XML config files he should do this: options_description desc.........; property_tree options; store(options, parse_command_line(desc, .....)); store(options, property_tree::parse_xml_config_file(.....)); So, parsing of XML files is done by property_tree, and merging that data with command line options is done by program_options. I think it's much more reasonable to use program_options for parsing command line, and classic config files. I'm not sure about registry values. - Volodya...
answer 6: Am I the only > person using it ? :) > > Thanks, > > MD > > > _____________________________________________ > > From: Drumheller, Michael > > Sent: Friday, July 21, 2006 9:06 AM > > To: 'boost-users@lists.boost.org' > > Subject: Question about program_options > > > > Regarding boost::program_options: > > > > I would like to parse (and then store) some > command-line options that > > potentially contain unregistered flags, and I > understand from > > > <<http://www.boost.org/doc/html/program_options/howto.html#id2716386>> > > that the way to do this is: > > > > basic_command_line_parser<char> parser(argc, argv); > > basic_parsed_options<char> > > > parsed(parser.options(options).allow_unregistered().run()); > > > > Indeed this works--for parsing. But how do I store > the resulting > > parsed options (in a way that ignores the unregistered > ones)? Simply > > calling > > > > store(parsed, vm); > > > > throws a boost::program_options::unknown_option > exception....
answer 7: GermÃ¡n Diago wrote: > Hi all. I have a question regarding boost.program_options. > > I want to parse a command-line but I want to know the order in which > each option appeared in the > command line. Is this possible? Thanks in advance. parse_command_line returns vector< basic_option<charT> >, which are in the order of occurence. This is a point where you can do logic based on the order. variables_map does not store order information. HTH, -- Vladimir Prus Mentor Graphics +7 (812) 677-68-40...
answer 8: Hi, I suggest to improve options' parsing error recognition, since program_options does not throw an exception for command line options that are substrings of actual options. To be clear : assume we add an option "myoption" with the boost::program_options::options_description::add_options() function. The following command line options are recognized (program_options does not throw an exception): myoption [OK,should be recognized] myopt [BAD,should not be recognized] The following command line options are not recognized (program_options throws an exception): myoptions [OK,should not be recognized] myopr [OK,should not be recognized] I suggest program_options should parse the entire option string until reaching a '=' or ' ' character, and then trying to recognize this option. Best, Florent...
answer 9: For command-line options, I understand from what I read so far that the options should be like --option_name=value There is a system(I believe it is gnu) which has the long and short versions of options, like -h and --help Also, on winxxx systems, usually the command line options are indicated with a / like /? or /x /X .... Is it possible to tune program_options to choose the platform's default way of treating options? Regards,...
answer 10: Hello! I'm using program_options to parse command line options and configuration files. I absolutley need the unknown option feature. For the command line options this works fine. However, the configuration file parsing always throws an option unknown exception when I parse cfg-files with non-registered options. Right right I circumvent this by catching the corresponding exception. But this is not very nice and I can as well not be sure that all options have been parsed in the cfg-file, depending upon the first occurence of an unknown option, right? So, is there a possibility to process unknown options in cfg-files? Thanks a lot in advance. Greetings, Sebastian...
answer 11: I'd like to be able to use program_options to help me parse the command line or config file, and so my plan for the command line is that it would support 4 options (one for each step), for instance with <required options> and [optional options]: app <--export [optional file name [binary|text [transpose]]> [--normalize [optional file name]] [--reduce [optional file name]] <--score <file name or server address> [optional treshold number]> <input file name> I want to allow each option to be given more than once, so that for instance data could be exported as text and binary with app --export file1.bin binary --export file2.txt text transposed ... In another case the command line might be simply app --export --normalize --score file://score.txt input.bin where --export and --normalize are given as boolean switches, and --score has used a default value for the threshold number. In another case, I would like all of the options in a configuration file, and only the input file name would be given on the command line. So my questions: 1/ Could I make my command line simpler? 2/ Will boost::program_options be helpful in this case - I've only used it once before in a much simpler scenario? 3/ What program_options methods should I be looking at?...
answer 12: Florent Teichteil wrote: > Hi, > > I suggest to improve options' parsing error recognition, since > program_options does not throw an exception for command line options > that are substrings of actual options. > > To be clear : assume we add an option "myoption" with the > boost::program_options::options_description::add_options() function. > > The following command line options are recognized (program_options > does not throw an exception): > myoption [OK,should be recognized] > myopt [BAD,should not be recognized] > > The following command line options are not recognized (program_options > throws an exception): > myoptions [OK,should not be recognized] > myopr [OK,should not be recognized] > > I suggest program_options should parse the entire option string until > reaching a '=' or ' ' character, and then trying to recognize this > option. This is by design. There's a style option 'allow_guessing' that's on by default, but you can always pass a different style to the parse_command_line function. - Volodya...
answer 13: Can anyone give me an idea of the general status of boost::program_options? Is it still being maintained? Am I the only person using it ? :) Thanks, MD > _____________________________________________ > From: Drumheller, Michael > Sent: Friday, July 21, 2006 9:06 AM > To: 'boost-users@lists.boost.org' > Subject: Question about program_options > > Regarding boost::program_options: > > I would like to parse (and then store) some command-line options that > potentially contain unregistered flags, and I understand from > <<http://www.boost.org/doc/html/program_options/howto.html#id2716386>> > that the way to do this is: > > basic_command_line_parser<char> parser(argc, argv); > basic_parsed_options<char> > parsed(parser.options(options).allow_unregistered().run()); > > Indeed this works--for parsing. But how do I store the resulting > parsed options (in a way that ignores the unregistered ones)? Simply > calling > > store(parsed, vm); > > throws a boost::program_options::unknown_option exception. I can take > the (brute force) step of erasing from parsed.options all elements for > which the unregistered attribute is true, and then calling > store(parsed, vm). That seems to work, but it so clumsy that it makes > me think I'm using the system in a way that was not intended. > > Can anyone help? > > Thank you. > > MD > > P.S....
answer 14: Regarding boost::program_options: I would like to parse (and then store) some command-line options that potentially contain unregistered flags, and I understand from <<http://www.boost.org/doc/html/program_options/howto.html#id2716386>> that the way to do this is: basic_command_line_parser<char> parser(argc, argv); basic_parsed_options<char> parsed(parser.options(options).allow_unregistered().run()); Indeed this works--for parsing. But how do I store the resulting parsed options (in a way that ignores the unregistered ones)? Simply calling store(parsed, vm); throws a boost::program_options::unknown_option exception. I can take the (brute force) step of erasing from parsed.options all elements for which the unregistered attribute is true, and then calling store(parsed, vm). That seems to work, but it so clumsy that it makes me think I'm using the system in a way that was not intended. Can anyone help? Thank you. MD P.S. There is a bug in the doc: "collect_arguments(...)" on the last line of the above link should be collect_unrecognized(...); similarly, in the source code parsers.hpp (line 158) there is a mention of the nonexistent function "collect_unregistered"). Michael Drumheller Boeing Phantom Works Mathematics and Engineering Analysis 425.865.3520 michael.drumheller@boeing.com This email may contain proprietary information. If you are not the intended recipient please delete it and notify the sender that you received it in error....
answer 15: Just a follow up: I did not receive any response to my query below (neither from the list, nor from the library author, whom I attempted to contact directly). Can anyone give me an idea of the general status of boost::program_options? Is it still being maintained? Am I the only person using it ? :) Thanks, MD > _____________________________________________ > From: Drumheller, Michael > Sent: Friday, July 21, 2006 9:06 AM > To: 'boost-users@lists.boost.org' > Subject: Question about program_options > > Regarding boost::program_options: > > I would like to parse (and then store) some command-line options that > potentially contain unregistered flags, and I understand from > <<http://www.boost.org/doc/html/program_options/howto.html#id2716386>> > that the way to do this is: > > basic_command_line_parser<char> parser(argc, argv); > basic_parsed_options<char> > parsed(parser.options(options).allow_unregistered().run()); > > Indeed this works--for parsing. But how do I store the resulting > parsed options (in a way that ignores the unregistered ones)? Simply > calling > > store(parsed, vm); > > throws a boost::program_options::unknown_option exception. I can take > the (brute force) step of erasing from parsed.options all elements for > which the unregistered attribute is true, and then calling > store(parsed, vm)....
- **avg_similarity**: 0.6291
- **max_similarity**: 0.7582
- **num_results**: 15
- **time_seconds**: 0.4176

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.5998788475990295 |
| 2 | None | None | 0.6599239706993103 |
| 3 | None | None | 0.5803439021110535 |
| 4 | None | None | 0.7134281992912292 |
| 5 | None | None | 0.4789959788322449 |
| 6 | None | None | 0.71747887134552 |
| 7 | None | None | 0.6083974242210388 |
| 8 | None | None | 0.704828679561615 |
| 9 | None | None | 0.5389427542686462 |
| 10 | None | None | 0.4627898335456848 |
| 11 | None | None | 0.5146166682243347 |
| 12 | None | None | 0.6521560549736023 |
| 13 | None | None | 0.7581999897956848 |
| 14 | None | None | 0.7134281992912292 |
| 15 | None | None | 0.732679009437561 |

## 17. Question

- **question**: What is Boost.Multiprecision and how do I use it?
- **ground_truth**: Boost.Multiprecision provides support for arbitrary precision arithmetic. Example:
```cpp
#include <boost/multiprecision/cpp_dec_float.hpp>
boost::multiprecision::cpp_dec_float_100 val = 1.234567890123456789;
std::cout << val << std::endl;
```
- **rag_answer**: answer 1: Fixed precision or arbitrary precision? Suggest you start with: #include <boost/multiprecision/cpp_int.hpp> using boost::multiprecision::int1024_t; // fixed precision 1024-bit integer, or: using boost::multiprecision::cpp_int; // arbitrary precision integer See https://www.boost.org/doc/libs/1_66_0/libs/multiprecision/doc/html/boost_multiprecision/tut/ints/cpp_int.html for other typedefs and examples. >and how do I specify the number of whole number points and decimal points,before starting my operations? That question makes no sense for integer types. > > -If I wish to go into arbitrary precision and scale numbers, > what is the type I should use for a *rational number*? What > is the #include statement I should use, and how do I specify > the number of whole number points and decimal points, > before starting my operations? If you want arbitrary precision then try: #include <boost/multiprecision/cpp_int.hpp> using boost::multiprecision::cpp_rational; // arbitrary precision rational or: #include <boost/multiprecision/cpp_int.hpp> #include <boost/rational.hpp> using boost::multiprecision::int1024_t; // fixed precision 1024-bit integer, or: typedef boost::rational<int1024> rational_1024_t; // 1024 bit fixed precision rational As before your other questions make no sense for these types....
answer 2: > -If I wish to go into arbitrary precision and scale numbers, > what is the type I should use for an *integer*? What is the > #include statement I should use, and how do I specify > the number of whole number points and decimal points, > before starting my operations? What kind of integer? Fixed precision or arbitrary precision? Suggest you start with: #include <boost/multiprecision/cpp_int.hpp> using boost::multiprecision::int1024_t; // fixed precision 1024-bit integer, or: using boost::multiprecision::cpp_int; // arbitrary precision integer See https://www.boost.org/doc/libs/1_66_0/libs/multiprecision/doc/html/boost_multiprecision/tut/ints/cpp_int.html for other typedefs and examples. >and how do I specify the number of whole number points and decimal points,before starting my operations? That question makes no sense for integer types. > > -If I wish to go into arbitrary precision and scale numbers, > what is the type I should use for a *rational number*? What > is the #include statement I should use, and how do I specify > the number of whole number points and decimal points, > before starting my operations?...
answer 3: I usually recommend: * Do support seamless interaction with built-in types. * Forbid implicit conversion of non-same specialized types. * Potentially support explicit construction of one type from another. Accordingly, we do support this: boost::multiprecision::cpp_dec_float_100 a(boost::multiprecision::cpp_dec_float_100(123) / 100); boost::multiprecision::cpp_dec_float_50 b(boost::multiprecision::cpp_dec_float_50(456) / 100); boost::multiprecision::cpp_dec_float_50 c = boost::multiprecision::cpp_dec_float_50(a) * b; But we do not support this: boost::multiprecision::cpp_dec_float_100 a(boost::multiprecision::cpp_dec_float_100(123) / 100); boost::multiprecision::cpp_dec_float_50 b(boost::multiprecision::cpp_dec_float_50(456) / 100); boost::multiprecision::cpp_dec_float_50 c = a * b; >> * What about replacing the second bool template parameter by an enum class expression_template {disabled, enabled}; which will be more explicit. That is > Not a bad idea actually, I'd like to know what others think. I like the suggestion. >> * can we convert from a cpp_dec_float_100 to a cpp_dec_float_50? >> if yes, which rounding policy is applied? >> Do you plan to let the user configure the rounding policy?...
answer 4: > *I have heard that there are some strange results that > can happen if you are quizzing multiprecision for trigonometry > and try to keep using the double type. Is this true, > so that I can just kee relying on the std library instead? > Sorry don't understand the question. > -What is the name of the 64 bit windows .dll, or .dll files, > that are the ones for the multiprecision library? > There are none - it's header only. > -If I wish to go into arbitrary precision and scale numbers, > what is the type I should use for an *integer*? What is the > #include statement I should use, and how do I specify > the number of whole number points and decimal points, > before starting my operations? What kind of integer? Fixed precision or arbitrary precision? Suggest you start with: #include <boost/multiprecision/cpp_int.hpp> using boost::multiprecision::int1024_t; // fixed precision 1024-bit integer, or: using boost::multiprecision::cpp_int; // arbitrary precision integer See https://www.boost.org/doc/libs/1_66_0/libs/multiprecision/doc/html/boost_multiprecision/tut/ints/cpp_int.html for other typedefs and examples. >and how do I specify the number of whole number points and decimal points,before starting my operations? That question makes no sense for integer types....
answer 5: I am aware the the boost multiprecision library is a headers library. -Is Boost multiprecision accurately arbitrary precision, ie. can have its number precisions and scales always made to a larger number, contingent only to the amount of available OS memory? -If I want to use boost Boost multiprecision on its own, what is the name of the Boost .dll or .lib files that have all the headers in it? I need a minimal set of files in order to run multiprecision on its own. ?...
answer 6: Fixed precision or arbitrary precision? Suggest you start with: #include <boost/multiprecision/cpp_int.hpp> using boost::multiprecision::int1024_t; // fixed precision 1024-bit integer, or: using boost::multiprecision::cpp_int; // arbitrary precision integer See https://www.boost.org/doc/libs/1_66_0/libs/multiprecision/doc/html/boost_multiprecision/tut/ints/cpp_int.html for other typedefs and examples. >and how do I specify the number of whole number points and decimal points,before starting my operations? That question makes no sense for integer types. > > -If I wish to go into arbitrary precision and scale numbers, > what is the type I should use for a *rational number*? What > is the #include statement I should use, and how do I specify > the number of whole number points and decimal points, > before starting my operations? If you want arbitrary precision then try: #include <boost/multiprecision/cpp_int.hpp> using boost::multiprecision::cpp_rational; // arbitrary precision rational or: #include <boost/multiprecision/cpp_int.hpp> #include <boost/rational.hpp> using boost::multiprecision::int1024_t; // fixed precision 1024-bit integer, or: typedef boost::rational<int1024> rational_1024_t; // 1024 bit fixed precision rational As before your other questions make no sense for these types....
answer 7: Thanks for your comments Robert. >> Although the proposed Boost.Multiprecision provides default >> implementations of int, rational and float, its main goal is >> not to compete with the world's best performing implementations >> thereof. > Of course it needn't compete with the world-class implementations, > at least not initially. However, it must be fast enough to be usable > in enough use cases to get sufficient experience to determine whether > the interface is right and whether the customization points are appropriate, > in order to have a solid foundation for a standard proposal. Agreed. In my opinion, though, the back-ends already provided in the review candidate provide sufficient performance to make the library absolutely usable and simultaneously gain experience with the interface. >> I would prefer spending review time working on the long-game >> of boost and C++. > Yes, given the minimal performance caveat noted above. >> How will boost or C++ potentially specify extended number >> types? >> >> template<typename back_end_numeric_type, >> typename numeric_traits, >> typename allocator_type, >> typename expression_method> >> mp_number >> { >> }; > That looks ugly, for a numeric type, but typedefs and template > aliases will be very useful in making nice, user-defined types > and class templates. Well, it's just an idea for potential standardization in my dream of the future. To me it doesn't really seem much uglier than std::basic_string. But honestly, we are far away from standardizing number representations. It's just one of my long-term goals....
answer 8: But... * There are no arbitrary precision floating point types - such types do not really exist in any case (how many digits does Pi have??). But... * There are *variable* precision floating point types - for example mpfr_float where you set the current working precision with the ::precision and ::default_precision member functions. > > -If I want to use boost Boost multiprecision on its own, > what is the name of the Boost .dll or .lib files that have all the headers > in it? I need a minimal set of files in order to run multiprecision > on its own. Huh? .dll's and .libs do not "contain" headers. On it's own, Boost.Multiprecision *does not need any external dll's or .lib's* - that's what "header only" means. But.... Some types in the library may make use of external libraries.... GMP, MPFR etc. You will need to look at the documentation for those libraries for the linking options required, but in general it's pretty simple on Unix like systems: Anything from boost/multiprecision/gmp.hpp requires -lgmp Anything from boost/multiprecision/mpfr.hpp requires -lmpfr -lgmp Anything from boost/multiprecision/mpfi.hpp requires -lmpfi -lmpfr -lgmp John. --- This email has been checked for viruses by Avast antivirus software. https://www.avast.com/antivirus...
answer 9: On 26/10/2018 06:03, A Z via Boost-users wrote: > I am aware the the boost multiprecision library is a headers library. > > -Is Boost multiprecision accurately arbitrary precision, ie. > can have its number precisions and scales always made to a larger number, > contingent only to the amount of available OS memory? This is a very vague question. But: * Yes for some integer types - for example cpp_int and mpz_int are both true arbitrary precision. But... * There are no arbitrary precision floating point types - such types do not really exist in any case (how many digits does Pi have??). But... * There are *variable* precision floating point types - for example mpfr_float where you set the current working precision with the ::precision and ::default_precision member functions. > > -If I want to use boost Boost multiprecision on its own, > what is the name of the Boost .dll or .lib files that have all the headers > in it? I need a minimal set of files in order to run multiprecision > on its own. Huh? .dll's and .libs do not "contain" headers. On it's own, Boost.Multiprecision *does not need any external dll's or .lib's* - that's what "header only" means. But.... Some types in the library may make use of external libraries.... GMP, MPFR etc....
answer 10: >> My code, when run as a 2048-point FFT, agrees with >> the MIT FFTW one to a max error margin of 6 parts >> per million. > This might be of interest: I've ported FFTW's arbitrary-precision > FFT to boost::multiprecision Awesome. I am a co-author of multiprecision and interested in your work. May I ask... Which FFTs did you concentrate on, dimensions, complex, etc.? What precisions did you use? Which multiprecision FP backend did you use? How was the performance? Where do you see the main application of your work in this area? How was your experience with multiprecision (critical suggestions are OK)? > Generally, I think it would be better if a boost::fft library would > primarily be a wrapper around existing FFT libraries, with the C++ > implementation only used as a fallback for multiprecision or licensing > issues since it's unlikely a template implementation would catch up with > the years of optimization work that went into single- and > double-precision libraries like MKL and FFTW, especially FFTW's kernel > generator and planner. I completely agree. This identically mirrors the philosophy used in multiprecision. > But a reasonably fast (and open) multidimensional multiprecision FFT > implementation doesn't seem to exist yet. I know. You're preaching to the choir. Got to put FFT on the back burner. GSoC 2014? Sincerely, Chris....
answer 11: Christopher Kormanyos <e_float <at> yahoo.com> writes: > * OK for GCC 4.7.2 > * Errors for VC10 (ambiguous symbols), AKA VisualStudio 2010 > * Errors for VC11 (ambiguous symbols), AKA VisualStudio 2012 Sorry. I've misinterpreted MSVC output. I do see the error now. And... this is really weird one. I did not see something like this in a long time. What it comes to can be illustrated in this example: #include <boost/multiprecision/cpp_dec_float.hpp> namespace boost { struct A{}; namespace inner1 { struct enable_if {}; } // inner namespace inner2 { using namespace ::boost::inner1; template<typename T> void f1( A& ) {} void f2() { f1<int>( A() ); // <=== !!!!!! Offending line } } // inner2 } // boost void foo() { typedef boost::multiprecision::number<boost::multiprecision::cpp_dec_float<50>, boost::multiprecision::et_off> mp_type; const mp_type test_value = mp_type(12) / 7; } I'm sure it can be simplified further by removing specifics of multiprecision library. And the offending line is ... the template instantiation, in unrelated namespace HAS NOTHING TO DO with enable_if at all. Good job MS - I am still trying to figure out how you manage to achieve this "result". Any hints are welcome. Gennadiy...
answer 12: On 26/10/2018 06:03, A Z via Boost-users wrote: > I am aware the the boost multiprecision library is a headers library. > > -Is Boost multiprecision accurately arbitrary precision, ie. > can have its number precisions and scales always made to a larger number, > contingent only to the amount of available OS memory? This is a very vague question. But: * Yes for some integer types - for example cpp_int and mpz_int are both true arbitrary precision. But... * There are no arbitrary precision floating point types - such types do not really exist in any case (how many digits does Pi have??). But... * There are *variable* precision floating point types - for example mpfr_float where you set the current working precision with the ::precision and ::default_precision member functions. > > -If I want to use boost Boost multiprecision on its own, > what is the name of the Boost .dll or .lib files that have all the headers > in it? I need a minimal set of files in order to run multiprecision > on its own. Huh? .dll's and .libs do not "contain" headers. On it's own, Boost.Multiprecision *does not need any external dll's or .lib's* - that's what "header only" means. But.... Some types in the library may make use of external libraries.... GMP, MPFR etc....
answer 13: Is there a fairly complete example program that uses Boost.Multiprecision? I saw the Miller-Rabin test > program, which is good. Perhaps a few more examples will help users to understand the basics of working > with the library. I'm impressed by this - both Chris's and John's work. It proves my thesis that no Maddock program is complete without lots of templates and some MPL as condiment! Boost has needed this for a long time, both integer and real. And now we have both. To be able to use the GMP and other packages optionally is a big bonus. I've also said that we must have more examples. This is going to be used by the 'great unwashed' when they run out of bits on the built-in types. So they won't read the manual (probably even if all else fails!) and will rely on examples to get they going, and to help out when they fall into some of the pits awaiting the unwary user (I fell :-( ). Suggestions for examples? Paul --- Paul A. Bristow, Prizet Farmhouse, Kendal LA8 8AB UK +44 1539 561830 07714330204 pbristow@hetp.u-net.com...
answer 14: > -If I wish to go into arbitrary precision and scale numbers, > what is the type I should use for an *integer*? What is the > #include statement I should use, and how do I specify > the number of whole number points and decimal points, > before starting my operations? What kind of integer? Fixed precision or arbitrary precision? Suggest you start with: #include <boost/multiprecision/cpp_int.hpp> using boost::multiprecision::int1024_t; // fixed precision 1024-bit integer, or: using boost::multiprecision::cpp_int; // arbitrary precision integer See https://www.boost.org/doc/libs/1_66_0/libs/multiprecision/doc/html/boost_multiprecision/tut/ints/cpp_int.html for other typedefs and examples. >and how do I specify the number of whole number points and decimal points,before starting my operations? That question makes no sense for integer types. > > -If I wish to go into arbitrary precision and scale numbers, > what is the type I should use for a *rational number*? What > is the #include statement I should use, and how do I specify > the number of whole number points and decimal points, > before starting my operations?...
answer 15: On 28/04/2016 08:05, Tassilo Glander wrote: > Dear List, > > When calling export_bits on a negative boost::multiprecision number based on cpp_int, an exception is thrown from the internal method msb ("testing individual bits in negative values is not supported"). > > boost::multiprecision::checked_int128_t i (-1); // use negative number > std::vector<unsigned char> v; > export_bits(i, std::back_inserter(v), 8); // throws > > How can I extract the content of a boost::multiprecision number? Boost documentation says, export_bits is designed to be used for data exchange, so in my understanding it would be a major flaw, if it cannot export supported values. > > I learnt that a workaround might be to directly access the backend's limbs, but this way I am accessing internals that may change. The issue here is that there is no portable bit-format for negative numbers, and in particular cpp_int does not use a 2's complement format if that's what you were expecting. So... while this should probably work to some degree (or at least give a better error message), what you're doing leads to all kinds of undefined behaviour. Bottom line, is that depending what you intend to do with the bits, you will need to handle negative values separately anyway. So a better workaround would be to only call export_bits on positive values....
- **avg_similarity**: 0.6799
- **max_similarity**: 0.7901
- **num_results**: 15
- **time_seconds**: 0.4177

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.7901365756988525 |
| 2 | None | None | 0.7289225459098816 |
| 3 | None | None | 0.7346479296684265 |
| 4 | None | None | 0.7383360266685486 |
| 5 | None | None | 0.6770451068878174 |
| 6 | None | None | 0.7901365756988525 |
| 7 | None | None | 0.6031051874160767 |
| 8 | None | None | 0.7376679182052612 |
| 9 | None | None | 0.7232648730278015 |
| 10 | None | None | 0.5705909132957458 |
| 11 | None | None | 0.5639909505844116 |
| 12 | None | None | 0.7232648730278015 |
| 13 | None | None | 0.4708307087421417 |
| 14 | None | None | 0.7289225459098816 |
| 15 | None | None | 0.6180076003074646 |

## 18. Question

- **question**: How do I share memory between processes using Boost.Interprocess?
- **ground_truth**: Boost.Interprocess provides shared memory support. Example:
```cpp
#include <boost/interprocess/managed_shared_memory.hpp>
boost::interprocess::managed_shared_memory segment(boost::interprocess::open_or_create, "MySharedMemory", 1024);
```
- **rag_answer**: answer 1: Sirs and madams, I hope to use boost interprocess shared memory to pass complex and dynamic data structures between processes on a host efficiently. The structures will be comprised only of simple primitives (int, float, etc.), interprocess basic_string, interprocess containers (vectors and maps), containers of containers, and (possible deal killer) boost::any. From the interprocess documentation, it _looks_ like the preceding is doable, aside from boost::any. The boost::any objects will themselves contain only primitives, basic_string, or interprocess vectors of unsigned char. So it _looks_ like the data held by the any should be okay. My question: does boost::any use pointers, references, or other constructs that preclude the class from working in shared memory? Thanks for your advice. Neil Ferguson...
answer 2: Borse, Ganesh wrote: > Hi, > I am developing an application with 2 unrelated, arbitrary processes having a C++ shared hash map between them to store data. > However, I am facing the problem of creating this template hash map in shared memory. > Can boost be used for this purpose? > Can anybody please suggest me the implementation which can be used to do this? > Thanks in advance. The hash map containers that were being developed by Daniel James (take a look at Vault/Containers) used to be shared memory friendly (I mean, compatible with Boost.Interprocess). I haven't tested them recently, though. To share containers between two unrelated processes please see Boost.Interprocess (currently in the CVS, and BoostVault/Concurrent Programming). Online docs here: http://ice.prohosting.com/newfunk/boost/libs/interprocess/ > Best Regards, > Ganesh B. Regards, Ion...
answer 3: The main > problem is, that we cannot use the managed_shared_memory code from > boost, because we rely on a different API to allocate the shared memory > between Windows and other devices. Also the container should be placed > at a fixed offset inside the created shared memory. > > I'm a complete newbie with boost and the interprocess library, that is > why I'm not sure which interface I have to provide for the interprocess > vector to be setup correctly. I hoped I could do something like: > > new (srh_mem_base + offset) boost::interprocess::vector<allocator>; > > I tried looking into the headers of the library to get an idea of that, > but I honestly got lost. > > I'm really sorry if this a stupid or obvious question - and I thank for > any help in advance! Unfortunatelly does not going to work. A shared memory vector expects a shared memory allocator that relies on the segment_manager class. That class expects a managed shared memory (or mapped file) that resolves allocation requests looking for free space in the managed shared memory segment. You would need to define a new allocator and managed shared memory (as you need to handle the allocation requests from the vector) that fulfills your needs. Not an easy task at all. For fixed offsets, you'd better avoid Interprocess and use an array or similar with no dynamic allocations. Best, Ion...
answer 4: Hi Phil, Phil Endecott <spam_from_boost_dev <at> chezphil.org> writes: > > Hi Mike, > > Mike Spertus wrote: > > basic_string and other containers take an > > allocator template argument, while basic_regex does not. > > > > If basic_regex had an allocator it would reap all the same benefits that > > other string and container types do. In particular, it would be possible > > to use boost::interprocess to place them in shared memory. > > IIUC, while the custom allocators let you put std::containers in shared > memory they are still not very useful since they can only be used by > the process that put them there - other processes will (potentially) > see the shared memory at a different address and all the pointers will > be wrong. Is this level of functionality useful to you? > Custom allocators do let multiple processes use the same containers in shared memory, even if they are mapped to different addresses because allocators define a pointer type for the container to use internally. For example, Boost::Interprocess provides an interprocess allocator that uses relative pointers to handle the exact issue you describe. See http://www.boost.org/doc/libs/1_41_0/doc/html/interprocess/allocators_containers.html#interprocess.allocators_containers.containers_explained for details. So shared memory STL containers are actually very useful, and we use them extensively in our project to share fully STL-compatible data structures between many processes....
answer 5: Hi all, I've been looking into the "boost::interprocess" library to use shared memory the resides in a non-paged physical memory facilitated by RTX (Real-time Windows extension). According to my understanding it's best to use "managed_external_buffer". I have managed to create the shared memory and create and share objects using raw pointers. I would however prefer using smart_ptr that is offered by the boost::interprocess. The problem I'm having is that I can create the shared pointer for any shared object in one process but when I want to create it's counter-part in the other process, it does not share the "share_count" with the original shared_ptr in the first process. For instance I tried to share a list of integers. So I used the interprocess::list as "named" object and once I crated it (following that "interprocess" documentation) I placed that pointer into a interprocess::shared ptr that I created using the helper function "make_managed_shared_ptr". Now in another process I am able to get hold of the raw pointer to that same list by looking up by the name but cant figure out (did lots of searches about this to no avail) how to instantiate an interprocess::shared_ptr such that it would get the same shared_count object. When I use the "make_managed_shared_ptr" and pass in the raw pointer to the shared object it will create one but with a new "shared_count" which is obviously bad....
answer 6: Dear folks, I have been using Boost's Interprocess module for communication between several peer processes. In particular, I am using the shared_memory_object. As I was trying to create it with open_or_create_t flag (to ensure it finishes in an atomic operation), I cannot tell whether it was created or it was just opened. I would like to apply initialization when it was created but use its current information when it was opened. I hope there is a member function that can return this status. Best regards, Gehua Yang...
answer 7: Hi, I'm a complete newbie with boost and have a question concerning the interprocess stuff. I took the piece of code to share a vector in shared memory between two processes from the quick-start guide as a start point and it compiled and ran immediately with success for me. Then I tried to replace the vector by a map: #include <boost/interprocess/managed_shared_memory.hpp> #include <boost/interprocess/containers/map.hpp> #include <boost/interprocess/allocators/allocator.hpp> using namespace std; int main () { boost::interprocess::shared_memory_object::remove("MySharedMemory"); boost::interprocess::managed_shared_memory segment(boost::interprocess::create_only, "MySharedMemory" ,65536); //segment size in bytes typedef pair<const int, int> MyPair; typedef boost::interprocess::allocator<MyPair, boost::interprocess::managed_shared_memory::segment_manager> ShmemAllocator; typedef boost::interprocess::map<int, int, less<int>, ShmemAllocator> MyMap; const ShmemAllocator alloc_inst (segment.get_segment_manager()); MyMap *mymap = segment.construct<MyMap>("MyMap")(alloc_inst); // mymap->insert(make_pair(1,10)); // mymap->insert(make_pair(2,20)); // mymap->insert(make_pair(3,30)); // mymap->insert(make_pair(4,40)); // mymap->insert(make_pair(5,50)); return 0; } and I wasn't able to compile it any more....
answer 8: On 10/11/13 4:40pm, Bjorn Reese wrote: > On 10/11/2013 02:55 PM, Sensei wrote: > >> Another side-question, if you don't mind. I'm not sure that what I'm >> doing is efficient, especially the need to copy from the region to a >> string. If you have suggestions, I'm more than happy to hear these. > > You may consider using <boost/interprocess/containers/string.hpp> > to avoid the copying. Hi Bjorn, I've tried to understand how boost::interprocess::string may work in conjunction with a mmapped file, but I'm lost in the documentation. All I've found regards shared memory between processes, but as far as I understand, I don't really need shared memory, since all my processing will be (for now) on a single process; in the future, threads, so even then I won't need shmem. Is there a document where I can read how to construct a container (or better a boost::interprocess::string) without shared memory? I'm not hopeful that a doc with boost::interprocess::string and mapped_region exists :) Thanks!...
answer 9: Hi, I'm looking into implementing an object cache available from multiple processes, I naturally found the boost::interprocess library mostly adapted for this. My problem is how to implement a cache eviction mechanism (LRU or other) when shared memory segment has been filled up. My problem gets worse, when I start using containers of containers, as described here : http://www.boost.org/doc/libs/1_46_1/doc/html/interprocess/allocators_containers.html#interprocess.allocators_containers.containers_explained.containers_of_containers So I have that allocator that I use everywhere, like in the example : typedef managed_shared_memory::segment_manager segment_manager_t; typedef allocator<void, segment_manager_t> void_allocator; I use it to create a boost::interprocess::map of objects, which in turn can contain a boost::interprocess::map of strings in shared memory as well. So to recap, I have an map of Object like an "object store" and each Object can contain a "dictionary" (map of strings) of unknown size, all of those living in a shared memory segment. My problem, is that shared memory segments are of a given size and any of the allocate() operation that the allocator is going to perform (when adding a new Object, or a new element in a dictionary) can throw a boost::interprocess::bad_alloc exception. So I'm wondering if there is a more suited library to do persistent caching of objects between processes, with a way to automatically evicts "old cache" from the memory....
answer 10: Hallo Group Members I need to use shared memory to communicate between two processes. is boost::tuple ready to be used by boost.interprocess? best regards, Michal...
answer 11: AMDG Michal wrote: > I need to use shared memory to communicate between two processes. > is boost::tuple ready to be used by boost.interprocess? > boost::tuple doesn't allocate dynamic memory and should not contain any pointers, so it ought to work. In Christ, Steven Watanabe...
answer 12: Hi there, at the moment I'm working on a Windows application, which uses Boost.Interprocess library to share data between two processes. The general approach is as follows: - start application A - start application B - create shared memory in A using 'wmanaged_windows_shared_memory'. The line of code would look like this: > sharedMemory = new wmanaged_windows_shared_memory(create_only, mName.c_str(), mSize); - connect B to shared memory using the 'open_only' argument for the line above (size is not needed when connecting) - then B creates data objects in the shard memory using offset pointers and when finished removes his references to the shared memory by deleting the 'wmanaged_windows_shared_memory' object - application A will then read these objects and when finished it will also delete his 'wmanaged_windows_shared_memory' object to remove all references and allow windows to free the allocated shared memory To enable Windows to free the shared memory I had to ensure that all references to this were removed. This was a little work, because at first not all references to the shared memory were freed by application B. In order to do so I replaced the existing Singleton with RII objects [1] to ensure all references are deleted when a well defined scope of application B is left....
answer 13: ----- Original Message ----- From: "Ion GaztaÃ±aga" <igaztanaga@gmail.com> To: <boost@lists.boost.org> Sent: Tuesday, February 17, 2009 5:57 PM Subject: Re: [boost] [future|interprocess] Could futures live in shared memory and synchronize process? vicente.botet wrote: > > Hi, > > > > As a future is a synchronization mechanism, I was wondering if > > futures are intrisic of mutil-threaded programs and so they > > live in the protected process memory or if the concept can be > > used in a multi-process context and have futures/promises > > living on shared memory. > > I don't see why do we want to have a future in shared memory. Do you see > any use case for this? I was just requesting the same thing. Well, it could be a way to communicate a value between a producer process and a consumer process, so ... the door is open. > A future is a handle of a concurrency unit that has spawned another > concurrency unit. A future for processes would be interesting, but > passing/returning values between processes is not easy and using shared > memory consumes at least 1 memory page. > > However, I can find useful a future returning "int", just because main > returns int and a process could spawn other processes and obtain futures > to them (Boost.Process child is a an example of this approach). Yes, I see but the future needed in this case will be internal to the spawning process, isnt't it?...
answer 14: <Viatcheslav.Sysoltsev <at> h-d-gmbh.de> writes: > > When process dies unexpectedly nobody guarantees your destructors are > called, but shared memory remains - this alone should let you rethink your > idea. As a rule of thumb I'd advise placing only plain POD-composed > structures in shared memory and never rely on the state of the shared > memory on startup before some kind of handshake with the counterparts. > Thanks Slava. Good points and I'm providing for handshaking between the participants and not relying on the shared mem. states alone. While the point is valid about the unexpected death of the process, I still find a gap in the knowledge of how the interprocess::shared_ptr is expected to be used across the processes. On my side I've been first exploring/assessing how the interprocess Shared Memory works (including the usefulness of shared_ptr/weak_ptr) before making design decisions. I don't like making premature design decisions just because of some gap in understanding about some library - you know what I mean :). Nonetheless thanks for the points :). If there is anyone who can show me how to use interprocess::shared_ptr with managed_external_buffer and ensure that the two sides would share the same shared_count I would be very grateful. Thanks in advance. gxl...
answer 15: Hello Boost-Mailing-List, I have a question about the boost interprocess library - and I hope I can explain it correctly. I looked at the "Quick guide for the impatient" about the interprocess library - but I'm not sure if I can use this for our purpose. The main goal is to insert a STL vector (or different container) in a predefined portion of an already existing shared memory. The main problem is, that we cannot use the managed_shared_memory code from boost, because we rely on a different API to allocate the shared memory between Windows and other devices. Also the container should be placed at a fixed offset inside the created shared memory. I'm a complete newbie with boost and the interprocess library, that is why I'm not sure which interface I have to provide for the interprocess vector to be setup correctly. I hoped I could do something like: new (srh_mem_base + offset) boost::interprocess::vector<allocator>; I tried looking into the headers of the library to get an idea of that, but I honestly got lost. I'm really sorry if this a stupid or obvious question - and I thank for any help in advance! Kind greetings BjÃ¶rn Als GmbH eingetragen im Handelsregister Bad Homburg v.d.H. HRB 9816, USt.ID-Nr. DE 114 165 789 GeschÃ¤ftsfÃ¼hrer: Dr. Hiroshi Nakamura, Dr....
- **avg_similarity**: 0.7121
- **max_similarity**: 0.8107
- **num_results**: 15
- **time_seconds**: 0.4324

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.7148934006690979 |
| 2 | None | None | 0.7604063749313354 |
| 3 | None | None | 0.8106787800788879 |
| 4 | None | None | 0.6633992791175842 |
| 5 | None | None | 0.7214779257774353 |
| 6 | None | None | 0.6088566184043884 |
| 7 | None | None | 0.7698266506195068 |
| 8 | None | None | 0.7852776646614075 |
| 9 | None | None | 0.6754503846168518 |
| 10 | None | None | 0.7382940649986267 |
| 11 | None | None | 0.8071708679199219 |
| 12 | None | None | 0.7612190246582031 |
| 13 | None | None | 0.49310022592544556 |
| 14 | None | None | 0.583743155002594 |
| 15 | None | None | 0.7879306674003601 |

## 19. Question

- **question**: How do I perform compile-time checks with Boost.StaticAssert?
- **ground_truth**: `BOOST_STATIC_ASSERT` allows you to perform compile-time checks. Example:
```cpp
BOOST_STATIC_ASSERT(sizeof(int) == 4);
```
- **rag_answer**: answer 1: Matt Calabrese wrote > On Mon, Sep 1, 2014 at 8:00 AM, Robert Ramey &lt; > ramey@ > &gt; wrote: > >> The compile-times argument doesn't impress me much though. Using >> a much more complex syntax or new library to shave a tiny bit of > > time of the compilation isn't a good trade off for me. >> > > The problem is that it can be far from tiny in practice. Compile-times are > often proportional to the amount of template instantiations you make, and > so when one branch makes a lot of them (I.E. one line of code instantiates > a ton of templates indirectly), it's horrible. Have you ever made a Spirit > grammar that takes minutes to compile? actually I have. But that was a very unusual case. In practice I just write the simple version and worry about when I find that it's a performance bottleneck. Actually, that's what I do with all my code. Turns out that only very infrequently (never?) do I have to go back and complicate things to address compilation times. FWIW - I'm extremely skeptical of performance claims based on speculation. It wouldn't surprise me of compilers are already skipping compilation of dead branches for which it can be easily determined that there are no compile-time side-effects. In fact since I generally have very little problem with compile times these days - in spite of writing a lot of template code - I'll bet that compiler writers already do this....
answer 2: On 16/10/2021 18:10, Peter Dimov via Boost wrote: > Nikita Kniazev wrote: >> Recently Core grew with additional dependencies on StaticAssert (in 1.76) and >> ThrowException (in the next release), previously it was only depending on >> Assert and Config. That made a lot of libraries checkout the same four >> repositories, three of them containing only a few headers. Merging into a >> single dependency will affect mostly positive about 100 libraries and negative >> 1: StlInterfaces (depends on Assert, and will on Core). >> >> Please leave a comment at https://github.com/boostorg/core/issues/97 if you >> think it is a good idea, or have concerns against doing that. > I prefer keeping this discussion here on the list, rather than in an issue, so please > reply here instead if you have an opinion. :-) > > The proposal is: > > * Merge Assert into Core > * Merge StaticAssert into Core This is fine by me, I imagine that Boost.StaticAssert is rapidly becoming obsolete anyway? John. -- This email has been checked for viruses by Avast antivirus software. https://www.avast.com/antivirus...
answer 3: On Mon, Sep 1, 2014 at 8:00 AM, Robert Ramey <ramey@rrsd.com> wrote: > The compile-times argument doesn't impress me much though. Using > a much more complex syntax or new library to shave a tiny bit of time of the compilation isn't a good trade off for me. > The problem is that it can be far from tiny in practice. Compile-times are often proportional to the amount of template instantiations you make, and so when one branch makes a lot of them (I.E. one line of code instantiates a ton of templates indirectly), it's horrible. Have you ever made a Spirit grammar that takes minutes to compile? Now imagine that each branch of an if at the top level creates a slightly different grammar or that uses it in a different way. Even if your condition is known through a compile-time constant bool, If you don't add a level of indirection to prevent both from being instantiated, either manually or by way of a higher-level facility like a static if, your compile time for that translation unit can possibly double, or worse. It does raise an interesting question though. Wouldn't it be a good thing > for the compiler to totally skip syntax checking for branches known to > be false at compile time - perhaps as a release mode option? > While it would be nice to more easily write code that's more lazy about instantiation like this, I don't think it's quite so simple to add to the language quite like that, and especially not as something that changes based on a compiler option....
answer 4: Ben Robinson wrote 2011-09-05 21:57: > ... I currently call it MetaBoundedInt, and the design philosophy > was to provide both an overflow, and ranged checked integer, which leverages > as much compile time information as possible to maximize performance, as > well as communicate overflow/range errors at compile time when possible. That seems to be more in line with how for instance Ada does it, which probably means that it is a more reasonable approach than mine. That said, part of the reason for me to start looking into this was some sloppy use of integers within a project I joined and a fairly strict environment would have helped. > mbi<throwing_policy, int8_t, -8, 8> var2(0U); // Detects overflow and range Why not go all the way and select an underlying int based on the given range? > As you requested Leif, the throwing_policy can be replaced in a release > build with an ignore_policy, so that these additional checks can be > eliminated for maximum release build performance. Then I was not clear enough. If a check cannot be made at compile-time I want it to be done at runtime. I do want this type of library to be as efficient as possible for better acceptance among developers, but my main reason for wanting it to do static checks as much as possible is to detect faults as early as possible, and to make it harder to write that sloppy code. Sincerely, Leif Linderstam...
answer 5: You're on the right track as far as the set of compilers that are working (I wouldn't sweat 4.1.1, if 4.1.2 works), but you may want to test your code against all the scenarios in MPL's has_xxx test suite. I found that while working out the kinks with these SFINAE techniques, false positives were common and even ICE could occur on different platforms. However, I think I may have worked out those kinks well enough that my effort could be reused, perhaps as the start of a compile time type introspection library. A few months ago, I submitted a patch to MPL's has_xxx utility to detect member templates. (The patch, svn ticket #861, didn't make it through the transition from cvs. When I just tried to upload it to Track it was rejected as spam.) Like I said, getting the patch to work took some effort as well as help from folks on this list. An e-mail describing the final product is archived at http://tinyurl.com/3b3enm. You can copy and past the patch at the bottom of the e-mail. Anyway, others have suggested using SFINAE to build various compile time type introspection capabilities for C++, and I kept that in mind while I was working on detecting member templates. I think the backbone is more or less in place for complete compile time type introspection that could address your issue with static member functions as well as non-static member functions, member data, templates, types, etc....
answer 6: On 02/09/2014 00:06, Robert Ramey wrote: > FWIW - I'm extremely skeptical of performance claims based on > speculation. It wouldn't surprise me of compilers are already > skipping compilation of dead branches for which it can be easily > determined that there are no compile-time side-effects. In fact > since I generally have very little problem with compile times these > days - in spite of writing a lot of template code - I'll bet that > compiler writers already do this. Not that it matters because > it's just not a problem except in contrived pathological cases. When you instantiate a template, it gets instantiated. It takes time. It takes place in RAM that is never freed until the end of processing the TU. There are costs associated to it. I don't see why there is any need to be skeptical about the workings of template mechanisms in C++ as implemented....
answer 7: Hi all! I've noticed that MSVC++ 2010 has implemented static_assert (compile time checks); and probably as a result, the code that used to build fine in MSVC++ 2008 is now generating the following error. code: BOOST_STATIC_ASSERT(N==1) *error C2338: (N==1)* ** Appreciate if anyone who has resolved this error can share their experiences.. Thanks, --Thomas. **...
answer 8: On 6 Sep 2011, at 19:33, Leif Linderstam wrote: > Ben Robinson wrote 2011-09-05 21:57: >> ... I currently call it MetaBoundedInt, and the design philosophy >> was to provide both an overflow, and ranged checked integer, which leverages >> as much compile time information as possible to maximize performance, as >> well as communicate overflow/range errors at compile time when possible. > > That seems to be more in line with how for instance Ada does it, which > probably means that it is a more reasonable approach than mine. That > said, part of the reason for me to start looking into this was some > sloppy use of integers within a project I joined and a fairly strict > environment would have helped. > >> mbi<throwing_policy, int8_t, -8, 8> var2(0U); // Detects overflow and range > > Why not go all the way and select an underlying int based on the given > range? > >> As you requested Leif, the throwing_policy can be replaced in a release >> build with an ignore_policy, so that these additional checks can be >> eliminated for maximum release build performance. > > Then I was not clear enough. If a check cannot be made at compile-time I > want it to be done at runtime....
answer 9: All have to do is use rationals, which I already have available, instead of integral types inside the mapped type. One thing I'll mention, in case anyone can think of something better, is that comparison of classifications and unit types takes either constant time or N*log(N) for a comparison resulting in true_, where N is the number of fundamental types which make up the derived type. This is due to the fact that the order of elements in a compile-time associative sequence in MPL is determined by how the sequence is created (and I see no simple way to make consistently ordered sequences of types at compile-time without requiring intrusive information, which is not an option in this case). So, in order to perform a proper comparison, I cycle through the fundamentals of one type and check the corresponding mapped type on the other type if an element with the same key exists. Hence, N*log(N) time for a comparison resulting in true_. Thankfully, due to the nature of templates, this time won't be needed in every check, since once the template is instantiated, the calculations won't have to be performed again with redundant instantiations. Aside from that, prior to doing the complex comparison described, I do a raw is_same check, which would run in constant time and is all that is required in the case that it yields true_, in the hope that in many situations the type will have been formed in a similar manner, meaning the complex check would not be required. Still, if anyone can think of a more efficient way of handling this without requiring a worst case scenario of N*log(N) time for comparisons yielding true_, I'm all ears....
answer 10: Nikita Kniazev wrote: > Recently Core grew with additional dependencies on StaticAssert (in 1.76) and > ThrowException (in the next release), previously it was only depending on > Assert and Config. That made a lot of libraries checkout the same four > repositories, three of them containing only a few headers. Merging into a > single dependency will affect mostly positive about 100 libraries and negative > 1: StlInterfaces (depends on Assert, and will on Core). > > Please leave a comment at https://github.com/boostorg/core/issues/97 if you > think it is a good idea, or have concerns against doing that. I prefer keeping this discussion here on the list, rather than in an issue, so please reply here instead if you have an opinion. :-) The proposal is: * Merge Assert into Core * Merge StaticAssert into Core * Merge ThrowException into Core Each of these may be done or not. We also have an additional option of * Merge StaticAssert into Assert if we decide not to do the above....
answer 11: On Sat, Oct 16, 2021 at 2:19 PM John Maddock wrote: > This is fine by me, I imagine that Boost.StaticAssert is rapidly > becoming obsolete anyway? Not everyone is on C++17 to use static_assert(expr), so even C++11 and C++14 Boost libraries (and some Boost users) choose BOOST_STATIC_ASSERT(expr) over having to static_assert(expr, "expr") etc. Glen...
answer 12: Hi there, do you think it would make sense to move static_warning.hpp from boost/serialization up directly under boost/, and perhaps move it conceptually under Boost.StaticAssert umbrella? It seems strange how a serialization library exposes such general-purpose service. We could still provide a forwarding header in Serialization namespace for backward compatibility. Shall I prepare a patch to that effect? Thanks, PM...
answer 13: It has an ugly syntax, but I > guess your framework could make it simpler. But then, even with full > concepts in C++ assertions have an advantage: they give you a cleaner error > message. Based on your and Vicente's input, I'll remove static_assert from contracts (pre, post, inv, etc). Is any predicate programmable with static_assert also programmable with Boost.ConceptCheck? I guess so if the Boost.ConceptCheck concept can do the static assertion using Boost.MPL or Boost.StaticAssert. If that it true then no need for me to provide static_assert at all, just use Boost.ConceptCheck. Otherwise, I'll allow static_assert together with Boost.ConceptCheck concepts in the requires clausle. How does that sound? > > 2) Let's assume, we answered option A to question 1): > > > > template< typename To, typename From > > > To* memcopy ( To* to, From* from ) > > precondition{ > > static_assert(sizeof(To) >= sizeof(From), "destination too > > small"); > > static_assert(boost::is_convertible<From, To>::value, > > "incompatible types"); > > to; // pointer not null > > from; // pointer not null > > } > > { > > // ... > > } > > > > Would you expect these static_asserts to be disabled when precondition > > compilation and checking is turned off at compilation time? I'd think > > so....
answer 14: I cannot use Boost libraries if they can't be certified. Static analyzers can help insure quality, which makes it easier to qualify these tools. There are many tools available. Some, like CppCheck, are open source. Others are built into development environments (aforementioned VS Analyzer, Clang tools, etc.). Further, I suspect that tool vendors could be convinced it would be good PR to have their tools used by Boost, so I suspect even those with paid licenses can be made available for free. Steve Hickman System Architect, Flight Deck of the Future 480-236-8367...
answer 15: > > Basically I am building a static library, which depends on some in-house > software components, Qt and Boost. > Our own library S3FC (), uses templates in such a manner as to make MSVC6 > very unhappy. Therefore we use the Intel compiler under M$. > Needless to say, our software compiles problemfree with GCC. For the > aforementioned and other reasons we do not make use of > Microsoft Foundation Classes when compiling under Windoze, but use the > latest version of STLPort (which has been at the same version level for some > time now). > > Anyway; our Windows development work takes place under Visual C++ but with > the Intel compiler (version 7.0) selected instead of the MSVC6 compiler. > > OK; with this background then, here is the basic Visual C++ project settings > for my build of the above-mentioned library. I have removed include paths > etc. which point to in-house > software: > > 1) "Not Using MFCC" selected for general project settings (as explained > above)....
- **avg_similarity**: 0.4673
- **max_similarity**: 0.7032
- **num_results**: 15
- **time_seconds**: 0.4164

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.37791112065315247 |
| 2 | None | None | 0.5912403464317322 |
| 3 | None | None | 0.4199058711528778 |
| 4 | None | None | 0.28488996624946594 |
| 5 | None | None | 0.4129062592983246 |
| 6 | None | None | 0.349111944437027 |
| 7 | None | None | 0.697914183139801 |
| 8 | None | None | 0.2678025960922241 |
| 9 | None | None | 0.370148241519928 |
| 10 | None | None | 0.5321003794670105 |
| 11 | None | None | 0.703234851360321 |
| 12 | None | None | 0.5110583901405334 |
| 13 | None | None | 0.6586369872093201 |
| 14 | None | None | 0.4922246038913727 |
| 15 | None | None | 0.3409136235713959 |

## 20. Question

- **question**: What are Boost.TypeTraits and how do they help with type manipulation?
- **ground_truth**: Boost.TypeTraits provide compile-time information about types, such as checking if a type is integral, floating point, or pointer. Example:
```cpp
#include <boost/type_traits.hpp
boost::is_integral<int>::value; // true
boost::is_integral<float>::value; // false
```
- **rag_answer**: answer 1: Hello John, you have probably already read that I think some new TypeTraits are useful. Here are the details: a) very useful: precise type classification - this is the basis of every abstraction and should definitely be implemented - is_character: contains only characters (char32/16/8_t, wchar_t, char); is_un/signed_character - is_integer: contains only integers and no characters and no bool (u/int8..X_t); is_un/signed_integer - is_logic: contains only logical types (bool and boost::tribool, *)) - is_string: contains everything that can be used as a string, but needs these specializations: 1) is_bounded_string (similar to is_bounded_array) 2) is_unbounded_string (similar to is_unbounded_array) 3) is_static_string (for boost::basic_static_string) 4) is_string_ref (for boost::basic_string ref) 5) is_string_view (for std::basic_string_view) 6) is_string_class (for std::basic_string) - character_of: the underlying character type based on is_string b) very useful - remove_cv_ptr (similar to remove_cv_ref) - make_same_signed (similar to make_un/signed): changes the sign depending on a type - conditional_signed: changes the sign depending on a truth value - is_same_signed: same sign c) also makes sense - is_tuple - is_rational (similar to boost::is_complex) - is_binary: if base==2 (numeric_limits::radix==2) - is_decimal: if base==10 (numeric_limits::radix==10) d) - is_native: a type is natively available on the platform (e.g....
answer 2: Hello, with the planned changes of the dependencies of the boost libraries to newer C++-standards, I would like to ask how this is planned for boost::TypeTraits. 1) In my opinion it would make sense to remove all TypeTraits that are already in the standard, and only provide those that do not exist in the standard (yet). Of course, this depends on the planned minimum standard for boost::TypeTraits. 2) If, on the other hand, boost::TypeTraits is to continue to work with C++03 (for which there may be reasons), however, quite a few adjustments must be made (for newer C++-standards) and bugs must be fixed. Examples: a) - no inline-variables are provided for C++17 (if useful), e.g. is_arithmetic_v - no concepts are provided for C++20 (if useful), e.g. arithmetic - that's why I already asked how to do this best without coming into (name)conflicts with existing structures/namespaces/etc. b) bugs - e.g. is_integral does not contain char8_t (if available) Probably my remarks also apply to other libraries, possibly TypeErasure, TypeIndex, TTI ... All this has to be reworked fundamentally and consolidated if necessary. best regards Gero...
answer 3: This might be a useful thing to do in perspective, but I don't think this is our immediate priority now to improve dependencies. I think MPL.Core and TypeTraits.Core would do better (for all Boost libraries) and simpler to achieve. I'm intentionally not calling TypeTraits v2 as TypeTraits.Core, as I'd really like TypeTraits.Core to not depend (interface-wise) on MPL or std::integral_constant or std:: type traits. I.e. TypeTraits.Core interface should only define a nested type ::type or constant ::value and not derive from any particular primitive (std or MPL). This still allows to implement TypeTraits.Core through std:: type traits. >> We don't need another bool_ in Core (yet) and TypeTraits.Core would be >> enough for us. > > Replacing use of TypeTraits with use of core type traits is precisely what > demands the use of another bool_, because you can no longer use the old > mpl::bool_ for dispatching a core type trait. Either we enhance mpl::bool_ > with a converting constructor, or we switch to core::bool_. In my view, TypeTraits.Core shall not be suitable for tag dispatching....
answer 4: - I have no idea when and where one should use this paradigm. I had implied that the scope of TypeErasure was to replace inheritanceâbased polymorphism whenever possible. Now I think it may be more modest, though it is unclear to me what is the actual field of application. Could anyone tell me how they intend to use type erasure ? Regards, Julien...
answer 5: Le 16/09/14 21:47, Andrey Semashev a Ã©crit : > On Tuesday 16 September 2014 20:06:27 John Maddock wrote: >>> Boost.TypeTraits is used in lots of other Boost libraries, and it >>> currently >>> unnecessarily pulls MPL and TypeOf. The dependencies are introduced by >>> just >>> these two public headers: floating_point_promotion.hpp and >>> common_type.hpp. >>> I'd like to avoid these dependencies. >>> >>> I propose to extract common_type.hpp (and its implementation and tests) >>> into a sublib within type_traits (e.g. type_traits/common_type). >>> >>> As for floating_point_promotion.hpp, it is used in promote.hpp, which is >>> using integral_promotion.hpp. I can see two ways of tackling it: >>> >>> 1. Extract all promotion traits into a sublib (e.g. >>> type_traits/promotion). >>> This includes floating_point_promotion.hpp, integral_promotion.hpp and >>> promote.hpp, as well as their tests. >> What happens to boost/type_traits.hpp in this scheme (which depends on >> *all* of type_traits)? > Hmm, I didn't notice that header. Ok, assuming we don't want to move this one > header to its own sublib, what if we approach it from the other side. We can > move all type traits except common_type.hpp and type_traits.hpp to a sublib > base (i.e. type_traits/base)....
answer 6: On the other hand, there are likely many uses of > type traits in an MPL context and I'm not sure what places, if any, need the > ::tag for instance. For purposes of tag dispatching and compatibility with standard type traits, it is sufficient to derive mpl::bool_ from boost::integral_constant, which could be an alias or derive from std::integral_constant. mpl::bool_ can add the ::tag typedef. If you want to just drop the mpl::bool_ part of the interface from type traits, that would be a breaking change, and arguably should be done as an alternative implementation of type traits (TypeTraits v2?). This might be a useful thing to do in perspective, but I don't think this is our immediate priority now to improve dependencies. I think MPL.Core and TypeTraits.Core would do better (for all Boost libraries) and simpler to achieve. I'm intentionally not calling TypeTraits v2 as TypeTraits.Core, as I'd really like TypeTraits.Core to not depend (interface-wise) on MPL or std::integral_constant or std:: type traits. I.e. TypeTraits.Core interface should only define a nested type ::type or constant ::value and not derive from any particular primitive (std or MPL). This still allows to implement TypeTraits.Core through std:: type traits. >> We don't need another bool_ in Core (yet) and TypeTraits.Core would be >> enough for us....
answer 7: frederic.bron@alcan.com wrote: > Dear boost implementers, > TypeTraits is very useful, thanks you. > However, recently, I needed something to know if a type is comparable > (with operator<) and that was not in the library. > Fortunately, somebody forwarded me an earlier post on the users list > where I could find what I wanted. The implementation was inspired > from boost/detail/is_incrementable.hpp > I have written is_less_comparable, is_less_equal_comparable, > is_greater_comparable... inspired from the same source and I wonder > if it could be possible to add it to the library as I think it could > be > helpful for others. I give the source code below (if it is useful) > but I am not able to make it fully general as it is in > boost/type_traits. In particular, I do not understand all the macros > that are > used. This has come up often enough that I think this is an excellent idea: I'd be happy to help with macro usage and other details, but the most important thing is for some docs and tests to get written :-) It might also be useful to have a very quick mini-review of an addition like this so folks can check that the names are all sensible choices etc (I have a couple of minor additions that might benifit similarly). If it would help I could set up a directory in the sandbox to add all the changes to? Regards, John Maddock....
answer 8: On 2/26/2011 4:21 AM, FrÃ©dÃ©ric Bron wrote: >> Have you looked for compound traits in other libraries that could be added to TypeTraits for convenience? That is, if it is very common to combine certain traits, then a single trait that captures the compound would simplify a good deal of code. I do not think you should worry too much about what else exists right now as long as you feel you have a complete set of operators, which should be the main focus of your library as I see it. There can be time enough if your library gets accepted into Boost for other implementers of type traits like extensions to use your operators instead of what they had been using in order to avoid redundancy. It's not your job to delay finishing your work in any way to worry about redundancies in all other Boost libraries. > > No I have not. > what about is_voidstar? I am using this a lot in my addition. > Would it be meaningful to add this? > > I checked a bit more for duplicates: > * these are duplicate: > . boost/detail/has_default_constructor.hpp and > boost/type_traits/has_trivial_constructor.hpp > . boost/type_traits/is_float.hpp and > boost/type_traits/is_floating_point.hpp (is_float is not in the > documentation) > > * these would be nice to have in type_traits > . boost/mpl/has_xxx.hpp These are in my TTI library as BOOST_TTI_HAS_TYPE and BOOST_TTI_HAS_TEMPLATE. > ....
answer 9: ----- Original Message ----- From: "John Maddock" <boost.regex@virgin.net> To: <boost@lists.boost.org> Sent: Wednesday, September 08, 2010 10:23 AM Subject: Re: [boost] [chrono] Split into Stopwatches, Chrono,Ratio and TypeTraits.ext > >>>> As requested in this ML I have splited Boost.Chrono into 4 libraries >>>> >>>> * Boost.TypeTraits.Ext: contains the C++0x common_type and add_rvalue >>>> reference traits classes and the declval utility function >>>> >>> Coudln't this be fast forwarded as type_traits new features ? >> >> This was my intent. What do they think the Boost.TypeTraits maintainers? > > Sounds fine to me, are there patches somewhere I can look at? Hi, Great. I have not developed this on the trunk. The current repository is http://svn.boost.org/svn/boost/sandbox/chrono/boost/type_traits/ http://svn.boost.org/svn/boost/sandbox/chrono/libs/type_traits_ext/ Of course, the subdirectory ext should be removed once integrated. I could move this to the trunk and provide a patch if this is better for you. I don't know how you want to include this on the current documentation. Let me know if I can do something....
answer 10: >> >> true > > This is, in my mind, a significant point which you overlook below. > > [snip "addition," etc. and "add," etc.] > >> I agree these names are nicer as those chosen by the standard >> and proto ... >> >> Still >> >> (1) I would prefer uniformity over improvement here. I think it is of >> greater value, if we manage to converge names in boost and the >> standard, specifically in fields that are very fundamental to c++ as a >> language, which is clearly the case here. > > It isn't uniformity when they name different things. Indeed, I consider using the same names for different things to be confusing. Hmm, not extremely different though. The way the std functors are implemented is that they just call the operators without changing the semantics that is implemented for a given type parameter they are working on. >> (2) If we considered to choose new names, I'd clearly prefer names >> that emphasize on syntax, to make clear that semantics is attached to >> operators by implementation >> >> sign semantics >> + cross addition, set union, concatenation, ... >> - dash subtraction, set difference, deletion ... >> * star multiplication, intersection, Cartesian product ... >> / slash division, factorization, ... > > I'd never think of "cross" for "+". It has always been a "plus sign" to me. You also have the problem of "*" being "asterisk" and "-" being "hyphen" to different people....
answer 11: I guess it depends to what >>>extra you see this as an extension to the Boost.TypeTraits >>>library for manipulating function types, and to what extent >>>it is viewed as a utility component for use in implementing >>>function wrappers and so on. >>> >> >>Supporting data members is trivial. So of what help could the library be? > > > Consistency. TR1 defines 'callable' types to include data > members; Boost.Function, Boost.Bind and Boost.Lambda all > support data mebers as unary functions. The > is_callable_builtin<> metafunctions are just for convenience > -- they can be implemented by mpl::or_'ing together > is_function, is_function_reference, is_function_pointer, and > is_member_function_pointer. I'm suggesting that you should > include is_member_object_pointer too. > I'm not fully convinced since that "callable builtin" term doesn't work without a definition, anyway. From my feeling data members should be handled at a higher level of abstraction (at the same place where we normalize between function objects and functions). >>>>>10....
answer 12: a) new io manipulators b) facilities for wrapping streambuf c) a couple of new kinds of streams These should be considered separately. Manipulators ============ Here is the first part of the documentation: Rationale There are several I/O manipulators that can be useful to a general audience besides the ones given in the Standard library. This header supplies some of them. Form-based Manipulator Header The header boost/io/iomanip_form.hpp contains a class template for multiple manipulations. Form-based Manipulator Objects from a boost::io::basic_ios_form template class represent manipulators that determine what and how to affect the standard I/O attributes via repeated calls to its member functions, then can change how a single insertion or extraction call happens for an streamable object. Said manipulators can be temporarily created (in-line, without a name) or created conventionally in advance for multiple insertions/extractions. On getting this far, I have no idea what these manipulators are supposed to do, what problem they are meant solve. Or when I would use them. I believe that this part of the manual should contain: Motivating example. Problem solved by form-based manipulators. A sort of Tutorial section. The line-skipping an repeated-char seem a little more understandable- if only because of their names. Repeated_char_narrow - I would think that the "narrowing" of characters might be something more commonly handled by codecvt facet. I would prefer that the html files be broken in smaller sections....
answer 13: > > Likewise I think an extern_c_cc that (currently) never > matches would be good. For what? <snip> > What are your thoughts on adding support for pointers to > member data to the library? I guess it depends to what > extra you see this as an extension to the Boost.TypeTraits > library for manipulating function types, and to what extent > it is viewed as a utility component for use in implementing > function wrappers and so on. > Supporting data members is trivial. So of what help could the library be? >>>8. 'Tag Types' documentation >>> >>> In several places, the 'Tag Types' documentation >>> incorrectly gives types two leading underscores. >> >>Where?! > > In the non_cv reference: > > | Equivalent to __tag<__non_const,__non_volatile>, but > | involves fewer template instantiations when evaluated. > > Also in const_non_volatile, volatile_non_const and > cv_qualfied. > > Actually, is the documentation in the zip file up to > date? It has [last-revision $Date: 2005/05/21 13:27:00 $]. I see. Thanks for spotting. It's a documentation problem. The names with the underscores should be identifier names for QuickBook macros that expand to hyperlinks -- obviously the definitions are missing... >>>10....
answer 14: frederic.bron@alcan.com wrote: > > Dear boost implementers, > TypeTraits is very useful, thanks you. > However, recently, I needed something to know if a type is comparable (with operator<) and that was not in the library. > Fortunately, somebody forwarded me an earlier post on the users list where I could find what I wanted. The implementation was inspired from boost/detail/is_incrementable.hpp > I have written is_less_comparable, is_less_equal_comparable, is_greater_comparable... inspired from the same source and I wonder if it could be possible to add it to the library as I think it could be > helpful for others. I give the source code below (if it is useful) but I am not able to make it fully general as it is in boost/type_traits. In particular, I do not understand all the macros that are > used. It would really be nice to have type_traits for all the possible user-defined operators. As part of that it seems that boost/detail/is_incrementable.hpp could be lifted from the boost::detail namespace and put into those new type_traits. I know you mentioned subsequently in another post that you are working on more of the operators but I do not know if you had decided to provide type_traits for all of the user-defined operators. If you had not decided to do all of them, I would like to encourage you to do so if you feel that the work to do them is not overwhelming....
answer 15: On such a system, surely extern "C" typedef void (*ext_c_func_ptr)(); is_function_pointer< ext_c_func_ptr, default_cc >::value *should* return false? (I appreciate it may not, but this is an problem with the implementation, albeit a problem that can't necessarily be solved at the moment.) > Adding a note to the docs won't hurt, though. > > > > > Likewise I think an extern_c_cc that (currently) never > > matches would be good. > > For what? So that a compiler supporting type introspection and language linkage in the type system can implement it properly. For example, in Digital Mars __cdecl and extern "C" are synonyms, so you already have support for it on that platform. > <snip> > > What are your thoughts on adding support for pointers to > > member data to the library? I guess it depends to what > > extra you see this as an extension to the Boost.TypeTraits > > library for manipulating function types, and to what extent > > it is viewed as a utility component for use in implementing > > function wrappers and so on. > > > > Supporting data members is trivial. So of what help could the library be? Consistency. TR1 defines 'callable' types to include data members; Boost.Function, Boost.Bind and Boost.Lambda all support data mebers as unary functions....
- **avg_similarity**: 0.5632
- **max_similarity**: 0.6808
- **num_results**: 15
- **time_seconds**: 0.4179

| rank | retrieval_method | source_file | similarity |
|---|---|---|---|
| 1 | None | None | 0.6051451563835144 |
| 2 | None | None | 0.6807767748832703 |
| 3 | None | None | 0.6638148427009583 |
| 4 | None | None | 0.27447137236595154 |
| 5 | None | None | 0.6039808988571167 |
| 6 | None | None | 0.613143265247345 |
| 7 | None | None | 0.6493058204650879 |
| 8 | None | None | 0.6030812859535217 |
| 9 | None | None | 0.5599531531333923 |
| 10 | None | None | 0.4461200535297394 |
| 11 | None | None | 0.5366857647895813 |
| 12 | None | None | 0.41951456665992737 |
| 13 | None | None | 0.5568566918373108 |
| 14 | None | None | 0.6716901659965515 |
| 15 | None | None | 0.5639129281044006 |
